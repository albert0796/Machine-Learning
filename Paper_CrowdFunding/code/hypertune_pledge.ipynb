{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/Users/iflab/Desktop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mix_platforms.csv', encoding='utf-8',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['platforms','pledged_percent','status'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('project_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>location</th>\n",
       "      <th>backers</th>\n",
       "      <th>goal_usd</th>\n",
       "      <th>pledged_usd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>620302213</td>\n",
       "      <td>Art</td>\n",
       "      <td>USD</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9572984</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1379346088</td>\n",
       "      <td>Art</td>\n",
       "      <td>MXN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>16.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                category location  backers  goal_usd  pledged_usd\n",
       "project_id                                                       \n",
       "620302213            Art      USD        6      0.01       100.00\n",
       "9572984     Film & Video      USD        0      0.15         0.00\n",
       "1379346088           Art      MXN        7      0.49        16.41"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iflab/Desktop/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "data['category'].loc[data['category']=='art']='Art'\n",
    "data['category'].loc[data['category']=='comics']='Comics'\n",
    "data['category'].loc[data['category']=='music']='Music'\n",
    "data['category'].loc[data['category']=='design']='Design'\n",
    "data['category'].loc[data['category']=='technology']='Technology'\n",
    "data['category'].loc[data['category']=='food']='Food'\n",
    "data['category'].loc[data['category']=='photography']='Photography'\n",
    "data['category'].loc[data['category']=='theatre']='Theater'\n",
    "data['category'].loc[data['category']=='fashion']='Fashion'\n",
    "data['category'].loc[data['category']=='dance']='Dance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593011, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.get_dummies(data,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers</th>\n",
       "      <th>goal_usd</th>\n",
       "      <th>pledged_usd</th>\n",
       "      <th>category_Comics</th>\n",
       "      <th>category_Crafts</th>\n",
       "      <th>category_Dance</th>\n",
       "      <th>category_Design</th>\n",
       "      <th>category_Fashion</th>\n",
       "      <th>category_Film &amp; Video</th>\n",
       "      <th>category_Food</th>\n",
       "      <th>...</th>\n",
       "      <th>location_EUR</th>\n",
       "      <th>location_GBP</th>\n",
       "      <th>location_HKD</th>\n",
       "      <th>location_JPY</th>\n",
       "      <th>location_MXN</th>\n",
       "      <th>location_NOK</th>\n",
       "      <th>location_NZD</th>\n",
       "      <th>location_SEK</th>\n",
       "      <th>location_SGD</th>\n",
       "      <th>location_USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>620302213</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9572984</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1379346088</td>\n",
       "      <td>7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>16.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            backers  goal_usd  pledged_usd  category_Comics  category_Crafts  \\\n",
       "project_id                                                                     \n",
       "620302213         6      0.01       100.00                0                0   \n",
       "9572984           0      0.15         0.00                0                0   \n",
       "1379346088        7      0.49        16.41                0                0   \n",
       "\n",
       "            category_Dance  category_Design  category_Fashion  \\\n",
       "project_id                                                      \n",
       "620302213                0                0                 0   \n",
       "9572984                  0                0                 0   \n",
       "1379346088               0                0                 0   \n",
       "\n",
       "            category_Film & Video  category_Food  ...  location_EUR  \\\n",
       "project_id                                        ...                 \n",
       "620302213                       0              0  ...             0   \n",
       "9572984                         1              0  ...             0   \n",
       "1379346088                      0              0  ...             0   \n",
       "\n",
       "            location_GBP  location_HKD  location_JPY  location_MXN  \\\n",
       "project_id                                                           \n",
       "620302213              0             0             0             0   \n",
       "9572984                0             0             0             0   \n",
       "1379346088             0             0             0             1   \n",
       "\n",
       "            location_NOK  location_NZD  location_SEK  location_SGD  \\\n",
       "project_id                                                           \n",
       "620302213              0             0             0             0   \n",
       "9572984                0             0             0             0   \n",
       "1379346088             0             0             0             0   \n",
       "\n",
       "            location_USD  \n",
       "project_id                \n",
       "620302213              1  \n",
       "9572984                1  \n",
       "1379346088             0  \n",
       "\n",
       "[3 rows x 61 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593011, 61)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('mix_platforms_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_v1.drop(\"pledged_usd\", axis=1).values\n",
    "y = data_v1[\"pledged_usd\"].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11818.4288975322 123761.02171133753 \n",
      "\n",
      "12084.047838491548 119781.33735993227\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_train),np.std(y_train),'\\n')\n",
    "print(np.mean(y_test),np.std(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                    ('scaler', Normalizer()),\n",
    "                    ('regressor', DecisionTreeRegressor())\n",
    "                     ])\n",
    "\n",
    "parameters = { \n",
    "              'scaler': [Normalizer(), MinMaxScaler(), None],\n",
    "              'regressor__max_depth': [4, 6, 8, 10]\n",
    "              }\n",
    "\n",
    "scoring = 'r2'\n",
    "\n",
    "n_splits = 5\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=123457)\n",
    "\n",
    "SearchCV = GridSearchCV(estimator=pipeline,\n",
    "                        param_grid=parameters,\n",
    "                        scoring=scoring, \n",
    "                        cv=cv,\n",
    "                        return_train_score=True,\n",
    "                        verbose=1, \n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=123457, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        Normalizer(copy=True, norm='l2')),\n",
       "                                       ('regressor',\n",
       "                                        DecisionTreeRegressor(criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features=None,\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_samples_leaf=1,\n",
       "                                                              min_samples_split=2,\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              presort=False,\n",
       "                                                              random_state=None,\n",
       "                                                              splitter='best'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=2,\n",
       "             param_grid={'regressor__max_depth': [4, 6, 8, 10],\n",
       "                         'scaler': [Normalizer(copy=True, norm='l2'),\n",
       "                                    MinMaxScaler(copy=True,\n",
       "                                                 feature_range=(0, 1)),\n",
       "                                    None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__max_depth': 6, 'scaler': None}\n",
      "0.7397881198482646\n"
     ]
    }
   ],
   "source": [
    "best_estimator = SearchCV.best_estimator_\n",
    "best_params = SearchCV.best_params_\n",
    "print(best_params)\n",
    "print(SearchCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test score (r2): 0.6378497330816209\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = SearchCV.predict(X_test)\n",
    "test_score = SearchCV.score(X_test, y_test) \n",
    "print(\" test score (\"+scoring+\"):\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt=SearchCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([2.98776255, 2.45326791, 2.11883445, 2.99934769, 3.12775245,\n",
      "       3.29102993, 3.60204725, 3.91453295, 3.7185216 , 3.88194342,\n",
      "       4.3942944 , 4.23350024]), 'std_fit_time': array([0.35927021, 0.13867583, 0.02021315, 0.09293019, 0.04121096,\n",
      "       0.4851518 , 0.13346905, 0.10630174, 0.05567935, 0.25471042,\n",
      "       0.07541504, 0.04308548]), 'mean_score_time': array([0.05380774, 0.03929586, 0.01995215, 0.04327435, 0.04332671,\n",
      "       0.02034225, 0.03928151, 0.03928552, 0.0206841 , 0.04276762,\n",
      "       0.04015465, 0.01844459]), 'std_score_time': array([0.01862724, 0.00381138, 0.0024549 , 0.002232  , 0.003649  ,\n",
      "       0.00225314, 0.0016405 , 0.00227   , 0.00148871, 0.00249717,\n",
      "       0.00215987, 0.00112156]), 'param_regressor__max_depth': masked_array(data=[4, 4, 4, 6, 6, 6, 8, 8, 8, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_scaler': masked_array(data=[Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'regressor__max_depth': 4, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 4, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 4, 'scaler': None}, {'regressor__max_depth': 6, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 6, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 6, 'scaler': None}, {'regressor__max_depth': 8, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 8, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 8, 'scaler': None}, {'regressor__max_depth': 10, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 10, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 10, 'scaler': None}], 'split0_test_score': array([0.20919283, 0.79586015, 0.79585604, 0.34590636, 0.81625591,\n",
      "       0.81201001, 0.41323382, 0.80475848, 0.80466957, 0.48381722,\n",
      "       0.71413238, 0.71016433]), 'split1_test_score': array([0.34167616, 0.64867983, 0.64821724, 0.58217329, 0.71432192,\n",
      "       0.71450465, 0.66741566, 0.70585045, 0.70892294, 0.66922194,\n",
      "       0.7049801 , 0.71672901]), 'split2_test_score': array([0.29031269, 0.5260591 , 0.42710502, 0.44716814, 0.46731821,\n",
      "       0.58489128, 0.50906459, 0.51896687, 0.48484424, 0.47973465,\n",
      "       0.5019719 , 0.55693043]), 'split3_test_score': array([0.2973492 , 0.71556962, 0.71556915, 0.35718824, 0.7681279 ,\n",
      "       0.76841369, 0.54751   , 0.7997705 , 0.80768333, 0.40856797,\n",
      "       0.79322034, 0.80239093]), 'split4_test_score': array([0.29110132, 0.76498295, 0.76457319, 0.72884384, 0.81904905,\n",
      "       0.8191204 , 0.74022436, 0.82417797, 0.82259259, 0.83277608,\n",
      "       0.80798973, 0.79261267]), 'mean_test_score': array([0.28592639, 0.69023048, 0.67026438, 0.49225584, 0.71701483,\n",
      "       0.73978812, 0.57548952, 0.73070497, 0.72574268, 0.57482358,\n",
      "       0.70445892, 0.71576546]), 'std_test_score': array([0.04283139, 0.09598569, 0.13140188, 0.1454326 , 0.13055855,\n",
      "       0.08597815, 0.11585346, 0.11352683, 0.12699471, 0.15518709,\n",
      "       0.10926278, 0.08794333]), 'rank_test_score': array([12,  7,  8, 11,  4,  1,  9,  2,  3, 10,  6,  5], dtype=int32), 'split0_train_score': array([0.30854739, 0.77648534, 0.77650091, 0.63987116, 0.84456064,\n",
      "       0.8447989 , 0.82149079, 0.8913254 , 0.89085244, 0.89330498,\n",
      "       0.93060866, 0.92996889]), 'split1_train_score': array([0.27385193, 0.77505931, 0.77512373, 0.60077224, 0.86868689,\n",
      "       0.86883974, 0.86573896, 0.90209923, 0.90217524, 0.92173139,\n",
      "       0.92550086, 0.92449602]), 'split2_train_score': array([0.29092997, 0.7841497 , 0.78415295, 0.6085624 , 0.84409064,\n",
      "       0.844124  , 0.75467848, 0.89321347, 0.89326226, 0.81902684,\n",
      "       0.92377634, 0.92388264]), 'split3_train_score': array([0.28715527, 0.78859946, 0.78860468, 0.63012587, 0.8569641 ,\n",
      "       0.85706018, 0.79715583, 0.90621695, 0.90615882, 0.86569253,\n",
      "       0.93400835, 0.93403408]), 'split4_train_score': array([0.29178887, 0.75152586, 0.75159519, 0.56626242, 0.84527874,\n",
      "       0.8451825 , 0.79640479, 0.89417313, 0.89441734, 0.919788  ,\n",
      "       0.92519491, 0.92767064]), 'mean_train_score': array([0.29045468, 0.77516394, 0.77519549, 0.60911882, 0.8519162 ,\n",
      "       0.85200106, 0.80709377, 0.89740563, 0.89737322, 0.88390875,\n",
      "       0.92781783, 0.92801046]), 'std_train_score': array([0.01109855, 0.01282009, 0.0127963 , 0.02566573, 0.00965543,\n",
      "       0.00969069, 0.03635082, 0.00573867, 0.00580352, 0.03833446,\n",
      "       0.00386505, 0.00373162])}\n"
     ]
    }
   ],
   "source": [
    "print(r_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parans:\n",
      " [{'regressor__max_depth': 4, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 4, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 4, 'scaler': None}, {'regressor__max_depth': 6, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 6, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 6, 'scaler': None}, {'regressor__max_depth': 8, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 8, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 8, 'scaler': None}, {'regressor__max_depth': 10, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 10, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 10, 'scaler': None}] \n",
      "\n",
      "mean_test_score:\n",
      " [0.28592639 0.69023048 0.67026438 0.49225584 0.71701483 0.73978812\n",
      " 0.57548952 0.73070497 0.72574268 0.57482358 0.70445892 0.71576546] \n",
      "\n",
      "std_test_score:\n",
      " [0.04283139 0.09598569 0.13140188 0.1454326  0.13055855 0.08597815\n",
      " 0.11585346 0.11352683 0.12699471 0.15518709 0.10926278 0.08794333] \n",
      "\n",
      "mean_train_score:\n",
      " [0.29045468 0.77516394 0.77519549 0.60911882 0.8519162  0.85200106\n",
      " 0.80709377 0.89740563 0.89737322 0.88390875 0.92781783 0.92801046] \n",
      "\n",
      "std_train_score:\n",
      " [0.01109855 0.01282009 0.0127963  0.02566573 0.00965543 0.00969069\n",
      " 0.03635082 0.00573867 0.00580352 0.03833446 0.00386505 0.00373162] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('parans:\\n',r_dt['params'],'\\n')\n",
    "print('mean_test_score:\\n',r_dt['mean_test_score'],'\\n')\n",
    "print('std_test_score:\\n',r_dt['std_test_score'],'\\n')\n",
    "print('mean_train_score:\\n',r_dt['mean_train_score'],'\\n')\n",
    "print('std_train_score:\\n',r_dt['std_train_score'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SearchCV_DecisionTree'\n",
    "pickle.dump(SearchCV, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                      ('scaler', Normalizer()),\n",
    "                      ('regressor', RandomForestRegressor())\n",
    "                     ])\n",
    "\n",
    "parameters = {    \n",
    "              'scaler': [Normalizer(), MinMaxScaler(), None],\n",
    "              'regressor__max_depth': [4, 6, 8]\n",
    "              }\n",
    "\n",
    "scoring = 'r2'\n",
    "\n",
    "n_splits = 5\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=123457)\n",
    "\n",
    "SearchCV = GridSearchCV(estimator=pipeline,\n",
    "                        param_grid=parameters,\n",
    "                        scoring=scoring, \n",
    "                        cv=cv,\n",
    "                        return_train_score=True,\n",
    "                        verbose=1, \n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  6.1min finished\n",
      "/Users/iflab/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/iflab/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py:356: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=123457, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        Normalizer(copy=True, norm='l2')),\n",
       "                                       ('regressor',\n",
       "                                        RandomForestRegressor(bootstrap=True,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features='auto',\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_split=None...\n",
       "                                                              n_estimators='warn',\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'regressor__max_depth': [4, 6, 8],\n",
       "                         'scaler': [Normalizer(copy=True, norm='l2'),\n",
       "                                    MinMaxScaler(copy=True,\n",
       "                                                 feature_range=(0, 1)),\n",
       "                                    None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__max_depth': 8, 'scaler': None}\n",
      "0.7587036524239468\n"
     ]
    }
   ],
   "source": [
    "best_estimator = SearchCV.best_estimator_\n",
    "best_params = SearchCV.best_params_\n",
    "print(best_params)\n",
    "print(SearchCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test score (r2): 0.7534544913376432\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = SearchCV.predict(X_test)\n",
    "test_score = SearchCV.score(X_test, y_test) \n",
    "print(\" test score (\"+scoring+\"):\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt=SearchCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([26.10589681, 21.16363716, 21.57030988, 30.45291376, 30.43098078,\n",
      "       30.37619061, 41.06919284, 39.60113235, 34.37029519]), 'std_fit_time': array([1.78813062, 0.5531927 , 0.38874875, 0.66656019, 0.06727203,\n",
      "       0.37085243, 0.97843173, 0.48680535, 6.41417137]), 'mean_score_time': array([0.10879788, 0.10626936, 0.06745949, 0.11311297, 0.11639848,\n",
      "       0.07822523, 0.13526702, 0.13756738, 0.07273145]), 'std_score_time': array([0.00536239, 0.00668117, 0.00723919, 0.01032546, 0.00425384,\n",
      "       0.00688106, 0.00796496, 0.00932761, 0.01892694]), 'param_regressor__max_depth': masked_array(data=[4, 4, 4, 6, 6, 6, 8, 8, 8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_scaler': masked_array(data=[Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'regressor__max_depth': 4, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 4, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 4, 'scaler': None}, {'regressor__max_depth': 6, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 6, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 6, 'scaler': None}, {'regressor__max_depth': 8, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 8, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 8, 'scaler': None}], 'split0_test_score': array([0.21687325, 0.75066767, 0.79508743, 0.44190884, 0.80327297,\n",
      "       0.78236926, 0.46441566, 0.77066392, 0.82182557]), 'split1_test_score': array([0.39693007, 0.72570177, 0.7308718 , 0.58754073, 0.76427542,\n",
      "       0.76518475, 0.70412744, 0.77188574, 0.76714259]), 'split2_test_score': array([0.23664061, 0.49233902, 0.55448324, 0.46664453, 0.50116084,\n",
      "       0.5384471 , 0.57785549, 0.56808144, 0.5857037 ]), 'split3_test_score': array([0.35111668, 0.73522996, 0.72930681, 0.56461161, 0.74874116,\n",
      "       0.76590265, 0.64735383, 0.76909674, 0.78775344]), 'split4_test_score': array([0.23154204, 0.65111527, 0.75712262, 0.69233652, 0.82429741,\n",
      "       0.81984177, 0.83942056, 0.8614704 , 0.83109209]), 'mean_test_score': array([0.28662063, 0.67101106, 0.71337462, 0.55060827, 0.72834983,\n",
      "       0.7343493 , 0.6466343 , 0.74823976, 0.75870365]), 'std_test_score': array([0.0731086 , 0.09568673, 0.08294244, 0.09001382, 0.11673942,\n",
      "       0.09993877, 0.12522519, 0.09672122, 0.08951917]), 'rank_test_score': array([9, 6, 5, 8, 4, 3, 7, 2, 1], dtype=int32), 'split0_train_score': array([0.28273186, 0.78200317, 0.79134547, 0.65999197, 0.85290253,\n",
      "       0.84343226, 0.81226751, 0.87351411, 0.87969602]), 'split1_train_score': array([0.36948948, 0.78953958, 0.7799089 , 0.63579999, 0.87308421,\n",
      "       0.8694723 , 0.83279664, 0.89085121, 0.90302299]), 'split2_train_score': array([0.34446032, 0.79128411, 0.79441907, 0.65008137, 0.85326119,\n",
      "       0.86198546, 0.818867  , 0.89277727, 0.89204778]), 'split3_train_score': array([0.39803133, 0.78875236, 0.7961157 , 0.67479316, 0.8614242 ,\n",
      "       0.85170386, 0.82274526, 0.89590762, 0.88532499]), 'split4_train_score': array([0.28165752, 0.7388385 , 0.76735732, 0.6010597 , 0.83399903,\n",
      "       0.84721262, 0.78040896, 0.89258992, 0.89338317]), 'mean_train_score': array([0.3352741 , 0.77808354, 0.78582929, 0.64434524, 0.85493423,\n",
      "       0.8547613 , 0.81341707, 0.88912803, 0.89069499]), 'std_train_score': array([0.0465381 , 0.01987388, 0.01082855, 0.02510561, 0.01278085,\n",
      "       0.00962579, 0.01779405, 0.00797531, 0.0078848 ])}\n"
     ]
    }
   ],
   "source": [
    "print(r_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parans:\n",
      " [{'regressor__max_depth': 4, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 4, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 4, 'scaler': None}, {'regressor__max_depth': 6, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 6, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 6, 'scaler': None}, {'regressor__max_depth': 8, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__max_depth': 8, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__max_depth': 8, 'scaler': None}] \n",
      "\n",
      "mean_test_score:\n",
      " [0.28662063 0.67101106 0.71337462 0.55060827 0.72834983 0.7343493\n",
      " 0.6466343  0.74823976 0.75870365] \n",
      "\n",
      "std_test_score:\n",
      " [0.0731086  0.09568673 0.08294244 0.09001382 0.11673942 0.09993877\n",
      " 0.12522519 0.09672122 0.08951917] \n",
      "\n",
      "mean_train_score:\n",
      " [0.3352741  0.77808354 0.78582929 0.64434524 0.85493423 0.8547613\n",
      " 0.81341707 0.88912803 0.89069499] \n",
      "\n",
      "std_train_score:\n",
      " [0.0465381  0.01987388 0.01082855 0.02510561 0.01278085 0.00962579\n",
      " 0.01779405 0.00797531 0.0078848 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('parans:\\n',r_dt['params'],'\\n')\n",
    "print('mean_test_score:\\n',r_dt['mean_test_score'],'\\n')\n",
    "print('std_test_score:\\n',r_dt['std_test_score'],'\\n')\n",
    "print('mean_train_score:\\n',r_dt['mean_train_score'],'\\n')\n",
    "print('std_train_score:\\n',r_dt['std_train_score'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SearchCV_RandomForest'\n",
    "pickle.dump(SearchCV, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                    ('scaler', Normalizer()),                 \n",
    "                    ('regressor', AdaBoostRegressor())\n",
    "                     ])\n",
    "\n",
    "parameters = {    \n",
    "                'scaler': [ Normalizer(), MinMaxScaler(), None],          \n",
    "                'regressor__n_estimators': [100, 200, 300, 400],\n",
    "                'regressor__learning_rate': [0.1, 0.01]\n",
    "              }\n",
    "\n",
    "scoring = 'r2'\n",
    "\n",
    "n_splits = 3\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=123457)\n",
    "\n",
    "SearchCV = GridSearchCV(estimator=pipeline,\n",
    "                        param_grid=parameters,\n",
    "                        scoring=scoring, \n",
    "                        cv=cv,\n",
    "                        return_train_score=True,\n",
    "                        verbose=1, \n",
    "                        n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 60.5min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 139.9min finished\n",
      "/Users/iflab/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=123457, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        Normalizer(copy=True, norm='l2')),\n",
       "                                       ('regressor',\n",
       "                                        AdaBoostRegressor(base_estimator=None,\n",
       "                                                          learning_rate=1.0,\n",
       "                                                          loss='linear',\n",
       "                                                          n_estimators=50,\n",
       "                                                          random_state=None))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'regressor__learning_rate': [0.1, 0.01],\n",
       "                         'regressor__n_estimators': [100, 200, 300, 400],\n",
       "                         'scaler': [Normalizer(copy=True, norm='l2'),\n",
       "                                    MinMaxScaler(copy=True,\n",
       "                                                 feature_range=(0, 1)),\n",
       "                                    None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__learning_rate': 0.01, 'regressor__n_estimators': 100, 'scaler': None}\n",
      "0.648895431328589\n"
     ]
    }
   ],
   "source": [
    "best_estimator = SearchCV.best_estimator_\n",
    "best_params = SearchCV.best_params_\n",
    "print(best_params)\n",
    "print(SearchCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test score (r2): 0.610495783989793\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = SearchCV.predict(X_test)\n",
    "test_score = SearchCV.score(X_test, y_test) \n",
    "print(\" test score (\"+scoring+\"):\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt=SearchCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([221.58707444, 199.30616713, 193.69772037, 329.33251166,\n",
      "       345.96807472, 323.63848646, 275.22223306, 421.54165999,\n",
      "       433.16904283, 255.07317702, 549.87216051, 532.35666958,\n",
      "       227.12427028, 205.87080264, 207.78822764, 446.28628238,\n",
      "       410.82063158, 416.25650104, 672.7289513 , 634.06869499,\n",
      "       624.47824907, 887.03042936, 820.32915934, 652.40309111]), 'std_fit_time': array([ 21.17907162,  10.11238873,   2.13599463, 124.42082974,\n",
      "        13.33107387,  45.12661063,  76.74651542, 139.19693934,\n",
      "       122.77458171,  92.67491094, 177.57516561, 204.19972785,\n",
      "         0.93935486,   0.84017702,   0.90528422,   1.45183278,\n",
      "         3.87313683,   3.29495453,   2.65482809,   0.92265405,\n",
      "        13.21896925,   1.53815349,   1.81429779, 121.14070745]), 'mean_score_time': array([ 3.48575425,  3.6734612 ,  3.61869438,  6.23136727,  7.43980018,\n",
      "        6.91250165,  5.20224722,  9.08342608,  8.85476295,  4.48959057,\n",
      "       11.917418  , 11.10935911,  3.63138628,  3.60758193,  3.47746412,\n",
      "        7.54200641,  7.35755428,  7.19852829, 14.63849497, 10.98625263,\n",
      "       10.63294538, 15.59775432, 14.45042872,  9.64727664]), 'std_score_time': array([0.40561516, 0.03970549, 0.06118664, 2.62132316, 0.42436311,\n",
      "       1.00006808, 1.64998223, 3.1811912 , 2.7146699 , 1.89354675,\n",
      "       4.14213797, 4.55142708, 0.02556337, 0.01569896, 0.02028781,\n",
      "       0.08712665, 0.20714852, 0.12262042, 0.96571778, 0.25057588,\n",
      "       0.0607042 , 0.40944138, 0.25006729, 2.09923662]), 'param_regressor__learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__n_estimators': masked_array(data=[100, 100, 100, 200, 200, 200, 300, 300, 300, 400, 400,\n",
      "                   400, 100, 100, 100, 200, 200, 200, 300, 300, 300, 400,\n",
      "                   400, 400],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_scaler': masked_array(data=[Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'regressor__learning_rate': 0.1, 'regressor__n_estimators': 100, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 100, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 100, 'scaler': None}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 200, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 200, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 200, 'scaler': None}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 300, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 300, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 300, 'scaler': None}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 400, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 400, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 400, 'scaler': None}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 100, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 100, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 100, 'scaler': None}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 200, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 200, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 200, 'scaler': None}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 300, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 300, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 300, 'scaler': None}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 400, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 400, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 400, 'scaler': None}], 'split0_test_score': array([0.31271094, 0.55166852, 0.54291543, 0.01533178, 0.52170752,\n",
      "       0.54948069, 0.12831472, 0.52470691, 0.53587302, 0.10065479,\n",
      "       0.56163945, 0.53845269, 0.1376938 , 0.70863904, 0.71141444,\n",
      "       0.17281409, 0.6919972 , 0.69222476, 0.18279166, 0.69192546,\n",
      "       0.64923214, 0.23589843, 0.62054337, 0.62590654]), 'split1_test_score': array([-0.01390341,  0.49823001,  0.49828662, -0.06286368,  0.46978686,\n",
      "        0.4534184 , -0.06739565,  0.46544123,  0.46692078,  0.04073313,\n",
      "        0.45489257,  0.43559101,  0.14267112,  0.56736462,  0.56331604,\n",
      "        0.14106872,  0.56372895,  0.56015126,  0.17567483,  0.55296064,\n",
      "        0.54938872,  0.13708945,  0.54072311,  0.53965403]), 'split2_test_score': array([0.22182532, 0.51139347, 0.5007791 , 0.13708571, 0.46238746,\n",
      "       0.46054659, 0.11731771, 0.4625419 , 0.47258757, 0.2468731 ,\n",
      "       0.4720031 , 0.46150585, 0.18600181, 0.65005277, 0.67195581,\n",
      "       0.24434438, 0.62765489, 0.626111  , 0.26792374, 0.53542313,\n",
      "       0.54841207, 0.30474461, 0.50802755, 0.51813578]), 'mean_test_score': array([0.17354428, 0.52043066, 0.51399371, 0.02985127, 0.48462728,\n",
      "       0.48781523, 0.05941226, 0.48423001, 0.49179379, 0.12942034,\n",
      "       0.49617837, 0.47851652, 0.15545558, 0.64201881, 0.64889543,\n",
      "       0.18607573, 0.62779368, 0.62616234, 0.20879675, 0.59343641,\n",
      "       0.58234431, 0.22591083, 0.55643134, 0.56123212]), 'std_test_score': array([0.13764091, 0.02273282, 0.02047604, 0.08227212, 0.02639313,\n",
      "       0.04370106, 0.08977906, 0.02864595, 0.03125446, 0.0865795 ,\n",
      "       0.04681208, 0.04368183, 0.02169482, 0.05795414, 0.06262119,\n",
      "       0.04319235, 0.05236539, 0.05391879, 0.04190993, 0.07000933,\n",
      "       0.04729852, 0.06880832, 0.04725825, 0.04656783]), 'rank_test_score': array([20,  9, 10, 24, 14, 13, 23, 15, 12, 22, 11, 16, 21,  2,  1, 19,  3,\n",
      "        4, 18,  5,  6, 17,  8,  7], dtype=int32), 'split0_train_score': array([0.40859571, 0.60675253, 0.59832464, 0.1156955 , 0.58178497,\n",
      "       0.60784448, 0.22517337, 0.58134284, 0.59797417, 0.19928179,\n",
      "       0.62070223, 0.59520164, 0.18971937, 0.76472256, 0.76350009,\n",
      "       0.26765806, 0.74451923, 0.74490026, 0.33064524, 0.74853889,\n",
      "       0.70462865, 0.3845247 , 0.66726709, 0.67605189]), 'split1_train_score': array([0.30487697, 0.65360295, 0.65220787, 0.28775586, 0.64420041,\n",
      "       0.63341166, 0.27233318, 0.64753724, 0.64395705, 0.34583379,\n",
      "       0.63407721, 0.60859997, 0.27986034, 0.75301265, 0.75163284,\n",
      "       0.29646668, 0.72416249, 0.72853905, 0.36383646, 0.70043163,\n",
      "       0.69424158, 0.38537417, 0.67905006, 0.68557449]), 'split2_train_score': array([0.2512503 , 0.49903784, 0.48665204, 0.17242045, 0.45111929,\n",
      "       0.4472702 , 0.16468576, 0.45170446, 0.46223615, 0.28897579,\n",
      "       0.47288417, 0.45198203, 0.21565614, 0.67779675, 0.68478029,\n",
      "       0.29791337, 0.64176793, 0.6411183 , 0.32631544, 0.53190706,\n",
      "       0.54466905, 0.3582666 , 0.49566059, 0.50736746]), 'mean_train_score': array([0.32157433, 0.58646444, 0.57906152, 0.19195727, 0.55903489,\n",
      "       0.56284211, 0.22073077, 0.56019485, 0.56805579, 0.27803046,\n",
      "       0.57588787, 0.55192788, 0.22841195, 0.73184399, 0.73330441,\n",
      "       0.28734604, 0.70348322, 0.70485253, 0.34026571, 0.66029253,\n",
      "       0.64784642, 0.37605516, 0.61399258, 0.62299794]), 'std_train_score': array([0.06531205, 0.06471115, 0.06894676, 0.07158891, 0.08044979,\n",
      "       0.08238556, 0.04405901, 0.0813349 , 0.07714468, 0.06032812,\n",
      "       0.07303901, 0.07088375, 0.03788915, 0.038515  , 0.03465208,\n",
      "       0.01393402, 0.04442358, 0.04555921, 0.0167605 , 0.09288236,\n",
      "       0.07308055, 0.01258319, 0.08381151, 0.08185547])}\n"
     ]
    }
   ],
   "source": [
    "print(r_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parans:\n",
      " [{'regressor__learning_rate': 0.1, 'regressor__n_estimators': 100, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 100, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 100, 'scaler': None}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 200, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 200, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 200, 'scaler': None}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 300, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 300, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 300, 'scaler': None}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 400, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 400, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 400, 'scaler': None}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 100, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 100, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 100, 'scaler': None}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 200, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 200, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 200, 'scaler': None}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 300, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 300, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 300, 'scaler': None}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 400, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 400, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 400, 'scaler': None}] \n",
      "\n",
      "mean_test_score:\n",
      " [0.17354428 0.52043066 0.51399371 0.02985127 0.48462728 0.48781523\n",
      " 0.05941226 0.48423001 0.49179379 0.12942034 0.49617837 0.47851652\n",
      " 0.15545558 0.64201881 0.64889543 0.18607573 0.62779368 0.62616234\n",
      " 0.20879675 0.59343641 0.58234431 0.22591083 0.55643134 0.56123212] \n",
      "\n",
      "std_test_score:\n",
      " [0.13764091 0.02273282 0.02047604 0.08227212 0.02639313 0.04370106\n",
      " 0.08977906 0.02864595 0.03125446 0.0865795  0.04681208 0.04368183\n",
      " 0.02169482 0.05795414 0.06262119 0.04319235 0.05236539 0.05391879\n",
      " 0.04190993 0.07000933 0.04729852 0.06880832 0.04725825 0.04656783] \n",
      "\n",
      "mean_train_score:\n",
      " [0.32157433 0.58646444 0.57906152 0.19195727 0.55903489 0.56284211\n",
      " 0.22073077 0.56019485 0.56805579 0.27803046 0.57588787 0.55192788\n",
      " 0.22841195 0.73184399 0.73330441 0.28734604 0.70348322 0.70485253\n",
      " 0.34026571 0.66029253 0.64784642 0.37605516 0.61399258 0.62299794] \n",
      "\n",
      "std_train_score:\n",
      " [0.06531205 0.06471115 0.06894676 0.07158891 0.08044979 0.08238556\n",
      " 0.04405901 0.0813349  0.07714468 0.06032812 0.07303901 0.07088375\n",
      " 0.03788915 0.038515   0.03465208 0.01393402 0.04442358 0.04555921\n",
      " 0.0167605  0.09288236 0.07308055 0.01258319 0.08381151 0.08185547] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('parans:\\n',r_dt['params'],'\\n')\n",
    "print('mean_test_score:\\n',r_dt['mean_test_score'],'\\n')\n",
    "print('std_test_score:\\n',r_dt['std_test_score'],'\\n')\n",
    "print('mean_train_score:\\n',r_dt['mean_train_score'],'\\n')\n",
    "print('std_train_score:\\n',r_dt['std_train_score'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SearchCV_AdaBoost'\n",
    "pickle.dump(SearchCV, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                    ('scaler', StandardScaler()),                 \n",
    "                    ('regressor', Lasso())\n",
    "                     ])\n",
    "\n",
    "parameters = {    \n",
    "                'scaler': [StandardScaler(), MinMaxScaler(), None],          \n",
    "                'regressor__normalize': [False, True],\n",
    "                'regressor__alpha': np.logspace(-4, 0, 5)\n",
    "              }\n",
    "\n",
    "scoring = 'r2'\n",
    "\n",
    "n_splits = 5\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=123457)\n",
    "\n",
    "SearchCV = GridSearchCV(estimator=pipeline,\n",
    "                        param_grid=parameters,\n",
    "                        scoring=scoring, \n",
    "                        cv=cv,\n",
    "                        return_train_score=True,\n",
    "                        verbose=1, \n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=123457, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('regressor',\n",
       "                                        Lasso(alpha=1.0, copy_X=True,\n",
       "                                              fit_intercept=True, max_iter=1000,\n",
       "                                              normalize=False, positive=False,\n",
       "                                              precompute=False,\n",
       "                                              random_state=None,\n",
       "                                              selecti...\n",
       "                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'regressor__alpha': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00]),\n",
       "                         'regressor__normalize': [False, True],\n",
       "                         'scaler': [StandardScaler(copy=True, with_mean=True,\n",
       "                                                   with_std=True),\n",
       "                                    MinMaxScaler(copy=True,\n",
       "                                                 feature_range=(0, 1)),\n",
       "                                    None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__alpha': 1.0, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "0.5093228285978368\n"
     ]
    }
   ],
   "source": [
    "best_estimator = SearchCV.best_estimator_\n",
    "best_params = SearchCV.best_params_\n",
    "print(best_params)\n",
    "print(SearchCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test score (r2): 0.5924377219747763\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = SearchCV.predict(X_test)\n",
    "test_score = SearchCV.score(X_test, y_test) \n",
    "print(\" test score (\"+scoring+\"):\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt=SearchCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([21.65586591, 20.65540919, 22.55563045, 14.47856879, 13.80966468,\n",
      "       13.20497952, 19.28855743, 17.67630172, 20.29647403, 11.54968495,\n",
      "       11.11240764, 10.47004194, 16.40492754, 14.74931521, 17.17800217,\n",
      "        7.60365491,  6.94220891,  6.12770348, 13.56931376, 11.46197329,\n",
      "       13.33061991,  3.6578475 ,  2.66451159,  2.18678279, 10.4548769 ,\n",
      "        6.82462559,  8.30059342,  2.8640378 ,  2.05385656,  1.6019969 ]), 'std_fit_time': array([0.40576291, 0.15794638, 0.38558457, 0.4584532 , 0.24905994,\n",
      "       0.28968038, 0.15356646, 0.18479274, 0.37505222, 0.12447201,\n",
      "       0.12196851, 0.15770066, 0.24278027, 0.40525514, 0.51005581,\n",
      "       0.67013899, 0.78565524, 0.68018711, 0.21283528, 0.30000254,\n",
      "       0.78571796, 0.30442473, 0.04152808, 0.16140819, 0.26760084,\n",
      "       0.50720592, 0.51139786, 0.17285909, 0.04536165, 0.02355806]), 'mean_score_time': array([0.07968197, 0.07758522, 0.01499419, 0.08120117, 0.08780041,\n",
      "       0.01605067, 0.08812709, 0.08130293, 0.01560593, 0.08263583,\n",
      "       0.08840499, 0.01458673, 0.08568921, 0.08866754, 0.01576843,\n",
      "       0.08346105, 0.08083577, 0.01777439, 0.0841464 , 0.08453674,\n",
      "       0.01663027, 0.07042069, 0.07281089, 0.01394782, 0.08424664,\n",
      "       0.08504324, 0.01526566, 0.07931724, 0.06534271, 0.01054702]), 'std_score_time': array([0.00764707, 0.00832029, 0.00201518, 0.00865769, 0.00643982,\n",
      "       0.00259621, 0.00247453, 0.01244788, 0.00162822, 0.00436646,\n",
      "       0.00305124, 0.00162365, 0.00574987, 0.00343904, 0.00378137,\n",
      "       0.01131892, 0.01028113, 0.00485412, 0.00539553, 0.00787644,\n",
      "       0.00132468, 0.01032259, 0.01127971, 0.00274721, 0.00859406,\n",
      "       0.00936466, 0.00310473, 0.00808854, 0.00807212, 0.00347613]), 'param_regressor__alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001,\n",
      "                   0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__normalize': masked_array(data=[False, False, False, True, True, True, False, False,\n",
      "                   False, True, True, True, False, False, False, True,\n",
      "                   True, True, False, False, False, True, True, True,\n",
      "                   False, False, False, True, True, True],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_scaler': masked_array(data=[StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'regressor__alpha': 0.0001, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.0001, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.0001, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 0.0001, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.0001, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.0001, 'regressor__normalize': True, 'scaler': None}, {'regressor__alpha': 0.001, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.001, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.001, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 0.001, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.001, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.001, 'regressor__normalize': True, 'scaler': None}, {'regressor__alpha': 0.01, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.01, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.01, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 0.01, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.01, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.01, 'regressor__normalize': True, 'scaler': None}, {'regressor__alpha': 0.1, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.1, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.1, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 0.1, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.1, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.1, 'regressor__normalize': True, 'scaler': None}, {'regressor__alpha': 1.0, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 1.0, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 1.0, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 1.0, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 1.0, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 1.0, 'regressor__normalize': True, 'scaler': None}], 'split0_test_score': array([0.48099715, 0.48099718, 0.48099716, 0.4809972 , 0.4809972 ,\n",
      "       0.4809972 , 0.48099715, 0.48099738, 0.48099722, 0.48099763,\n",
      "       0.48099763, 0.48099763, 0.48099716, 0.48099938, 0.4809978 ,\n",
      "       0.48100218, 0.48100218, 0.48100218, 0.48099724, 0.48101931,\n",
      "       0.48100362, 0.48104263, 0.48104263, 0.48104263, 0.48099801,\n",
      "       0.48121453, 0.48106194, 0.48135008, 0.48135008, 0.48135008]), 'split1_test_score': array([0.46480134, 0.46480138, 0.46480134, 0.46480145, 0.46480145,\n",
      "       0.46480145, 0.46480134, 0.46480171, 0.46480134, 0.46480247,\n",
      "       0.46480247, 0.46480247, 0.46480136, 0.464805  , 0.46480135,\n",
      "       0.46481216, 0.46481216, 0.46481216, 0.46480154, 0.46483782,\n",
      "       0.46480137, 0.46489941, 0.46489941, 0.46489941, 0.46480328,\n",
      "       0.46516012, 0.46479809, 0.46548171, 0.46548171, 0.46548171]), 'split2_test_score': array([0.60087834, 0.60087834, 0.60087835, 0.60087841, 0.60087841,\n",
      "       0.60087841, 0.60087834, 0.60087835, 0.6008784 , 0.600879  ,\n",
      "       0.600879  , 0.600879  , 0.60087836, 0.60087837, 0.60087887,\n",
      "       0.60088449, 0.60088449, 0.60088449, 0.60087846, 0.6008785 ,\n",
      "       0.60088354, 0.60092753, 0.60092753, 0.60092753, 0.60087948,\n",
      "       0.60087174, 0.60092858, 0.60106495, 0.60106495, 0.60106495]), 'split3_test_score': array([0.49738764, 0.49738765, 0.49738765, 0.49738768, 0.49738768,\n",
      "       0.49738768, 0.49738764, 0.49738773, 0.49738773, 0.49738801,\n",
      "       0.49738801, 0.49738801, 0.49738765, 0.49738851, 0.49738853,\n",
      "       0.49739146, 0.49739146, 0.49739146, 0.49738771, 0.49739624,\n",
      "       0.49739643, 0.49742961, 0.49742961, 0.49742961, 0.49738827,\n",
      "       0.49746855, 0.49747581, 0.4974899 , 0.4974899 , 0.4974899 ]), 'split4_test_score': array([0.50227748, 0.50227744, 0.50227748, 0.50227741, 0.50227741,\n",
      "       0.50227741, 0.50227748, 0.5022771 , 0.50227751, 0.50227679,\n",
      "       0.50227679, 0.50227679, 0.50227747, 0.50227362, 0.5022778 ,\n",
      "       0.50227028, 0.50227028, 0.50227028, 0.50227736, 0.50223882,\n",
      "       0.50228059, 0.50219345, 0.50219345, 0.50219345, 0.50227627,\n",
      "       0.50188507, 0.50230535, 0.50122837, 0.50122837, 0.50122837]), 'mean_test_score': array([0.50926822, 0.50926822, 0.50926822, 0.50926826, 0.50926826,\n",
      "       0.50926826, 0.50926822, 0.50926828, 0.50926826, 0.5092686 ,\n",
      "       0.5092686 , 0.5092686 , 0.50926822, 0.5092688 , 0.5092687 ,\n",
      "       0.50927194, 0.50927194, 0.50927194, 0.50926828, 0.50927396,\n",
      "       0.50927293, 0.50929835, 0.50929835, 0.50929835, 0.50926889,\n",
      "       0.50931983, 0.50931378, 0.50932283, 0.50932283, 0.50932283]), 'std_test_score': array([0.04766334, 0.04766333, 0.04766334, 0.04766334, 0.04766334,\n",
      "       0.04766334, 0.04766334, 0.04766325, 0.04766334, 0.04766333,\n",
      "       0.04766333, 0.04766333, 0.04766334, 0.04766247, 0.04766341,\n",
      "       0.04766311, 0.04766311, 0.04766311, 0.04766334, 0.04765467,\n",
      "       0.04766403, 0.04765896, 0.04765896, 0.04765896, 0.04766331,\n",
      "       0.04757614, 0.04767037, 0.04759548, 0.04759548, 0.04759548]), 'rank_test_score': array([30, 27, 28, 23, 23, 23, 29, 21, 22, 17, 17, 17, 26, 15, 16, 12, 12,\n",
      "       11, 20,  9, 10,  8,  6,  6, 14,  4,  5,  3,  1,  1], dtype=int32), 'split0_train_score': array([0.52399272, 0.52399272, 0.52399272, 0.52399272, 0.52399272,\n",
      "       0.52399272, 0.52399272, 0.52399272, 0.52399272, 0.52399271,\n",
      "       0.52399271, 0.52399271, 0.52399272, 0.52399272, 0.52399272,\n",
      "       0.52399241, 0.52399241, 0.52399241, 0.52399272, 0.52399262,\n",
      "       0.52399266, 0.52398317, 0.52398317, 0.52398317, 0.5239927 ,\n",
      "       0.52398676, 0.52399077, 0.52362477, 0.52362477, 0.52362477]), 'split1_train_score': array([0.52999815, 0.52999815, 0.52999815, 0.52999815, 0.52999815,\n",
      "       0.52999815, 0.52999815, 0.52999815, 0.52999815, 0.52999814,\n",
      "       0.52999814, 0.52999814, 0.52999815, 0.52999815, 0.52999815,\n",
      "       0.52999775, 0.52999775, 0.52999775, 0.52999815, 0.52999805,\n",
      "       0.52999809, 0.52998749, 0.52998749, 0.52998749, 0.52999814,\n",
      "       0.52999207, 0.52999563, 0.5296087 , 0.5296087 , 0.5296087 ]), 'split2_train_score': array([0.4924153 , 0.4924153 , 0.4924153 , 0.4924153 , 0.4924153 ,\n",
      "       0.4924153 , 0.4924153 , 0.4924153 , 0.4924153 , 0.49241529,\n",
      "       0.49241529, 0.49241529, 0.4924153 , 0.4924153 , 0.4924153 ,\n",
      "       0.4924149 , 0.4924149 , 0.4924149 , 0.4924153 , 0.49241518,\n",
      "       0.49241524, 0.49240397, 0.49240397, 0.49240397, 0.49241528,\n",
      "       0.49240737, 0.49241303, 0.49202563, 0.49202563, 0.49202563]), 'split3_train_score': array([0.52007099, 0.52007099, 0.52007099, 0.52007099, 0.52007099,\n",
      "       0.52007099, 0.52007099, 0.52007099, 0.52007099, 0.52007099,\n",
      "       0.52007099, 0.52007099, 0.52007099, 0.52007099, 0.52007099,\n",
      "       0.52007075, 0.52007075, 0.52007075, 0.52007099, 0.52007089,\n",
      "       0.52007094, 0.52006148, 0.52006148, 0.52006148, 0.52007098,\n",
      "       0.52006408, 0.52006908, 0.51970544, 0.51970544, 0.51970544]), 'split4_train_score': array([0.51916575, 0.51916575, 0.51916575, 0.51916575, 0.51916575,\n",
      "       0.51916575, 0.51916575, 0.51916575, 0.51916575, 0.51916574,\n",
      "       0.51916574, 0.51916574, 0.51916575, 0.51916575, 0.51916575,\n",
      "       0.51916539, 0.51916539, 0.51916539, 0.51916575, 0.51916564,\n",
      "       0.51916569, 0.51915482, 0.51915482, 0.51915482, 0.51916574,\n",
      "       0.51915889, 0.51916364, 0.51879099, 0.51879099, 0.51879099]), 'mean_train_score': array([0.51712858, 0.51712858, 0.51712858, 0.51712858, 0.51712858,\n",
      "       0.51712858, 0.51712858, 0.51712858, 0.51712858, 0.51712858,\n",
      "       0.51712858, 0.51712858, 0.51712858, 0.51712858, 0.51712858,\n",
      "       0.51712824, 0.51712824, 0.51712824, 0.51712858, 0.51712848,\n",
      "       0.51712852, 0.51711819, 0.51711819, 0.51711819, 0.51712857,\n",
      "       0.51712183, 0.51712643, 0.51675111, 0.51675111, 0.51675111]), 'std_train_score': array([0.01293288, 0.01293288, 0.01293288, 0.01293288, 0.01293288,\n",
      "       0.01293288, 0.01293288, 0.01293288, 0.01293288, 0.01293288,\n",
      "       0.01293288, 0.01293288, 0.01293288, 0.01293288, 0.01293288,\n",
      "       0.01293289, 0.01293289, 0.01293289, 0.01293288, 0.01293288,\n",
      "       0.01293288, 0.01293329, 0.01293329, 0.01293329, 0.01293288,\n",
      "       0.01293353, 0.01293288, 0.01293679, 0.01293679, 0.01293679])}\n"
     ]
    }
   ],
   "source": [
    "print(r_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parans:\n",
      " [{'regressor__alpha': 0.0001, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.0001, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.0001, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 0.0001, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.0001, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.0001, 'regressor__normalize': True, 'scaler': None}, {'regressor__alpha': 0.001, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.001, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.001, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 0.001, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.001, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.001, 'regressor__normalize': True, 'scaler': None}, {'regressor__alpha': 0.01, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.01, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.01, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 0.01, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.01, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.01, 'regressor__normalize': True, 'scaler': None}, {'regressor__alpha': 0.1, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.1, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.1, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 0.1, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 0.1, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 0.1, 'regressor__normalize': True, 'scaler': None}, {'regressor__alpha': 1.0, 'regressor__normalize': False, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 1.0, 'regressor__normalize': False, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 1.0, 'regressor__normalize': False, 'scaler': None}, {'regressor__alpha': 1.0, 'regressor__normalize': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}, {'regressor__alpha': 1.0, 'regressor__normalize': True, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__alpha': 1.0, 'regressor__normalize': True, 'scaler': None}] \n",
      "\n",
      "mean_test_score:\n",
      " [0.50926822 0.50926822 0.50926822 0.50926826 0.50926826 0.50926826\n",
      " 0.50926822 0.50926828 0.50926826 0.5092686  0.5092686  0.5092686\n",
      " 0.50926822 0.5092688  0.5092687  0.50927194 0.50927194 0.50927194\n",
      " 0.50926828 0.50927396 0.50927293 0.50929835 0.50929835 0.50929835\n",
      " 0.50926889 0.50931983 0.50931378 0.50932283 0.50932283 0.50932283] \n",
      "\n",
      "std_test_score:\n",
      " [0.04766334 0.04766333 0.04766334 0.04766334 0.04766334 0.04766334\n",
      " 0.04766334 0.04766325 0.04766334 0.04766333 0.04766333 0.04766333\n",
      " 0.04766334 0.04766247 0.04766341 0.04766311 0.04766311 0.04766311\n",
      " 0.04766334 0.04765467 0.04766403 0.04765896 0.04765896 0.04765896\n",
      " 0.04766331 0.04757614 0.04767037 0.04759548 0.04759548 0.04759548] \n",
      "\n",
      "mean_train_score:\n",
      " [0.51712858 0.51712858 0.51712858 0.51712858 0.51712858 0.51712858\n",
      " 0.51712858 0.51712858 0.51712858 0.51712858 0.51712858 0.51712858\n",
      " 0.51712858 0.51712858 0.51712858 0.51712824 0.51712824 0.51712824\n",
      " 0.51712858 0.51712848 0.51712852 0.51711819 0.51711819 0.51711819\n",
      " 0.51712857 0.51712183 0.51712643 0.51675111 0.51675111 0.51675111] \n",
      "\n",
      "std_train_score:\n",
      " [0.01293288 0.01293288 0.01293288 0.01293288 0.01293288 0.01293288\n",
      " 0.01293288 0.01293288 0.01293288 0.01293288 0.01293288 0.01293288\n",
      " 0.01293288 0.01293288 0.01293288 0.01293289 0.01293289 0.01293289\n",
      " 0.01293288 0.01293288 0.01293288 0.01293329 0.01293329 0.01293329\n",
      " 0.01293288 0.01293353 0.01293288 0.01293679 0.01293679 0.01293679] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('parans:\\n',r_dt['params'],'\\n')\n",
    "print('mean_test_score:\\n',r_dt['mean_test_score'],'\\n')\n",
    "print('std_test_score:\\n',r_dt['std_test_score'],'\\n')\n",
    "print('mean_train_score:\\n',r_dt['mean_train_score'],'\\n')\n",
    "print('std_train_score:\\n',r_dt['std_train_score'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SearchCV_Lasso'\n",
    "pickle.dump(SearchCV, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                    ('scaler', Normalizer()),                 \n",
    "                    ('regressor', MLPRegressor())\n",
    "                     ])\n",
    "\n",
    "parameters = {    \n",
    "                'scaler': [Normalizer(), MinMaxScaler(), None],          \n",
    "                'regressor__hidden_layer_sizes': [(32), (64), (128), (64, 64)],\n",
    "                'regressor__activation': ['relu'],\n",
    "                'regressor__solver': ['lbfgs'],\n",
    "                'regressor__alpha': [0.1, 0.01],\n",
    "                'regressor__batch_size': ['auto'], \n",
    "                'regressor__learning_rate': ['constant'],\n",
    "                'regressor__learning_rate_init': [0.01],\n",
    "                'regressor__max_iter': [200]\n",
    "              }\n",
    "\n",
    "scoring = 'r2'\n",
    "\n",
    "n_splits = 3\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=123457)\n",
    "\n",
    "SearchCV = GridSearchCV(estimator=pipeline,\n",
    "                        param_grid=parameters,\n",
    "                        scoring=scoring, \n",
    "                        cv=cv,\n",
    "                        return_train_score=True,\n",
    "                        verbose=1, \n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/iflab/Desktop/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 60.2min finished\n",
      "/Users/iflab/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=123457, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        Normalizer(copy=True, norm='l2')),\n",
       "                                       ('regressor',\n",
       "                                        MLPRegressor(activation='relu',\n",
       "                                                     alpha=0.0001,\n",
       "                                                     batch_size='auto',\n",
       "                                                     beta_1=0.9, beta_2=0.999,\n",
       "                                                     early_stopping=False,\n",
       "                                                     epsilon=1e-08,\n",
       "                                                     hidden_layer_sizes=(100,),\n",
       "                                                     learning_r...\n",
       "                         'regressor__hidden_layer_sizes': [32, 64, 128,\n",
       "                                                           (64, 64)],\n",
       "                         'regressor__learning_rate': ['constant'],\n",
       "                         'regressor__learning_rate_init': [0.01],\n",
       "                         'regressor__max_iter': [200],\n",
       "                         'regressor__solver': ['lbfgs'],\n",
       "                         'scaler': [Normalizer(copy=True, norm='l2'),\n",
       "                                    MinMaxScaler(copy=True,\n",
       "                                                 feature_range=(0, 1)),\n",
       "                                    None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}\n",
      "0.5473576139719951\n"
     ]
    }
   ],
   "source": [
    "best_estimator = SearchCV.best_estimator_\n",
    "best_params = SearchCV.best_params_\n",
    "print(best_params)\n",
    "print(SearchCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test score (r2): 0.6032325083454158\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = SearchCV.predict(X_test)\n",
    "test_score = SearchCV.score(X_test, y_test) \n",
    "print(\" test score (\"+scoring+\"):\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt=SearchCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 65.33528789,  65.31971184,  55.28994592, 147.09206899,\n",
      "       146.09891454, 148.17036438, 282.5468878 , 280.83875394,\n",
      "       288.30925306, 306.82461214, 301.55317465, 254.28775358,\n",
      "        63.58463073,  63.74197229,  62.61407272, 145.60055971,\n",
      "       144.00814017, 132.34722765, 326.26563295, 288.12685712,\n",
      "       245.33574494, 306.08483934, 303.30921006, 245.80762434]), 'std_fit_time': array([ 0.48704783,  0.987063  , 15.43473104,  0.48796178,  0.69868957,\n",
      "        0.88440977,  2.12793512,  0.98788218,  3.19182219,  2.08922381,\n",
      "        0.16016405, 89.08992204,  0.48152097,  1.00530483,  4.89648046,\n",
      "        1.01395647,  2.07950817, 35.56093476,  0.50610444, 11.74386737,\n",
      "       42.71606848,  0.78840554,  1.65534025, 37.5515289 ]), 'mean_score_time': array([0.14431135, 0.15273873, 0.09388574, 0.20579958, 0.20918218,\n",
      "       0.15705991, 0.38428156, 0.41411829, 0.34785565, 0.40169772,\n",
      "       0.41326165, 0.33122786, 0.15415533, 0.1519533 , 0.09094628,\n",
      "       0.21378398, 0.21756784, 0.21474465, 0.39257709, 0.39296269,\n",
      "       0.34473809, 0.41906468, 0.40668257, 0.20737998]), 'std_score_time': array([0.00991338, 0.0080548 , 0.00408081, 0.00288462, 0.00251648,\n",
      "       0.00512176, 0.0197432 , 0.01414064, 0.00551152, 0.01089726,\n",
      "       0.01967702, 0.00291781, 0.01240627, 0.00491687, 0.00411186,\n",
      "       0.01322614, 0.00846003, 0.06308224, 0.00782539, 0.01553307,\n",
      "       0.01498505, 0.00872562, 0.01765012, 0.04357069]), 'param_regressor__activation': masked_array(data=['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
      "                   'relu', 'relu', 'relu'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__alpha': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__batch_size': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__hidden_layer_sizes': masked_array(data=[32, 32, 32, 64, 64, 64, 128, 128, 128, (64, 64),\n",
      "                   (64, 64), (64, 64), 32, 32, 32, 64, 64, 64, 128, 128,\n",
      "                   128, (64, 64), (64, 64), (64, 64)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__learning_rate': masked_array(data=['constant', 'constant', 'constant', 'constant',\n",
      "                   'constant', 'constant', 'constant', 'constant',\n",
      "                   'constant', 'constant', 'constant', 'constant',\n",
      "                   'constant', 'constant', 'constant', 'constant',\n",
      "                   'constant', 'constant', 'constant', 'constant',\n",
      "                   'constant', 'constant', 'constant', 'constant'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__learning_rate_init': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__max_iter': masked_array(data=[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
      "                   200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
      "                   200, 200],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__solver': masked_array(data=['lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
      "                   'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
      "                   'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
      "                   'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_scaler': masked_array(data=[Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}], 'split0_test_score': array([0.02922771, 0.39495601, 0.48071827, 0.03275347, 0.39618196,\n",
      "       0.5153712 , 0.0296631 , 0.34707237, 0.4593209 , 0.02841313,\n",
      "       0.31381222, 0.49753041, 0.03067553, 0.34820759, 0.52489701,\n",
      "       0.03005045, 0.38705079, 0.51023752, 0.02946176, 0.37224964,\n",
      "       0.51700368, 0.0290715 , 0.41149857, 0.44471594]), 'split1_test_score': array([0.02608536, 0.54896425, 0.58549011, 0.02375526, 0.48358554,\n",
      "       0.60901484, 0.02690157, 0.53146333, 0.58289211, 0.02480162,\n",
      "       0.5620165 , 0.59513454, 0.02494891, 0.54131229, 0.57597136,\n",
      "       0.02386034, 0.44701707, 0.55415547, 0.02496696, 0.45561358,\n",
      "       0.59464561, 0.02504267, 0.21914345, 0.09501252]), 'split2_test_score': array([0.02698511, 0.44936788, 0.49428344, 0.02866991, 0.45732425,\n",
      "       0.5176868 , 0.02725008, 0.4565697 , 0.48821668, 0.0274642 ,\n",
      "       0.39502619, 0.00094434, 0.0322302 , 0.38132019, 0.49122483,\n",
      "       0.02758972, 0.43633599, 0.50125044, 0.02641477, 0.4236519 ,\n",
      "       0.46284348, 0.02876589, 0.38912656, 0.49521883]), 'mean_test_score': array([0.02743273, 0.46442938, 0.52016394, 0.02839288, 0.44569725,\n",
      "       0.54735761, 0.02793825, 0.44503513, 0.51014323, 0.02689298,\n",
      "       0.4236183 , 0.36453643, 0.02928488, 0.42361336, 0.53069773,\n",
      "       0.02716683, 0.42346795, 0.52188114, 0.02694783, 0.4171717 ,\n",
      "       0.52483092, 0.02762668, 0.33992286, 0.34498243]), 'std_test_score': array([0.00132133, 0.06376922, 0.04652336, 0.00367872, 0.03661727,\n",
      "       0.04360849, 0.00122792, 0.07571786, 0.05277651, 0.00152872,\n",
      "       0.10332626, 0.26016795, 0.003131  , 0.08431643, 0.03483991,\n",
      "       0.00254473, 0.02611741, 0.02311444, 0.00187331, 0.03434027,\n",
      "       0.05409189, 0.00183143, 0.08589093, 0.17795384]), 'rank_test_score': array([21,  7,  5, 18,  8,  1, 19,  9,  6, 24, 10, 14, 17, 11,  2, 22, 12,\n",
      "        4, 23, 13,  3, 20, 16, 15], dtype=int32), 'split0_train_score': array([0.02796638, 0.54039686, 0.56890839, 0.03025744, 0.5379248 ,\n",
      "       0.54790682, 0.0281603 , 0.51280697, 0.5237133 , 0.02553604,\n",
      "       0.49194675, 0.56439127, 0.02703833, 0.52057875, 0.55900833,\n",
      "       0.02787649, 0.54118648, 0.53579421, 0.02731755, 0.52688639,\n",
      "       0.55900531, 0.02713584, 0.54358989, 0.50703284]), 'split1_train_score': array([0.03060842, 0.47084767, 0.49481424, 0.0317391 , 0.40509139,\n",
      "       0.52028661, 0.03109534, 0.44702924, 0.50456326, 0.03055897,\n",
      "       0.49941671, 0.51685092, 0.02963529, 0.45471531, 0.487833  ,\n",
      "       0.02882306, 0.40137904, 0.44358186, 0.02928652, 0.40918075,\n",
      "       0.50096291, 0.04219849, 0.29752715, 0.08729783]), 'split2_train_score': array([0.02702976, 0.48737988, 0.54937373, 0.02958696, 0.50741035,\n",
      "       0.55638333, 0.02739098, 0.49127874, 0.56722927, 0.02808542,\n",
      "       0.45654746, 0.00195285, 0.03374796, 0.38684299, 0.55632218,\n",
      "       0.02792043, 0.49399972, 0.54526253, 0.02771476, 0.47022115,\n",
      "       0.54660623, 0.02868746, 0.42446953, 0.5433681 ]), 'mean_train_score': array([0.02853486, 0.49954147, 0.53769879, 0.03052783, 0.48347552,\n",
      "       0.54152559, 0.02888221, 0.48370498, 0.53183527, 0.02806015,\n",
      "       0.48263697, 0.36106501, 0.03014052, 0.45404568, 0.53438784,\n",
      "       0.02820666, 0.47885508, 0.50821287, 0.02810628, 0.46876276,\n",
      "       0.53552482, 0.03267393, 0.42186219, 0.37923292]), 'std_train_score': array([0.00151527, 0.02966705, 0.03135511, 0.00089917, 0.05680866,\n",
      "       0.01541176, 0.00159613, 0.02738246, 0.02621999, 0.00205068,\n",
      "       0.01869843, 0.25467127, 0.00276239, 0.05459945, 0.0329375 ,\n",
      "       0.00043623, 0.05807208, 0.0458642 , 0.00085017, 0.04806419,\n",
      "       0.02495768, 0.0067646 , 0.10047161, 0.20696157])}\n"
     ]
    }
   ],
   "source": [
    "print(r_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parans:\n",
      " [{'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.1, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 32, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 64, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': 128, 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__activation': 'relu', 'regressor__alpha': 0.01, 'regressor__batch_size': 'auto', 'regressor__hidden_layer_sizes': (64, 64), 'regressor__learning_rate': 'constant', 'regressor__learning_rate_init': 0.01, 'regressor__max_iter': 200, 'regressor__solver': 'lbfgs', 'scaler': None}] \n",
      "\n",
      "mean_test_score:\n",
      " [0.02743273 0.46442938 0.52016394 0.02839288 0.44569725 0.54735761\n",
      " 0.02793825 0.44503513 0.51014323 0.02689298 0.4236183  0.36453643\n",
      " 0.02928488 0.42361336 0.53069773 0.02716683 0.42346795 0.52188114\n",
      " 0.02694783 0.4171717  0.52483092 0.02762668 0.33992286 0.34498243] \n",
      "\n",
      "std_test_score:\n",
      " [0.00132133 0.06376922 0.04652336 0.00367872 0.03661727 0.04360849\n",
      " 0.00122792 0.07571786 0.05277651 0.00152872 0.10332626 0.26016795\n",
      " 0.003131   0.08431643 0.03483991 0.00254473 0.02611741 0.02311444\n",
      " 0.00187331 0.03434027 0.05409189 0.00183143 0.08589093 0.17795384] \n",
      "\n",
      "mean_train_score:\n",
      " [0.02853486 0.49954147 0.53769879 0.03052783 0.48347552 0.54152559\n",
      " 0.02888221 0.48370498 0.53183527 0.02806015 0.48263697 0.36106501\n",
      " 0.03014052 0.45404568 0.53438784 0.02820666 0.47885508 0.50821287\n",
      " 0.02810628 0.46876276 0.53552482 0.03267393 0.42186219 0.37923292] \n",
      "\n",
      "std_train_score:\n",
      " [0.00151527 0.02966705 0.03135511 0.00089917 0.05680866 0.01541176\n",
      " 0.00159613 0.02738246 0.02621999 0.00205068 0.01869843 0.25467127\n",
      " 0.00276239 0.05459945 0.0329375  0.00043623 0.05807208 0.0458642\n",
      " 0.00085017 0.04806419 0.02495768 0.0067646  0.10047161 0.20696157] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('parans:\\n',r_dt['params'],'\\n')\n",
    "print('mean_test_score:\\n',r_dt['mean_test_score'],'\\n')\n",
    "print('std_test_score:\\n',r_dt['std_test_score'],'\\n')\n",
    "print('mean_train_score:\\n',r_dt['mean_train_score'],'\\n')\n",
    "print('std_train_score:\\n',r_dt['std_train_score'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SearchCV_MLP'\n",
    "pickle.dump(SearchCV, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                      ('scaler', Normalizer()),\n",
    "                      ('regressor', xgb.XGBRegressor())\n",
    "                     ])\n",
    "\n",
    "parameters = {    \n",
    "              'scaler': [Normalizer(), MinMaxScaler(), None],\n",
    "              'regressor__learning_rate': [0.1, 0.01],\n",
    "              'regressor__max_depth': [4, 6, 8],\n",
    "              'regressor__min_child_weight': [1, 3],\n",
    "              'regressor__gamma': [0.0, 0.1, 0.2],\n",
    "              'regressor__colsample_bytree': [0.3, 0.5, 0.7, 1]\n",
    "              }\n",
    "\n",
    "scoring = 'r2'\n",
    "\n",
    "n_splits = 3\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=123457)\n",
    "\n",
    "SearchCV = GridSearchCV(estimator=pipeline,\n",
    "                        param_grid=parameters,\n",
    "                        scoring=scoring, \n",
    "                        cv=cv,\n",
    "                        return_train_score=True,\n",
    "                        verbose=1, \n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/iflab/Desktop/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 81.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 201.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 402.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 736.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed: 779.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:46:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=123457, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        Normalizer(copy=True, norm='l2')),\n",
       "                                       ('regressor',\n",
       "                                        XGBRegressor(base_score=0.5,\n",
       "                                                     booster='gbtree',\n",
       "                                                     colsample_bylevel=1,\n",
       "                                                     colsample_bynode=1,\n",
       "                                                     colsample_bytree=1,\n",
       "                                                     gamma=0,\n",
       "                                                     importance_type='gain',\n",
       "                                                     learning_rate=0.1,\n",
       "                                                     max_d...\n",
       "             param_grid={'regressor__colsample_bytree': [0.3, 0.5, 0.7, 1],\n",
       "                         'regressor__gamma': [0.0, 0.1, 0.2],\n",
       "                         'regressor__learning_rate': [0.1, 0.01],\n",
       "                         'regressor__max_depth': [4, 6, 8],\n",
       "                         'regressor__min_child_weight': [1, 3],\n",
       "                         'scaler': [Normalizer(copy=True, norm='l2'),\n",
       "                                    MinMaxScaler(copy=True,\n",
       "                                                 feature_range=(0, 1)),\n",
       "                                    None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "0.7596090028797056\n"
     ]
    }
   ],
   "source": [
    "best_estimator = SearchCV.best_estimator_\n",
    "best_params = SearchCV.best_params_\n",
    "print(best_params)\n",
    "print(SearchCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test score (r2): 0.7875404099265876\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = SearchCV.predict(X_test)\n",
    "test_score = SearchCV.score(X_test, y_test) \n",
    "print(\" test score (\"+scoring+\"):\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt=SearchCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 85.03228227,  81.2793409 ,  85.88820974, 100.62872179,\n",
      "        95.53083595,  85.61545857, 103.34528248,  98.18514935,\n",
      "        98.26147834, 103.58297515,  97.85068162,  98.237173  ,\n",
      "       125.90761201, 115.21949975, 114.98412387, 123.72440434,\n",
      "       114.89533059, 113.89263741,  84.57555946,  81.81584024,\n",
      "        81.85847012,  85.08403476,  82.00047461,  81.88234011,\n",
      "       104.39531477,  98.39975937,  98.33510669, 103.49279952,\n",
      "        98.68612663,  98.28831959, 124.95710079, 116.36088236,\n",
      "       119.8023862 , 128.31408898, 115.43061757, 114.84433126,\n",
      "        82.52027472,  79.6548907 ,  79.42980353,  81.80671573,\n",
      "        79.77137661,  79.63494611, 100.46102317,  95.63144875,\n",
      "        95.56378961, 100.21471667,  95.68352938,  95.65943352,\n",
      "       122.29075027, 112.72558331, 112.51241104, 121.4545548 ,\n",
      "       112.56627806, 112.71632202,  83.79697529,  82.23155125,\n",
      "        81.29320971,  83.62075456,  80.60865394,  80.51200867,\n",
      "       101.68993743,  97.00126576,  96.71536549, 101.98142902,\n",
      "        97.12808037,  96.9581039 , 123.12424103, 114.50678523,\n",
      "       114.25398246, 123.08490968, 114.23698529, 113.96209733,\n",
      "        83.12834167,  81.14766518,  80.69990524,  83.5049746 ,\n",
      "        81.16813183,  80.99242345, 101.91955765,  96.39759843,\n",
      "        96.97722236, 101.51068695,  96.71921444,  96.16515811,\n",
      "       123.20226844, 114.81031958, 113.83804361, 122.14088329,\n",
      "       113.41363311, 113.08958999,  83.56794564,  81.37750753,\n",
      "        81.4534684 ,  83.41690405,  80.95468895,  81.09780089,\n",
      "       102.41298946,  97.14236466,  97.06106734, 102.07644741,\n",
      "        96.96243779,  96.66681083, 123.38372064, 115.0394423 ,\n",
      "       114.53910112, 123.56548834, 114.62725075, 114.21373558,\n",
      "       100.50605623,  96.98549461,  96.57051492, 101.31804784,\n",
      "        97.16091943,  96.65238301, 128.32237299, 122.11725871,\n",
      "       121.45427473, 128.0127093 , 121.4987584 , 121.29246481,\n",
      "       160.02292625, 148.22898602, 148.00262674, 158.34544309,\n",
      "       147.21829065, 146.64630135, 101.26146277,  97.26482932,\n",
      "        97.42743651, 101.31937194,  97.52962335,  97.0539457 ,\n",
      "       129.36265675, 123.06751259, 122.51618131, 129.1580708 ,\n",
      "       122.41765213, 121.89470744, 161.57644002, 150.4294947 ,\n",
      "       150.23678096, 161.54114167, 149.36074201, 149.27506844,\n",
      "       100.92876395,  97.75745765,  97.22748796, 100.58708318,\n",
      "        97.88693031,  97.90266887, 128.80858366, 121.73505004,\n",
      "       122.00570838, 128.83759363, 122.27737776, 121.87029282,\n",
      "       159.85319742, 148.82890399, 148.16656009, 158.07193828,\n",
      "       148.2447869 , 147.60105332, 101.18796635,  97.866208  ,\n",
      "        97.32304207, 101.65408023,  97.86990873,  97.15806691,\n",
      "       129.60259175, 123.00763464, 122.64936002, 129.54829478,\n",
      "       122.63930217, 122.21682795, 161.49892227, 151.20893415,\n",
      "       150.33831096, 161.58435464, 149.9695096 , 149.83131329,\n",
      "       100.81400601,  97.71714234,  97.081393  , 101.49308221,\n",
      "        97.91286182,  97.51398301, 128.76023563, 122.52109996,\n",
      "       121.83106891, 128.79773561, 127.85986169, 124.77077715,\n",
      "       160.23407435, 149.00561293, 148.32696104, 158.45783305,\n",
      "       147.69009821, 147.30953526, 101.30361867,  98.00953539,\n",
      "        97.00886242, 100.72512754,  98.12865472,  98.08072225,\n",
      "       129.73168715, 124.49120847, 122.87439005, 130.41439382,\n",
      "       122.80915666, 122.39370298, 162.30306665, 150.63387076,\n",
      "       150.11391576, 161.3427457 , 150.1578277 , 149.41262436,\n",
      "       118.69441764, 114.05752627, 114.05257503, 118.52344314,\n",
      "       113.73451702, 113.0613095 , 155.69358238, 147.11066397,\n",
      "       146.39957603, 154.77471908, 146.21040511, 145.54039701,\n",
      "       195.08320347, 181.53753877, 181.28201493, 193.2520167 ,\n",
      "       179.62770295, 179.41771022, 118.55496041, 114.558851  ,\n",
      "       113.60413504, 118.51597714, 115.0296936 , 113.35853545,\n",
      "       155.82712356, 148.34774478, 147.77267893, 156.3030138 ,\n",
      "       148.01577568, 147.4746867 , 197.66971159, 184.91808669,\n",
      "       184.43811639, 197.6044236 , 183.34241231, 183.84802461,\n",
      "       118.14234455, 113.7099305 , 113.92732755, 118.15862783,\n",
      "       113.68993235, 113.79907632, 154.79209479, 146.5857927 ,\n",
      "       146.60150671, 154.44180226, 146.2004865 , 146.24394798,\n",
      "       194.93598564, 181.98858094, 181.28778529, 193.2585872 ,\n",
      "       179.83355792, 179.87925076, 118.60563429, 114.20094228,\n",
      "       113.86979787, 118.8618803 , 113.9673353 , 113.72835795,\n",
      "       156.62063511, 148.22365952, 147.74198945, 155.97836582,\n",
      "       147.85250433, 148.10214416, 197.90260832, 185.87542446,\n",
      "       185.12937204, 198.66755613, 184.81428901, 185.15078227,\n",
      "       119.19070506, 114.45045726, 114.74998061, 119.80947908,\n",
      "       115.26509142, 115.56004707, 156.24886497, 148.0047613 ,\n",
      "       147.61095142, 156.06723277, 147.72613907, 147.31133103,\n",
      "       196.85099101, 183.77720737, 182.94675636, 194.90015022,\n",
      "       181.72832529, 181.18573705, 120.33745869, 115.10060318,\n",
      "       115.39932481, 119.8191971 , 115.33789611, 114.97634999,\n",
      "       157.61033758, 149.61981297, 149.04422824, 157.82834339,\n",
      "       149.04588628, 148.57161117, 199.27889331, 186.31255261,\n",
      "       186.450864  , 198.55657522, 184.99163318, 185.11060055,\n",
      "       145.41914097, 138.50873733, 139.03072397, 144.85816526,\n",
      "       139.09092021, 138.71604927, 195.55346576, 184.04849346,\n",
      "       183.61127861, 195.90763346, 182.66474668, 182.61243852,\n",
      "       248.83520428, 231.35304062, 231.03400866, 248.57771262,\n",
      "       228.61173598, 228.430113  , 145.01131805, 138.43039838,\n",
      "       138.16773907, 144.61571709, 138.95635041, 138.27745024,\n",
      "       195.30086517, 184.98955504, 184.23023725, 195.32184299,\n",
      "       183.83345024, 183.98724039, 251.7766904 , 233.6248312 ,\n",
      "       233.31908091, 250.47685194, 232.82425125, 232.06377943,\n",
      "       144.76756652, 137.74885893, 138.220011  , 144.41704535,\n",
      "       137.87030665, 137.42085703, 194.41295322, 183.05354047,\n",
      "       181.91161132, 194.80837973, 182.68485967, 181.52687605,\n",
      "       247.48501158, 229.79015803, 229.13691115, 246.38598593,\n",
      "       228.02029395, 227.13413898, 144.45933954, 138.20794169,\n",
      "       137.40019623, 144.65155109, 137.67779064, 137.19396257,\n",
      "       194.20316235, 184.43671934, 183.23633909, 194.98785051,\n",
      "       183.24264805, 183.80196285, 249.93514331, 233.64893564,\n",
      "       232.92659871, 250.6428384 , 231.5724833 , 231.18122999,\n",
      "       144.89661765, 137.68653369, 137.99195957, 144.74866605,\n",
      "       137.64255857, 137.20075178, 195.16038291, 182.96825266,\n",
      "       183.23109945, 195.12958924, 182.65174699, 182.04606835,\n",
      "       247.65014434, 230.58000525, 229.82171639, 247.70194674,\n",
      "       228.05458927, 227.48572946, 145.17209236, 138.21404322,\n",
      "       137.56351844, 145.48620868, 138.22193011, 138.20363061,\n",
      "       195.26594559, 184.85790984, 184.62073199, 196.54250034,\n",
      "       184.64099526, 184.69748108, 251.47303065, 234.99924413,\n",
      "       234.42521771, 251.34946458, 233.08593067, 209.70638529]), 'std_fit_time': array([3.42249533e-01, 4.69780021e-01, 7.61692038e+00, 1.73507063e-01,\n",
      "       3.06899085e-01, 6.26122156e+00, 3.88985335e-01, 2.22105506e-01,\n",
      "       8.33342833e-01, 2.21322271e-01, 5.59765425e-01, 3.70609555e-01,\n",
      "       1.85668535e-01, 3.96994449e-01, 5.30131672e-01, 2.44243217e-01,\n",
      "       5.51427084e-02, 2.85666011e-01, 2.92342898e-01, 2.17203804e-01,\n",
      "       2.79614489e-01, 4.46959331e-01, 1.60931066e-02, 2.34325984e-01,\n",
      "       2.65258677e-01, 1.01171382e-01, 5.62612087e-01, 1.76329123e-01,\n",
      "       3.97224713e-01, 2.44538832e-01, 1.16917667e-01, 3.25476326e-01,\n",
      "       4.46019894e-01, 1.56317303e+00, 1.65100553e-01, 4.60698793e-01,\n",
      "       9.77792607e-02, 3.45604313e-01, 2.96880627e-01, 1.33591394e-01,\n",
      "       6.67253285e-02, 3.44943390e-01, 7.83101301e-02, 7.34395528e-02,\n",
      "       3.14176482e-01, 5.01033922e-01, 1.38388049e-01, 4.17211612e-01,\n",
      "       4.24130388e-01, 4.42720540e-01, 6.30894031e-02, 4.58507528e-01,\n",
      "       2.99901790e-01, 1.88935322e-01, 6.87917612e-01, 5.54113381e-02,\n",
      "       1.70141774e-01, 4.32597858e-01, 1.72099448e-02, 1.11515186e-01,\n",
      "       1.62995304e-01, 2.60021369e-01, 4.15066114e-01, 1.41634002e-01,\n",
      "       2.34271766e-01, 2.88569576e-01, 3.54272562e-01, 5.72373879e-02,\n",
      "       3.84209729e-01, 5.15384531e-01, 1.29949965e-01, 2.55160826e-01,\n",
      "       1.69484376e-01, 1.57035200e-01, 2.46601706e-01, 1.28073315e-01,\n",
      "       4.18259204e-02, 3.30163436e-01, 2.62225694e-01, 1.97537015e-01,\n",
      "       2.08277047e-01, 3.06790066e-01, 3.31837757e-01, 5.96482534e-02,\n",
      "       2.40685825e-01, 1.90278452e-01, 5.18418906e-01, 8.04050292e-02,\n",
      "       2.75248304e-01, 3.40797497e-01, 1.85005077e-01, 2.93382460e-01,\n",
      "       5.97650859e-01, 4.52214518e-01, 7.86186938e-02, 1.47330336e-01,\n",
      "       2.98751278e-01, 2.88526966e-01, 2.26107253e-01, 3.52574084e-01,\n",
      "       8.26602502e-02, 2.57617199e-01, 1.80755726e-01, 5.36692962e-01,\n",
      "       2.07342424e-01, 2.60460056e-01, 2.44403424e-01, 1.64022767e-01,\n",
      "       1.71127899e-01, 1.89023524e-01, 4.95027629e-01, 4.09281612e-01,\n",
      "       1.85628304e-01, 4.02219044e-01, 2.25214323e-01, 3.54756695e-01,\n",
      "       4.04279940e-02, 4.56788048e-01, 2.84498146e-01, 1.04601318e-01,\n",
      "       7.62589472e-02, 3.10870044e-01, 2.50372147e-01, 5.48951976e-01,\n",
      "       9.68230434e-02, 4.26160433e-01, 2.00258184e-01, 1.29353922e-01,\n",
      "       2.72561494e-01, 2.47876749e-01, 2.17305292e-01, 7.92469231e-02,\n",
      "       3.85153628e-01, 9.18385139e-02, 1.13059881e-01, 2.10110075e-01,\n",
      "       2.35113506e-01, 1.82848267e-01, 4.13419897e-01, 2.15793932e-01,\n",
      "       6.21906372e-01, 1.63980142e-01, 1.22277212e-01, 3.91182490e-01,\n",
      "       4.66017780e-01, 1.55668913e-01, 2.38478106e-01, 1.84595848e-01,\n",
      "       3.57863440e-01, 3.35681744e-01, 4.08411018e-01, 3.12423642e-01,\n",
      "       4.34663487e-01, 7.38932178e-01, 1.95673982e-01, 4.02199539e-01,\n",
      "       3.62071112e-01, 3.57405141e-01, 2.27789248e-01, 2.05975191e-01,\n",
      "       4.38952709e-01, 5.32323575e-01, 2.59426474e-01, 2.86757674e-01,\n",
      "       1.29410858e-01, 7.22414273e-01, 4.11381683e-01, 1.87731962e-01,\n",
      "       2.46225300e-01, 2.85351102e-01, 2.15219729e-01, 1.37541929e-01,\n",
      "       4.61100978e-01, 1.94170166e-01, 3.37936350e-01, 8.33739776e-02,\n",
      "       4.53742481e-01, 1.31801617e-01, 1.79920447e-01, 4.80896653e-01,\n",
      "       1.01249231e-01, 1.57439030e-01, 1.89257971e-01, 3.48053691e-01,\n",
      "       2.64234040e-01, 4.12530835e-01, 2.95900703e-01, 5.68542894e-01,\n",
      "       3.82041024e-01, 4.40114716e-01, 1.63059116e+00, 3.07386362e+00,\n",
      "       2.69268112e-01, 2.05789905e-01, 7.85000088e-02, 3.68635838e-01,\n",
      "       4.31946013e-01, 3.50054717e-01, 1.89489466e-01, 1.42415497e-01,\n",
      "       1.55161204e-01, 5.01196889e-01, 1.39545407e-01, 3.10156371e-01,\n",
      "       2.45296129e-01, 3.98212197e-01, 2.82827379e-01, 1.84435376e-01,\n",
      "       2.11779366e-01, 1.83566580e-01, 1.35823049e-02, 3.00341602e-01,\n",
      "       2.87087433e-01, 2.32651428e-01, 6.47129154e-01, 5.75436401e-01,\n",
      "       1.56091601e-01, 3.29252486e-01, 3.27317979e-01, 1.24726919e-01,\n",
      "       1.32273556e-01, 1.91726839e-01, 2.01004563e-01, 3.58127401e-02,\n",
      "       3.37712122e-01, 3.42140969e-01, 5.35330257e-01, 4.46223468e-01,\n",
      "       5.29603133e-01, 5.83096383e-01, 3.02390913e-01, 4.88041103e-01,\n",
      "       2.42347959e-01, 3.07396640e-01, 7.39199285e-02, 6.76946625e-01,\n",
      "       4.03758795e-01, 4.19655194e-01, 1.03876611e+00, 3.54136172e-01,\n",
      "       5.64675855e-01, 7.21318700e-01, 5.14611569e-01, 5.08103486e-01,\n",
      "       3.30712013e-01, 8.52337054e-01, 1.35237017e-01, 6.46027926e-01,\n",
      "       2.85283959e-01, 4.12504845e-02, 1.32995736e-01, 6.44539142e-01,\n",
      "       3.81004281e-01, 5.68880440e-01, 1.06181076e-01, 1.37153932e-01,\n",
      "       3.78470956e-01, 3.65487491e-01, 1.65255926e-01, 5.10299777e-01,\n",
      "       2.95152911e-01, 3.39389282e-01, 9.57652124e-02, 6.48470769e-01,\n",
      "       1.05059620e+00, 6.04435669e-01, 2.30576500e-01, 1.92004062e-01,\n",
      "       3.92123209e-01, 5.56702055e-01, 3.72356849e-01, 1.38992812e-01,\n",
      "       2.59045810e-01, 2.07028633e-01, 2.43186590e-01, 2.18968751e-01,\n",
      "       1.93492015e-01, 7.35982187e-01, 4.68715024e-01, 4.96545931e-01,\n",
      "       3.66216435e-01, 8.03084299e-01, 2.97220825e-01, 2.53412843e-01,\n",
      "       6.46906766e-01, 1.84269878e-01, 5.24832401e-02, 1.95324009e-01,\n",
      "       6.72303203e-02, 1.11826275e-01, 2.86023752e-01, 2.66277941e-01,\n",
      "       1.60597213e-01, 9.77209478e-02, 1.14103924e-01, 4.11150597e-01,\n",
      "       3.69274274e-01, 5.23412001e-01, 1.08208156e+00, 1.04253450e-01,\n",
      "       6.24089518e-01, 5.75897385e-01, 3.72489327e-01, 2.26288527e-01,\n",
      "       2.09891057e-01, 2.73888151e-01, 1.34839599e-01, 1.20919743e-01,\n",
      "       3.01351017e-01, 4.78770097e-01, 2.70479611e-01, 2.01274862e-01,\n",
      "       2.16996862e-01, 6.97852835e-01, 1.78418368e-01, 5.72066278e-01,\n",
      "       4.14436503e-01, 1.62643632e-01, 3.23356880e-01, 7.94855137e-01,\n",
      "       3.51591854e-01, 3.67315301e-01, 3.46450483e-01, 2.81323493e-01,\n",
      "       3.36499556e-01, 2.53705553e-01, 1.62801998e-01, 3.00785454e-01,\n",
      "       7.47667391e-02, 3.13686703e-01, 5.43340029e-01, 2.38745032e-01,\n",
      "       7.34588919e-02, 2.77827741e-01, 2.76287490e-01, 1.15876747e-01,\n",
      "       8.85672083e-01, 3.07324184e-01, 8.98000381e-02, 5.73250173e-01,\n",
      "       6.00664396e-01, 4.15662275e-01, 2.62491901e-01, 2.17266118e-01,\n",
      "       6.83960056e-01, 3.05240435e-01, 4.57862861e-01, 2.76155256e-01,\n",
      "       9.56787596e-02, 5.81214420e-01, 5.85370228e-01, 3.77408415e-01,\n",
      "       2.54841213e-01, 4.57697724e-01, 5.00223918e-01, 3.94200612e-01,\n",
      "       7.25517866e-01, 4.91347673e-01, 1.26886466e+00, 7.72768809e-01,\n",
      "       2.94163858e-01, 5.35828531e-01, 2.27349818e-01, 4.48553847e-02,\n",
      "       3.91986296e-01, 5.36130760e-01, 2.06437138e-01, 4.48819362e-01,\n",
      "       2.18195103e-01, 3.96080768e-01, 4.26635356e-01, 3.73616591e-01,\n",
      "       1.01085674e+00, 7.80286230e-01, 2.16690210e-01, 5.21762592e-01,\n",
      "       6.48836894e-01, 1.04832566e+00, 6.07853912e-01, 4.48492719e-01,\n",
      "       5.50183315e-01, 2.94765551e-01, 3.15887271e-01, 9.57174944e-02,\n",
      "       4.10217299e-01, 1.20247904e+00, 7.31942174e-01, 3.48632135e-01,\n",
      "       4.88385528e-01, 4.40728436e-01, 5.20855268e-01, 8.52593251e-01,\n",
      "       7.14618975e-01, 1.47008668e-01, 2.91716214e-01, 5.82348629e-02,\n",
      "       3.91653801e-01, 4.68493269e-01, 4.10683177e-01, 4.17472527e-01,\n",
      "       8.55663781e-02, 5.40610768e-02, 3.64422122e-01, 5.04304904e-01,\n",
      "       1.54348468e-01, 6.22412691e-01, 1.00425939e-01, 5.36292633e-01,\n",
      "       6.98975029e-01, 3.13995471e-01, 1.00511616e-01, 1.32162164e+00,\n",
      "       6.20113200e-01, 6.44666635e-01, 3.52599414e-01, 3.83219636e-01,\n",
      "       1.81992944e-01, 1.30153392e-01, 2.71286086e-01, 1.27947216e-01,\n",
      "       3.03111944e-01, 4.47371724e-01, 4.99268512e-01, 4.17996865e-01,\n",
      "       5.00025923e-01, 3.26941594e-01, 1.30589492e-01, 6.50745102e-01,\n",
      "       8.73976051e-01, 3.59743280e-01, 7.68721368e-01, 1.74353878e+01]), 'mean_score_time': array([0.85852146, 0.643296  , 0.65060902, 0.76461649, 0.63730733,\n",
      "       0.60405111, 1.03353008, 0.85141865, 0.77850302, 0.99807151,\n",
      "       0.81841771, 0.79837092, 1.49798409, 1.0938096 , 1.02658987,\n",
      "       1.43995539, 1.05449295, 1.02538721, 0.78141673, 0.67592867,\n",
      "       0.68918157, 0.78637624, 0.6843036 , 0.643013  , 1.09712029,\n",
      "       0.87542725, 0.88139598, 1.09593383, 0.90381932, 0.84858537,\n",
      "       1.54630725, 1.21925704, 1.23696717, 1.56849639, 1.19179376,\n",
      "       1.13469895, 0.74036733, 0.6380744 , 0.58233587, 0.74169858,\n",
      "       0.6276354 , 0.5874273 , 1.00977421, 0.8043987 , 0.78181847,\n",
      "       1.00276772, 0.80594198, 0.7980237 , 1.42448672, 1.07557344,\n",
      "       1.01449124, 1.40224783, 1.0319589 , 0.98591232, 0.7837077 ,\n",
      "       0.69468538, 0.60473029, 0.78746621, 0.64931393, 0.60819848,\n",
      "       1.05314032, 0.88077895, 0.85197576, 1.02879469, 0.91224702,\n",
      "       0.84128634, 1.4704833 , 1.19120749, 1.14802329, 1.5109636 ,\n",
      "       1.17622201, 1.15373635, 0.74351533, 0.63043642, 0.60212811,\n",
      "       0.74770776, 0.6368409 , 0.59010863, 0.99191435, 0.8357106 ,\n",
      "       0.7912147 , 1.00413664, 0.83342878, 0.78588986, 1.45080821,\n",
      "       1.08017015, 1.02190399, 1.42050807, 1.05042696, 0.98517823,\n",
      "       0.77349234, 0.65263923, 0.62072627, 0.78813712, 0.66913907,\n",
      "       0.61756301, 1.03930298, 0.87384542, 0.84150203, 1.04271571,\n",
      "       0.89656631, 0.84358072, 1.50717028, 1.20307644, 1.13922429,\n",
      "       1.51516978, 1.18007771, 1.15106916, 0.72846103, 0.63189197,\n",
      "       0.58140675, 0.71398203, 0.618167  , 0.59028204, 0.96804937,\n",
      "       0.84776092, 0.80461137, 1.00241661, 0.83164597, 0.78861992,\n",
      "       1.41412544, 1.10212223, 1.03633499, 1.35088833, 1.06394728,\n",
      "       1.02641026, 0.81601826, 0.65992872, 0.61185217, 0.82499735,\n",
      "       0.65665523, 0.61920174, 1.09414673, 0.9086868 , 0.86375944,\n",
      "       1.10458589, 0.90267134, 0.85933391, 1.62053561, 1.30368757,\n",
      "       1.25548561, 1.60472735, 1.28448613, 1.27167821, 0.73967528,\n",
      "       0.62411904, 0.5828677 , 0.72285056, 0.62349025, 0.599262  ,\n",
      "       0.99746076, 0.82723387, 0.81351725, 0.99726534, 0.81824199,\n",
      "       0.78745929, 1.42637992, 1.11661267, 1.06324569, 1.37307231,\n",
      "       1.09860508, 1.02225868, 0.79879554, 0.66019376, 0.62157663,\n",
      "       0.80160697, 0.66488775, 0.62993614, 1.08979154, 0.90183036,\n",
      "       0.88863635, 1.11038756, 0.92390649, 0.85948126, 1.61996404,\n",
      "       1.26815136, 1.25293771, 1.62626664, 1.29596345, 1.20555019,\n",
      "       0.73846706, 0.62968127, 0.58056641, 0.72422846, 0.62493904,\n",
      "       0.57958968, 1.00393836, 0.8249596 , 0.79502233, 0.97309677,\n",
      "       0.83137393, 0.76986225, 1.39404297, 1.08776911, 1.05405426,\n",
      "       1.34466887, 1.06635427, 1.02534803, 0.80701558, 0.65900906,\n",
      "       0.62603633, 0.79962349, 0.66089463, 0.61232861, 1.10040776,\n",
      "       0.91332952, 0.85867747, 1.11013397, 0.92706315, 0.86582001,\n",
      "       1.59858791, 1.27794822, 1.23521725, 1.61656547, 1.28006037,\n",
      "       1.21518962, 0.71767688, 0.63152734, 0.58570838, 0.71826164,\n",
      "       0.62222584, 0.57688944, 0.9396739 , 0.80956372, 0.76659886,\n",
      "       0.93897557, 0.80741731, 0.75224606, 1.29706995, 1.08806944,\n",
      "       1.03325661, 1.27336168, 1.03365898, 0.9843173 , 0.76927455,\n",
      "       0.65787466, 0.59974464, 0.77276818, 0.63362702, 0.59968654,\n",
      "       1.08217152, 0.8941896 , 0.84153573, 1.07536523, 0.88573837,\n",
      "       0.84023269, 1.54325676, 1.24745162, 1.18263125, 1.5698421 ,\n",
      "       1.23079324, 1.2000579 , 0.71666241, 0.63294554, 0.58445438,\n",
      "       0.72001831, 0.61330239, 0.58109609, 0.94034139, 0.83498645,\n",
      "       0.76078002, 0.93476764, 0.80381695, 0.73880172, 1.28418159,\n",
      "       1.06364989, 1.01562262, 1.28459779, 1.03442367, 0.98847167,\n",
      "       0.76711488, 0.65232968, 0.59566887, 0.77712464, 0.64254467,\n",
      "       0.60783696, 1.07320023, 0.88362145, 0.85738611, 1.07193073,\n",
      "       0.90415875, 0.84849246, 1.56063374, 1.24869434, 1.20076323,\n",
      "       1.57317122, 1.24943089, 1.18583028, 0.74521565, 0.63970304,\n",
      "       0.59101129, 0.72925639, 0.61636527, 0.58952689, 0.95367058,\n",
      "       0.81990496, 0.7760059 , 0.96614949, 0.81526963, 0.7633427 ,\n",
      "       1.28178104, 1.09553568, 1.03592404, 1.31075104, 1.00984279,\n",
      "       0.98279897, 0.78171492, 0.65298406, 0.60504866, 0.76808818,\n",
      "       0.65578993, 0.61542726, 1.07003903, 0.9055748 , 0.84965642,\n",
      "       1.09451834, 0.88991841, 0.8468643 , 1.56943003, 1.27177143,\n",
      "       1.21000671, 1.5748771 , 1.2475729 , 1.19369404, 0.71301516,\n",
      "       0.62934049, 0.58426809, 0.71810349, 0.62938317, 0.58185204,\n",
      "       0.94191027, 0.81630421, 0.76558797, 0.94434023, 0.79823764,\n",
      "       0.74175771, 1.26179846, 1.04553405, 1.00470765, 1.2485381 ,\n",
      "       0.97846103, 0.94321497, 0.71839595, 0.62359333, 0.58462588,\n",
      "       0.75064802, 0.62682033, 0.58288781, 0.96134766, 0.84044862,\n",
      "       0.79944038, 0.96098876, 0.83947333, 0.79750689, 1.29064035,\n",
      "       1.11091582, 1.08244713, 1.30411474, 1.12618876, 1.06570705,\n",
      "       0.71257846, 0.62819274, 0.58081158, 0.71064599, 0.61931777,\n",
      "       0.57408373, 0.93054008, 0.81369654, 0.76108376, 0.93000722,\n",
      "       0.78090938, 0.7256697 , 1.25644016, 1.07004396, 1.00574183,\n",
      "       1.24725819, 0.95260803, 0.9195013 , 0.71607304, 0.62142762,\n",
      "       0.57436458, 0.7147793 , 0.61859997, 0.57263994, 0.93981266,\n",
      "       0.82141328, 0.78488922, 0.95296995, 0.83208036, 0.7993772 ,\n",
      "       1.2963407 , 1.12020334, 1.10536631, 1.31901503, 1.11052068,\n",
      "       1.05988431, 0.71193043, 0.64305997, 0.5938189 , 0.72023471,\n",
      "       0.61437933, 0.59061225, 0.94318978, 0.81655963, 0.77059595,\n",
      "       0.93126114, 0.76623321, 0.72337929, 1.2458566 , 1.05472287,\n",
      "       1.00202489, 1.22557863, 0.97036131, 0.928255  , 0.72989599,\n",
      "       0.61982242, 0.57633281, 0.71702917, 0.63056723, 0.57757576,\n",
      "       0.94261734, 0.85116752, 0.78701774, 0.94615571, 0.84774748,\n",
      "       0.82235193, 1.28309504, 1.12870757, 1.08713706, 1.3247474 ,\n",
      "       1.1297996 , 0.74539161]), 'std_score_time': array([0.01913775, 0.02910268, 0.02082235, 0.0180725 , 0.00850671,\n",
      "       0.00241167, 0.01530885, 0.0132337 , 0.0048706 , 0.0093575 ,\n",
      "       0.00999119, 0.00609355, 0.07616872, 0.03070721, 0.01944153,\n",
      "       0.01445792, 0.01671902, 0.01257968, 0.01791566, 0.01729245,\n",
      "       0.02869156, 0.00568636, 0.02840258, 0.02772385, 0.05641453,\n",
      "       0.03182022, 0.04844433, 0.03997064, 0.01459716, 0.00729188,\n",
      "       0.05255021, 0.02510625, 0.02742769, 0.04487175, 0.04017521,\n",
      "       0.0268307 , 0.00883596, 0.01078909, 0.00880465, 0.00850563,\n",
      "       0.01798972, 0.0094586 , 0.04259132, 0.0082004 , 0.02834275,\n",
      "       0.02424754, 0.00329732, 0.03383339, 0.03677852, 0.02637926,\n",
      "       0.01289189, 0.03526393, 0.00719884, 0.01113282, 0.02321456,\n",
      "       0.03222019, 0.00713191, 0.00629496, 0.00931356, 0.01167879,\n",
      "       0.01447419, 0.01641519, 0.00547135, 0.01003834, 0.04782002,\n",
      "       0.01247584, 0.01896488, 0.00558778, 0.01649387, 0.01614462,\n",
      "       0.01603535, 0.03177002, 0.00304344, 0.00384761, 0.01310834,\n",
      "       0.00611224, 0.00502793, 0.00520753, 0.01395562, 0.01501236,\n",
      "       0.00572816, 0.01000539, 0.00627871, 0.00625662, 0.03351193,\n",
      "       0.00483663, 0.00990349, 0.02754719, 0.01492178, 0.01412769,\n",
      "       0.0143383 , 0.01791077, 0.00677074, 0.01323993, 0.00747926,\n",
      "       0.00866218, 0.02204215, 0.00248053, 0.00829336, 0.0326277 ,\n",
      "       0.00661465, 0.00772687, 0.00848961, 0.01715147, 0.00664405,\n",
      "       0.02912412, 0.02100015, 0.00988232, 0.00854831, 0.00244563,\n",
      "       0.00708027, 0.01490206, 0.003251  , 0.0092919 , 0.01205271,\n",
      "       0.02417432, 0.03722597, 0.0533291 , 0.01652905, 0.03497641,\n",
      "       0.03574444, 0.02869191, 0.00760151, 0.00635709, 0.00631925,\n",
      "       0.01430601, 0.0160074 , 0.00746969, 0.0088678 , 0.01929591,\n",
      "       0.00528572, 0.00680732, 0.00777437, 0.00720277, 0.01965551,\n",
      "       0.0286558 , 0.01828537, 0.00665452, 0.01754506, 0.03982083,\n",
      "       0.00922621, 0.01484128, 0.0138348 , 0.02715867, 0.00422608,\n",
      "       0.0052631 , 0.0021673 , 0.00691414, 0.00329273, 0.02015347,\n",
      "       0.01279712, 0.00166584, 0.03134898, 0.02090411, 0.00733072,\n",
      "       0.01053953, 0.03812558, 0.01687475, 0.03051603, 0.02375006,\n",
      "       0.00873035, 0.00696316, 0.00143617, 0.00964602, 0.00251263,\n",
      "       0.00949558, 0.01256152, 0.02284066, 0.01266823, 0.00277642,\n",
      "       0.02157879, 0.01875665, 0.01738541, 0.0181808 , 0.00483015,\n",
      "       0.02346454, 0.05130702, 0.00417918, 0.02783466, 0.02202137,\n",
      "       0.01711975, 0.01786822, 0.01103887, 0.00813312, 0.0049773 ,\n",
      "       0.01045532, 0.00840591, 0.01266621, 0.01055704, 0.00820629,\n",
      "       0.01880174, 0.0043027 , 0.01360267, 0.00403616, 0.01992566,\n",
      "       0.01098104, 0.00368039, 0.00193944, 0.00938731, 0.00849871,\n",
      "       0.00684648, 0.01042022, 0.00337711, 0.00484572, 0.00830771,\n",
      "       0.02051813, 0.00211512, 0.02130805, 0.01846251, 0.02062557,\n",
      "       0.00943641, 0.0359434 , 0.01235773, 0.03923734, 0.03439128,\n",
      "       0.011052  , 0.00356462, 0.00635999, 0.00307373, 0.00357038,\n",
      "       0.01878459, 0.00414292, 0.00323939, 0.01231678, 0.01004714,\n",
      "       0.00397973, 0.01037886, 0.00486058, 0.01408618, 0.02852124,\n",
      "       0.01196026, 0.00177734, 0.02022937, 0.02271871, 0.00598484,\n",
      "       0.00746948, 0.0023753 , 0.00749178, 0.02133888, 0.00691521,\n",
      "       0.01560022, 0.00982468, 0.00497544, 0.00567444, 0.01858732,\n",
      "       0.00551001, 0.00363982, 0.02394013, 0.0086747 , 0.01413749,\n",
      "       0.0158308 , 0.02155373, 0.00578804, 0.00938759, 0.00381927,\n",
      "       0.00902186, 0.00577176, 0.00927287, 0.01039616, 0.01997492,\n",
      "       0.00568519, 0.00270061, 0.017216  , 0.01079176, 0.02864168,\n",
      "       0.00484476, 0.02521054, 0.01675138, 0.00591325, 0.01533972,\n",
      "       0.00665521, 0.00915357, 0.00369701, 0.00865231, 0.00237333,\n",
      "       0.0114972 , 0.02022023, 0.00471811, 0.02056604, 0.0092605 ,\n",
      "       0.02523429, 0.00826776, 0.00401004, 0.02237495, 0.00253556,\n",
      "       0.03820715, 0.02093426, 0.01044628, 0.00257973, 0.01167985,\n",
      "       0.01546066, 0.01121546, 0.00975182, 0.01276127, 0.0241512 ,\n",
      "       0.01368651, 0.01737223, 0.01521907, 0.00734733, 0.01349207,\n",
      "       0.01361155, 0.02314139, 0.00944335, 0.02379441, 0.0206034 ,\n",
      "       0.02341427, 0.00337442, 0.00778364, 0.0039727 , 0.00580962,\n",
      "       0.00372429, 0.00655526, 0.02111998, 0.02959032, 0.00568651,\n",
      "       0.00350137, 0.00553566, 0.01343723, 0.00634105, 0.02507685,\n",
      "       0.02046505, 0.0161631 , 0.01591192, 0.02322119, 0.00578852,\n",
      "       0.00186484, 0.00816637, 0.0106935 , 0.012882  , 0.01102647,\n",
      "       0.01851944, 0.01708897, 0.008153  , 0.02244058, 0.01523911,\n",
      "       0.01605018, 0.02831111, 0.00537765, 0.0157132 , 0.02294056,\n",
      "       0.02675005, 0.05278178, 0.00536561, 0.00311967, 0.00827333,\n",
      "       0.03042642, 0.00834711, 0.0054569 , 0.01097262, 0.00913204,\n",
      "       0.01701694, 0.00767397, 0.01520961, 0.01017759, 0.0276973 ,\n",
      "       0.01771233, 0.00905797, 0.00873243, 0.02244349, 0.00323026,\n",
      "       0.00355813, 0.0025044 , 0.00501059, 0.00647533, 0.01685097,\n",
      "       0.00810478, 0.01371915, 0.00619321, 0.01152706, 0.01405183,\n",
      "       0.01639811, 0.00781506, 0.03599291, 0.0195402 , 0.01290287,\n",
      "       0.02238258, 0.02092227, 0.01362882, 0.00344184, 0.01316696,\n",
      "       0.0072748 , 0.01009504, 0.00341825, 0.00433637, 0.00587719,\n",
      "       0.01126488, 0.00920296, 0.01398041, 0.01554982, 0.00629972,\n",
      "       0.01616296, 0.01709341, 0.05215585, 0.0124596 , 0.01196258,\n",
      "       0.0131586 , 0.00151582, 0.01354853, 0.01271664, 0.00856041,\n",
      "       0.01048437, 0.01015539, 0.01906265, 0.03706315, 0.01305089,\n",
      "       0.00810851, 0.01307015, 0.00501741, 0.02297173, 0.02269067,\n",
      "       0.01644766, 0.00394056, 0.02933898, 0.02276274, 0.01624248,\n",
      "       0.00620169, 0.01780196, 0.00525031, 0.0031771 , 0.00482797,\n",
      "       0.01766525, 0.0188841 , 0.01300951, 0.02556899, 0.02462441,\n",
      "       0.02395822, 0.01585193, 0.0249056 , 0.02129291, 0.01638632,\n",
      "       0.00903323, 0.09572053]), 'param_regressor__colsample_bytree': masked_array(data=[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__gamma': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.2, 0.2, 0.2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__max_depth': masked_array(data=[4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8,\n",
      "                   4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_regressor__min_child_weight': masked_array(data=[1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3,\n",
      "                   1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 1, 3, 3, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_scaler': masked_array(data=[Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}], 'split0_test_score': array([0.50568762, 0.68265312, 0.68265312, 0.50569355, 0.71090461,\n",
      "       0.71090526, 0.66148417, 0.7230878 , 0.7230878 , 0.64910968,\n",
      "       0.72439285, 0.7243923 , 0.66840555, 0.7436628 , 0.74366266,\n",
      "       0.65422904, 0.7429435 , 0.7429438 , 0.14547761, 0.31377298,\n",
      "       0.31377298, 0.14406115, 0.31186022, 0.31186022, 0.21370545,\n",
      "       0.32136612, 0.32136612, 0.21556535, 0.31759626, 0.31759626,\n",
      "       0.25054192, 0.33534652, 0.33534657, 0.24621044, 0.32967478,\n",
      "       0.32967481, 0.50568762, 0.68265312, 0.68265312, 0.50569355,\n",
      "       0.71090461, 0.71090526, 0.66148417, 0.7230878 , 0.7230878 ,\n",
      "       0.64910968, 0.72439285, 0.7243923 , 0.66840555, 0.7436628 ,\n",
      "       0.74366266, 0.65422904, 0.7429435 , 0.7429438 , 0.14547761,\n",
      "       0.31377298, 0.31377298, 0.14406115, 0.31186022, 0.31186022,\n",
      "       0.21370545, 0.32136612, 0.32136612, 0.21556535, 0.31759626,\n",
      "       0.31759626, 0.25054192, 0.33534652, 0.33534657, 0.24621044,\n",
      "       0.32967478, 0.32967481, 0.50568762, 0.68265312, 0.68265312,\n",
      "       0.50569355, 0.71090461, 0.71090526, 0.66148417, 0.7230878 ,\n",
      "       0.7230878 , 0.64910968, 0.72439285, 0.7243923 , 0.66840555,\n",
      "       0.7436628 , 0.74366266, 0.65422904, 0.7429435 , 0.7429438 ,\n",
      "       0.14547761, 0.31377298, 0.31377298, 0.14406115, 0.31186022,\n",
      "       0.31186022, 0.21370545, 0.32136612, 0.32136612, 0.21556535,\n",
      "       0.31759626, 0.31759626, 0.25054192, 0.33534652, 0.33534657,\n",
      "       0.24621044, 0.32967478, 0.32967481, 0.6099758 , 0.73913536,\n",
      "       0.73913536, 0.59107798, 0.75074271, 0.75074487, 0.67952192,\n",
      "       0.77578398, 0.77579139, 0.67767841, 0.75972406, 0.75972545,\n",
      "       0.71444929, 0.74271014, 0.74270933, 0.67989367, 0.76659155,\n",
      "       0.76659377, 0.23616245, 0.42024916, 0.42024916, 0.24902161,\n",
      "       0.4130878 , 0.4130878 , 0.36655449, 0.42887466, 0.42887263,\n",
      "       0.37689621, 0.42292155, 0.42292003, 0.40714323, 0.44267397,\n",
      "       0.44267236, 0.41844422, 0.43232011, 0.4323186 , 0.6099758 ,\n",
      "       0.73913536, 0.73913536, 0.59107798, 0.75074271, 0.75074487,\n",
      "       0.67952192, 0.77578398, 0.77579139, 0.67767841, 0.75972406,\n",
      "       0.75972545, 0.71444929, 0.74271014, 0.74270933, 0.67989367,\n",
      "       0.76659155, 0.76659377, 0.23616245, 0.42024916, 0.42024916,\n",
      "       0.24902161, 0.4130878 , 0.4130878 , 0.36655449, 0.42887466,\n",
      "       0.42887263, 0.37689621, 0.42292155, 0.42292003, 0.40714323,\n",
      "       0.44267397, 0.44267236, 0.41844422, 0.43232011, 0.4323186 ,\n",
      "       0.6099758 , 0.73913536, 0.73913536, 0.59107798, 0.75074271,\n",
      "       0.75074487, 0.67952192, 0.77578398, 0.77579139, 0.67767841,\n",
      "       0.75972406, 0.75972545, 0.71444929, 0.74271014, 0.74270933,\n",
      "       0.67989367, 0.76659155, 0.76659377, 0.23616245, 0.42024916,\n",
      "       0.42024916, 0.24902161, 0.4130878 , 0.4130878 , 0.36655449,\n",
      "       0.42887466, 0.42887263, 0.37689621, 0.42292155, 0.42292003,\n",
      "       0.40714323, 0.44267397, 0.44267236, 0.41844422, 0.43232011,\n",
      "       0.4323186 , 0.57516635, 0.75004493, 0.75004493, 0.61107853,\n",
      "       0.75586252, 0.75586252, 0.68957822, 0.77032173, 0.77032173,\n",
      "       0.67127208, 0.77925446, 0.77925446, 0.6869598 , 0.75202848,\n",
      "       0.75202819, 0.67117687, 0.77610555, 0.77610555, 0.26461865,\n",
      "       0.52155588, 0.52155588, 0.3076045 , 0.50637824, 0.50637824,\n",
      "       0.45451873, 0.529293  , 0.52929269, 0.45876036, 0.51746205,\n",
      "       0.51746168, 0.48395056, 0.53418526, 0.53418473, 0.4941116 ,\n",
      "       0.52391546, 0.52391516, 0.57516635, 0.75004493, 0.75004493,\n",
      "       0.61107853, 0.75586252, 0.75586252, 0.68957822, 0.77032173,\n",
      "       0.77032173, 0.67127208, 0.77925446, 0.77925446, 0.6869598 ,\n",
      "       0.75202848, 0.75202819, 0.67117687, 0.77610555, 0.77610555,\n",
      "       0.26461865, 0.52155588, 0.52155588, 0.3076045 , 0.50637824,\n",
      "       0.50637824, 0.45451873, 0.529293  , 0.52929269, 0.45876036,\n",
      "       0.51746205, 0.51746168, 0.48395056, 0.53418526, 0.53418473,\n",
      "       0.4941116 , 0.52391546, 0.52391516, 0.57516635, 0.75004493,\n",
      "       0.75004493, 0.61107853, 0.75586252, 0.75586252, 0.68957822,\n",
      "       0.77032173, 0.77032173, 0.67127208, 0.77925446, 0.77925446,\n",
      "       0.6869598 , 0.75202848, 0.75202819, 0.67117687, 0.77610555,\n",
      "       0.77610555, 0.26461865, 0.52155588, 0.52155588, 0.3076045 ,\n",
      "       0.50637824, 0.50637824, 0.45451873, 0.529293  , 0.52929269,\n",
      "       0.45876036, 0.51746205, 0.51746168, 0.48395056, 0.53418526,\n",
      "       0.53418473, 0.4941116 , 0.52391546, 0.52391516, 0.53637397,\n",
      "       0.76736274, 0.76736274, 0.59431607, 0.77995552, 0.77995552,\n",
      "       0.66199951, 0.78705863, 0.78706079, 0.65669995, 0.79054623,\n",
      "       0.79054623, 0.63206342, 0.77314488, 0.77314341, 0.64133444,\n",
      "       0.7944682 , 0.79446802, 0.26231092, 0.60293949, 0.60293949,\n",
      "       0.3287839 , 0.57733406, 0.57733406, 0.46896867, 0.62218607,\n",
      "       0.62218607, 0.47564187, 0.59489302, 0.59489302, 0.48083341,\n",
      "       0.62014456, 0.62014456, 0.49129637, 0.59618771, 0.59618771,\n",
      "       0.53637397, 0.76736274, 0.76736274, 0.59431607, 0.77995552,\n",
      "       0.77995552, 0.66199951, 0.78705863, 0.78706079, 0.65669995,\n",
      "       0.79054623, 0.79054623, 0.63206342, 0.77314488, 0.77314341,\n",
      "       0.64133444, 0.7944682 , 0.79446802, 0.26231092, 0.60293949,\n",
      "       0.60293949, 0.3287839 , 0.57733406, 0.57733406, 0.46896867,\n",
      "       0.62218607, 0.62218607, 0.47564187, 0.59489302, 0.59489302,\n",
      "       0.48083341, 0.62014456, 0.62014456, 0.49129637, 0.59618771,\n",
      "       0.59618771, 0.53637397, 0.76736274, 0.76736274, 0.59431607,\n",
      "       0.77995552, 0.77995552, 0.66199951, 0.78705863, 0.78706079,\n",
      "       0.65669995, 0.79054623, 0.79054623, 0.63206342, 0.77314488,\n",
      "       0.77314341, 0.64133444, 0.7944682 , 0.79446802, 0.26231092,\n",
      "       0.60293949, 0.60293949, 0.3287839 , 0.57733406, 0.57733406,\n",
      "       0.46896867, 0.62218607, 0.62218607, 0.47564187, 0.59489302,\n",
      "       0.59489302, 0.48083341, 0.62014456, 0.62014456, 0.49129637,\n",
      "       0.59618771, 0.59618771]), 'split1_test_score': array([0.45820819, 0.58048695, 0.58048695, 0.46805998, 0.58833125,\n",
      "       0.58833125, 0.5751972 , 0.60256096, 0.60256094, 0.57882419,\n",
      "       0.58470356, 0.58470206, 0.60023824, 0.60500382, 0.6050042 ,\n",
      "       0.5912682 , 0.59058935, 0.59058956, 0.12180699, 0.26346045,\n",
      "       0.26346045, 0.12844764, 0.26384019, 0.26384019, 0.1927573 ,\n",
      "       0.27566935, 0.27566935, 0.20150446, 0.27514053, 0.27514053,\n",
      "       0.2327383 , 0.27960782, 0.27960773, 0.23843285, 0.28129827,\n",
      "       0.28129827, 0.45820819, 0.58048695, 0.58048695, 0.46805998,\n",
      "       0.58833125, 0.58833125, 0.5751972 , 0.60256096, 0.60256094,\n",
      "       0.57882419, 0.58470356, 0.58470206, 0.60023824, 0.60500382,\n",
      "       0.6050042 , 0.5912682 , 0.59058935, 0.59058956, 0.12180699,\n",
      "       0.26346045, 0.26346045, 0.12844764, 0.26384019, 0.26384019,\n",
      "       0.1927573 , 0.27566935, 0.27566935, 0.20150446, 0.27514053,\n",
      "       0.27514053, 0.2327383 , 0.27960782, 0.27960773, 0.23843285,\n",
      "       0.28129827, 0.28129827, 0.45820819, 0.58048695, 0.58048695,\n",
      "       0.46805998, 0.58833125, 0.58833125, 0.5751972 , 0.60256096,\n",
      "       0.60256094, 0.57882419, 0.58470356, 0.58470206, 0.60023824,\n",
      "       0.60500382, 0.6050042 , 0.5912682 , 0.59058935, 0.59058956,\n",
      "       0.12180699, 0.26346045, 0.26346045, 0.12844764, 0.26384019,\n",
      "       0.26384019, 0.1927573 , 0.27566935, 0.27566935, 0.20150446,\n",
      "       0.27514053, 0.27514053, 0.2327383 , 0.27960782, 0.27960773,\n",
      "       0.23843285, 0.28129827, 0.28129827, 0.5714293 , 0.62423748,\n",
      "       0.62423748, 0.53588276, 0.60762777, 0.60762777, 0.64392697,\n",
      "       0.64460389, 0.64460389, 0.62406464, 0.6115613 , 0.61156065,\n",
      "       0.66397163, 0.65763213, 0.65763211, 0.64789841, 0.620485  ,\n",
      "       0.62048507, 0.21386677, 0.35845757, 0.35845757, 0.22243808,\n",
      "       0.35900802, 0.35900802, 0.31834044, 0.37658425, 0.37658425,\n",
      "       0.31994714, 0.37479995, 0.37479995, 0.37453075, 0.3872074 ,\n",
      "       0.38720738, 0.37863281, 0.38770434, 0.38770431, 0.5714293 ,\n",
      "       0.62423748, 0.62423748, 0.53588276, 0.60762777, 0.60762777,\n",
      "       0.64392697, 0.64460389, 0.64460389, 0.62406464, 0.6115613 ,\n",
      "       0.61156065, 0.66397163, 0.65763213, 0.65763211, 0.64789841,\n",
      "       0.620485  , 0.62048507, 0.21386677, 0.35845757, 0.35845757,\n",
      "       0.22243808, 0.35900802, 0.35900802, 0.31834044, 0.37658425,\n",
      "       0.37658425, 0.31994714, 0.37479995, 0.37479995, 0.37453075,\n",
      "       0.3872074 , 0.38720738, 0.37863281, 0.38770434, 0.38770431,\n",
      "       0.5714293 , 0.62423748, 0.62423748, 0.53588276, 0.60762777,\n",
      "       0.60762777, 0.64392697, 0.64460389, 0.64460389, 0.62406464,\n",
      "       0.6115613 , 0.61156065, 0.66397163, 0.65763213, 0.65763211,\n",
      "       0.64789841, 0.620485  , 0.62048507, 0.21386677, 0.35845757,\n",
      "       0.35845757, 0.22243808, 0.35900802, 0.35900802, 0.31834044,\n",
      "       0.37658425, 0.37658425, 0.31994714, 0.37479995, 0.37479995,\n",
      "       0.37453075, 0.3872074 , 0.38720738, 0.37863281, 0.38770434,\n",
      "       0.38770431, 0.56606355, 0.63278595, 0.63278595, 0.56274812,\n",
      "       0.61617064, 0.61617064, 0.67006416, 0.65332429, 0.65332429,\n",
      "       0.62239152, 0.62053903, 0.62053903, 0.67622948, 0.66408504,\n",
      "       0.6640846 , 0.65686736, 0.61647003, 0.61647183, 0.24834671,\n",
      "       0.44464869, 0.44464869, 0.28019499, 0.43864211, 0.43864211,\n",
      "       0.39113308, 0.46372491, 0.46372491, 0.38834503, 0.45609803,\n",
      "       0.45609803, 0.4566349 , 0.47677479, 0.47677478, 0.45445849,\n",
      "       0.47169154, 0.47169152, 0.56606355, 0.63278595, 0.63278595,\n",
      "       0.56274812, 0.61617064, 0.61617064, 0.67006416, 0.65332429,\n",
      "       0.65332429, 0.62239152, 0.62053903, 0.62053903, 0.67622948,\n",
      "       0.66408504, 0.6640846 , 0.65686736, 0.61647003, 0.61647183,\n",
      "       0.24834671, 0.44464869, 0.44464869, 0.28019499, 0.43864211,\n",
      "       0.43864211, 0.39113308, 0.46372491, 0.46372491, 0.38834503,\n",
      "       0.45609803, 0.45609803, 0.4566349 , 0.47677479, 0.47677478,\n",
      "       0.45445849, 0.47169154, 0.47169152, 0.56606355, 0.63278595,\n",
      "       0.63278595, 0.56274812, 0.61617064, 0.61617064, 0.67006416,\n",
      "       0.65332429, 0.65332429, 0.62239152, 0.62053903, 0.62053903,\n",
      "       0.67622948, 0.66408504, 0.6640846 , 0.65686736, 0.61647003,\n",
      "       0.61647183, 0.24834671, 0.44464869, 0.44464869, 0.28019499,\n",
      "       0.43864211, 0.43864211, 0.39113308, 0.46372491, 0.46372491,\n",
      "       0.38834503, 0.45609803, 0.45609803, 0.4566349 , 0.47677479,\n",
      "       0.47677478, 0.45445849, 0.47169154, 0.47169152, 0.54425945,\n",
      "       0.63436042, 0.63436047, 0.55772353, 0.62942362, 0.6294236 ,\n",
      "       0.61655408, 0.63248529, 0.63248708, 0.60841138, 0.59530086,\n",
      "       0.59529893, 0.66389919, 0.64139085, 0.64135441, 0.66765836,\n",
      "       0.60034867, 0.60034908, 0.25107441, 0.49880458, 0.49880458,\n",
      "       0.30790317, 0.48796958, 0.48796958, 0.40362996, 0.51699487,\n",
      "       0.51699487, 0.40783816, 0.50505498, 0.50505498, 0.47952251,\n",
      "       0.53243811, 0.53243825, 0.48390919, 0.51824853, 0.51824858,\n",
      "       0.54425945, 0.63436042, 0.63436047, 0.55772353, 0.62942362,\n",
      "       0.6294236 , 0.61655408, 0.63248529, 0.63248708, 0.60841138,\n",
      "       0.59530086, 0.59529893, 0.66389919, 0.64139085, 0.64135441,\n",
      "       0.66765836, 0.60034867, 0.60034908, 0.25107441, 0.49880458,\n",
      "       0.49880458, 0.30790317, 0.48796958, 0.48796958, 0.40362996,\n",
      "       0.51699487, 0.51699487, 0.40783816, 0.50505498, 0.50505498,\n",
      "       0.47952251, 0.53243811, 0.53243825, 0.48390919, 0.51824853,\n",
      "       0.51824858, 0.54425945, 0.63436042, 0.63436047, 0.55772353,\n",
      "       0.62942362, 0.6294236 , 0.61655408, 0.63248529, 0.63248708,\n",
      "       0.60841138, 0.59530086, 0.59529893, 0.66389919, 0.64139085,\n",
      "       0.64135441, 0.66765836, 0.60034867, 0.60034908, 0.25107441,\n",
      "       0.49880458, 0.49880458, 0.30790317, 0.48796958, 0.48796958,\n",
      "       0.40362996, 0.51699487, 0.51699487, 0.40783816, 0.50505498,\n",
      "       0.50505498, 0.47952251, 0.53243811, 0.53243825, 0.48390919,\n",
      "       0.51824853, 0.51824858]), 'split2_test_score': array([0.62120589, 0.80083262, 0.80083262, 0.61958027, 0.80359966,\n",
      "       0.80359966, 0.76532419, 0.85114644, 0.85114644, 0.75325054,\n",
      "       0.84121073, 0.84121073, 0.76829799, 0.85099032, 0.85100072,\n",
      "       0.77379318, 0.84850513, 0.84848938, 0.15920015, 0.31454567,\n",
      "       0.31454567, 0.15620277, 0.30982745, 0.30982745, 0.26757567,\n",
      "       0.34550389, 0.34550389, 0.2598833 , 0.33827903, 0.33827904,\n",
      "       0.30503576, 0.35363804, 0.35363903, 0.29022469, 0.34675063,\n",
      "       0.34675162, 0.62120589, 0.80083262, 0.80083262, 0.61958027,\n",
      "       0.80359966, 0.80359966, 0.76532419, 0.85114644, 0.85114644,\n",
      "       0.75325054, 0.84121073, 0.84121073, 0.76829799, 0.85099032,\n",
      "       0.85100072, 0.77379318, 0.84850513, 0.84848938, 0.15920015,\n",
      "       0.31454567, 0.31454567, 0.15620277, 0.30982745, 0.30982745,\n",
      "       0.26757567, 0.34550389, 0.34550389, 0.2598833 , 0.33827903,\n",
      "       0.33827904, 0.30503576, 0.35363804, 0.35363903, 0.29022469,\n",
      "       0.34675063, 0.34675162, 0.62120589, 0.80083262, 0.80083262,\n",
      "       0.61958027, 0.80359966, 0.80359966, 0.76532419, 0.85114644,\n",
      "       0.85114644, 0.75325054, 0.84121073, 0.84121073, 0.76829799,\n",
      "       0.85099032, 0.85100072, 0.77379318, 0.84850513, 0.84848938,\n",
      "       0.15920015, 0.31454567, 0.31454567, 0.15620277, 0.30982745,\n",
      "       0.30982745, 0.26757567, 0.34550389, 0.34550389, 0.2598833 ,\n",
      "       0.33827903, 0.33827904, 0.30503576, 0.35363804, 0.35363903,\n",
      "       0.29022469, 0.34675063, 0.34675162, 0.74195375, 0.83105126,\n",
      "       0.83105126, 0.72862085, 0.82567157, 0.82567157, 0.81082599,\n",
      "       0.8514957 , 0.8514941 , 0.79291242, 0.85272162, 0.85271129,\n",
      "       0.83272059, 0.86696001, 0.86695586, 0.81175546, 0.85751736,\n",
      "       0.85749175, 0.28755881, 0.42016404, 0.42016404, 0.2795343 ,\n",
      "       0.41484971, 0.41484971, 0.44898051, 0.47198642, 0.47198652,\n",
      "       0.44055954, 0.46680734, 0.46680744, 0.49889809, 0.4821414 ,\n",
      "       0.48214866, 0.49010076, 0.47508594, 0.47509009, 0.74195375,\n",
      "       0.83105126, 0.83105126, 0.72862085, 0.82567157, 0.82567157,\n",
      "       0.81082599, 0.8514957 , 0.8514941 , 0.79291242, 0.85272162,\n",
      "       0.85271129, 0.83272059, 0.86696001, 0.86695586, 0.81175546,\n",
      "       0.85751736, 0.85749175, 0.28755881, 0.42016404, 0.42016404,\n",
      "       0.2795343 , 0.41484971, 0.41484971, 0.44898051, 0.47198642,\n",
      "       0.47198652, 0.44055954, 0.46680734, 0.46680744, 0.49889809,\n",
      "       0.4821414 , 0.48214866, 0.49010076, 0.47508594, 0.47509009,\n",
      "       0.74195375, 0.83105126, 0.83105126, 0.72862085, 0.82567157,\n",
      "       0.82567157, 0.81082599, 0.8514957 , 0.8514941 , 0.79291242,\n",
      "       0.85272162, 0.85271129, 0.83272059, 0.86696001, 0.86695586,\n",
      "       0.81175546, 0.85751736, 0.85749175, 0.28755881, 0.42016404,\n",
      "       0.42016404, 0.2795343 , 0.41484971, 0.41484971, 0.44898051,\n",
      "       0.47198642, 0.47198652, 0.44055954, 0.46680734, 0.46680744,\n",
      "       0.49889809, 0.4821414 , 0.48214866, 0.49010076, 0.47508594,\n",
      "       0.47509009, 0.75340213, 0.84263676, 0.84263676, 0.70969347,\n",
      "       0.83239869, 0.83239869, 0.83720206, 0.84743638, 0.84744603,\n",
      "       0.82047927, 0.85329662, 0.85329662, 0.85063928, 0.86271349,\n",
      "       0.8626881 , 0.82367061, 0.86328686, 0.8632363 , 0.33746254,\n",
      "       0.5075336 , 0.5075336 , 0.3420424 , 0.49826424, 0.49826424,\n",
      "       0.55276747, 0.58689288, 0.58689304, 0.54834379, 0.58184881,\n",
      "       0.58184899, 0.5977173 , 0.59628179, 0.59628627, 0.59532773,\n",
      "       0.5912649 , 0.59126936, 0.75340213, 0.84263676, 0.84263676,\n",
      "       0.70969347, 0.83239869, 0.83239869, 0.83720206, 0.84743638,\n",
      "       0.84744603, 0.82047927, 0.85329662, 0.85329662, 0.85063928,\n",
      "       0.86271349, 0.8626881 , 0.82367061, 0.86328686, 0.8632363 ,\n",
      "       0.33746254, 0.5075336 , 0.5075336 , 0.3420424 , 0.49826424,\n",
      "       0.49826424, 0.55276747, 0.58689288, 0.58689304, 0.54834379,\n",
      "       0.58184881, 0.58184899, 0.5977173 , 0.59628179, 0.59628627,\n",
      "       0.59532773, 0.5912649 , 0.59126936, 0.75340213, 0.84263676,\n",
      "       0.84263676, 0.70969347, 0.83239869, 0.83239869, 0.83720206,\n",
      "       0.84743638, 0.84744603, 0.82047927, 0.85329662, 0.85329662,\n",
      "       0.85063928, 0.86271349, 0.8626881 , 0.82367061, 0.86328686,\n",
      "       0.8632363 , 0.33746254, 0.5075336 , 0.5075336 , 0.3420424 ,\n",
      "       0.49826424, 0.49826424, 0.55276747, 0.58689288, 0.58689304,\n",
      "       0.54834379, 0.58184881, 0.58184899, 0.5977173 , 0.59628179,\n",
      "       0.59628627, 0.59532773, 0.5912649 , 0.59126936, 0.74040991,\n",
      "       0.85142386, 0.85142386, 0.72281333, 0.84631207, 0.84631207,\n",
      "       0.84744151, 0.85596755, 0.85596768, 0.82873298, 0.85593358,\n",
      "       0.8559337 , 0.85030043, 0.86353156, 0.8635273 , 0.81230569,\n",
      "       0.86558464, 0.86556534, 0.33258307, 0.56952021, 0.56952021,\n",
      "       0.33145744, 0.5605102 , 0.5605102 , 0.58976604, 0.69058322,\n",
      "       0.69058349, 0.57854457, 0.67614788, 0.6761481 , 0.64907819,\n",
      "       0.69875241, 0.69875814, 0.63744773, 0.68565318, 0.68565616,\n",
      "       0.74040991, 0.85142386, 0.85142386, 0.72281333, 0.84631207,\n",
      "       0.84631207, 0.84744151, 0.85596755, 0.85596768, 0.82873298,\n",
      "       0.85593358, 0.8559337 , 0.85030043, 0.86353156, 0.8635273 ,\n",
      "       0.81230569, 0.86558464, 0.86556534, 0.33258307, 0.56952021,\n",
      "       0.56952021, 0.33145744, 0.5605102 , 0.5605102 , 0.58976604,\n",
      "       0.69058322, 0.69058349, 0.57854457, 0.67614788, 0.6761481 ,\n",
      "       0.64907819, 0.69875241, 0.69875814, 0.63744773, 0.68565318,\n",
      "       0.68565616, 0.74040991, 0.85142386, 0.85142386, 0.72281333,\n",
      "       0.84631207, 0.84631207, 0.84744151, 0.85596755, 0.85596768,\n",
      "       0.82873298, 0.85593358, 0.8559337 , 0.85030043, 0.86353156,\n",
      "       0.8635273 , 0.81230569, 0.86558464, 0.86556534, 0.33258307,\n",
      "       0.56952021, 0.56952021, 0.33145744, 0.5605102 , 0.5605102 ,\n",
      "       0.58976604, 0.69058322, 0.69058349, 0.57854457, 0.67614788,\n",
      "       0.6761481 , 0.64907819, 0.69875241, 0.69875814, 0.63744773,\n",
      "       0.68565318, 0.68565616]), 'mean_test_score': array([0.52836724, 0.6879909 , 0.6879909 , 0.53111126, 0.70094517,\n",
      "       0.70094539, 0.66733518, 0.7255984 , 0.7255984 , 0.66039481,\n",
      "       0.71676905, 0.71676836, 0.6789806 , 0.73321898, 0.73322253,\n",
      "       0.67309681, 0.72734599, 0.72734091, 0.14216158, 0.2972597 ,\n",
      "       0.2972597 , 0.14290385, 0.29517595, 0.29517595, 0.22467947,\n",
      "       0.31417979, 0.31417979, 0.22565104, 0.31033861, 0.31033861,\n",
      "       0.262772  , 0.32286413, 0.32286444, 0.25828932, 0.31924123,\n",
      "       0.31924157, 0.52836724, 0.6879909 , 0.6879909 , 0.53111126,\n",
      "       0.70094517, 0.70094539, 0.66733518, 0.7255984 , 0.7255984 ,\n",
      "       0.66039481, 0.71676905, 0.71676836, 0.6789806 , 0.73321898,\n",
      "       0.73322253, 0.67309681, 0.72734599, 0.72734091, 0.14216158,\n",
      "       0.2972597 , 0.2972597 , 0.14290385, 0.29517595, 0.29517595,\n",
      "       0.22467947, 0.31417979, 0.31417979, 0.22565104, 0.31033861,\n",
      "       0.31033861, 0.262772  , 0.32286413, 0.32286444, 0.25828932,\n",
      "       0.31924123, 0.31924157, 0.52836724, 0.6879909 , 0.6879909 ,\n",
      "       0.53111126, 0.70094517, 0.70094539, 0.66733518, 0.7255984 ,\n",
      "       0.7255984 , 0.66039481, 0.71676905, 0.71676836, 0.6789806 ,\n",
      "       0.73321898, 0.73322253, 0.67309681, 0.72734599, 0.72734091,\n",
      "       0.14216158, 0.2972597 , 0.2972597 , 0.14290385, 0.29517595,\n",
      "       0.29517595, 0.22467947, 0.31417979, 0.31417979, 0.22565104,\n",
      "       0.31033861, 0.31033861, 0.262772  , 0.32286413, 0.32286444,\n",
      "       0.25828932, 0.31924123, 0.31924157, 0.64111961, 0.7314747 ,\n",
      "       0.7314747 , 0.61852719, 0.72801402, 0.72801474, 0.71142496,\n",
      "       0.75729452, 0.75729646, 0.69821849, 0.74133566, 0.74133246,\n",
      "       0.73704717, 0.75576743, 0.75576577, 0.71318251, 0.74819797,\n",
      "       0.7481902 , 0.24586268, 0.39962359, 0.39962359, 0.25033133,\n",
      "       0.39564851, 0.39564851, 0.37795848, 0.42581511, 0.42581447,\n",
      "       0.3791343 , 0.42150961, 0.42150914, 0.42685736, 0.43734093,\n",
      "       0.4373428 , 0.42905927, 0.43170346, 0.43170433, 0.64111961,\n",
      "       0.7314747 , 0.7314747 , 0.61852719, 0.72801402, 0.72801474,\n",
      "       0.71142496, 0.75729452, 0.75729646, 0.69821849, 0.74133566,\n",
      "       0.74133246, 0.73704717, 0.75576743, 0.75576577, 0.71318251,\n",
      "       0.74819797, 0.7481902 , 0.24586268, 0.39962359, 0.39962359,\n",
      "       0.25033133, 0.39564851, 0.39564851, 0.37795848, 0.42581511,\n",
      "       0.42581447, 0.3791343 , 0.42150961, 0.42150914, 0.42685736,\n",
      "       0.43734093, 0.4373428 , 0.42905927, 0.43170346, 0.43170433,\n",
      "       0.64111961, 0.7314747 , 0.7314747 , 0.61852719, 0.72801402,\n",
      "       0.72801474, 0.71142496, 0.75729452, 0.75729646, 0.69821849,\n",
      "       0.74133566, 0.74133246, 0.73704717, 0.75576743, 0.75576577,\n",
      "       0.71318251, 0.74819797, 0.7481902 , 0.24586268, 0.39962359,\n",
      "       0.39962359, 0.25033133, 0.39564851, 0.39564851, 0.37795848,\n",
      "       0.42581511, 0.42581447, 0.3791343 , 0.42150961, 0.42150914,\n",
      "       0.42685736, 0.43734093, 0.4373428 , 0.42905927, 0.43170346,\n",
      "       0.43170433, 0.63154401, 0.74182255, 0.74182255, 0.62784004,\n",
      "       0.73481062, 0.73481062, 0.73228148, 0.75702747, 0.75703068,\n",
      "       0.70471429, 0.75103004, 0.75103004, 0.73794285, 0.759609  ,\n",
      "       0.7596003 , 0.71723828, 0.75195415, 0.75193789, 0.28347597,\n",
      "       0.49124606, 0.49124606, 0.3099473 , 0.48109486, 0.48109486,\n",
      "       0.46613976, 0.52663693, 0.52663688, 0.46514973, 0.51846963,\n",
      "       0.51846957, 0.51276759, 0.53574728, 0.53574859, 0.51463261,\n",
      "       0.5289573 , 0.52895868, 0.63154401, 0.74182255, 0.74182255,\n",
      "       0.62784004, 0.73481062, 0.73481062, 0.73228148, 0.75702747,\n",
      "       0.75703068, 0.70471429, 0.75103004, 0.75103004, 0.73794285,\n",
      "       0.759609  , 0.7596003 , 0.71723828, 0.75195415, 0.75193789,\n",
      "       0.28347597, 0.49124606, 0.49124606, 0.3099473 , 0.48109486,\n",
      "       0.48109486, 0.46613976, 0.52663693, 0.52663688, 0.46514973,\n",
      "       0.51846963, 0.51846957, 0.51276759, 0.53574728, 0.53574859,\n",
      "       0.51463261, 0.5289573 , 0.52895868, 0.63154401, 0.74182255,\n",
      "       0.74182255, 0.62784004, 0.73481062, 0.73481062, 0.73228148,\n",
      "       0.75702747, 0.75703068, 0.70471429, 0.75103004, 0.75103004,\n",
      "       0.73794285, 0.759609  , 0.7596003 , 0.71723828, 0.75195415,\n",
      "       0.75193789, 0.28347597, 0.49124606, 0.49124606, 0.3099473 ,\n",
      "       0.48109486, 0.48109486, 0.46613976, 0.52663693, 0.52663688,\n",
      "       0.46514973, 0.51846963, 0.51846957, 0.51276759, 0.53574728,\n",
      "       0.53574859, 0.51463261, 0.5289573 , 0.52895868, 0.60701444,\n",
      "       0.75104901, 0.75104902, 0.62495098, 0.75189707, 0.75189706,\n",
      "       0.70866503, 0.75850382, 0.75850519, 0.6979481 , 0.74726022,\n",
      "       0.74725962, 0.71542101, 0.75935576, 0.75934171, 0.7070995 ,\n",
      "       0.75346717, 0.75346081, 0.28198947, 0.55708809, 0.55708809,\n",
      "       0.32271484, 0.54193794, 0.54193794, 0.48745489, 0.60992138,\n",
      "       0.60992147, 0.48734153, 0.59203196, 0.59203203, 0.53647804,\n",
      "       0.61711169, 0.61711365, 0.5375511 , 0.6000298 , 0.60003081,\n",
      "       0.60701444, 0.75104901, 0.75104902, 0.62495098, 0.75189707,\n",
      "       0.75189706, 0.70866503, 0.75850382, 0.75850519, 0.6979481 ,\n",
      "       0.74726022, 0.74725962, 0.71542101, 0.75935576, 0.75934171,\n",
      "       0.7070995 , 0.75346717, 0.75346081, 0.28198947, 0.55708809,\n",
      "       0.55708809, 0.32271484, 0.54193794, 0.54193794, 0.48745489,\n",
      "       0.60992138, 0.60992147, 0.48734153, 0.59203196, 0.59203203,\n",
      "       0.53647804, 0.61711169, 0.61711365, 0.5375511 , 0.6000298 ,\n",
      "       0.60003081, 0.60701444, 0.75104901, 0.75104902, 0.62495098,\n",
      "       0.75189707, 0.75189706, 0.70866503, 0.75850382, 0.75850519,\n",
      "       0.6979481 , 0.74726022, 0.74725962, 0.71542101, 0.75935576,\n",
      "       0.75934171, 0.7070995 , 0.75346717, 0.75346081, 0.28198947,\n",
      "       0.55708809, 0.55708809, 0.32271484, 0.54193794, 0.54193794,\n",
      "       0.48745489, 0.60992138, 0.60992147, 0.48734153, 0.59203196,\n",
      "       0.59203203, 0.53647804, 0.61711169, 0.61711365, 0.5375511 ,\n",
      "       0.6000298 , 0.60003081]), 'std_test_score': array([0.0684487 , 0.09003489, 0.09003489, 0.06441607, 0.08816468,\n",
      "       0.0881647 , 0.07772921, 0.10150013, 0.10150013, 0.07165497,\n",
      "       0.10485728, 0.1048579 , 0.06901639, 0.10069473, 0.10069863,\n",
      "       0.07570045, 0.10586973, 0.10586365, 0.01544472, 0.02390176,\n",
      "       0.02390176, 0.0113605 , 0.02217327, 0.02217327, 0.03151475,\n",
      "       0.02895914, 0.02895914, 0.0248772 , 0.0262821 , 0.0262821 ,\n",
      "       0.03075616, 0.03148519, 0.03148556, 0.02280385, 0.0277206 ,\n",
      "       0.02772092, 0.0684487 , 0.09003489, 0.09003489, 0.06441607,\n",
      "       0.08816468, 0.0881647 , 0.07772921, 0.10150013, 0.10150013,\n",
      "       0.07165497, 0.10485728, 0.1048579 , 0.06901639, 0.10069473,\n",
      "       0.10069863, 0.07570045, 0.10586973, 0.10586365, 0.01544472,\n",
      "       0.02390176, 0.02390176, 0.0113605 , 0.02217327, 0.02217327,\n",
      "       0.03151475, 0.02895914, 0.02895914, 0.0248772 , 0.0262821 ,\n",
      "       0.0262821 , 0.03075616, 0.03148519, 0.03148556, 0.02280385,\n",
      "       0.0277206 , 0.02772092, 0.0684487 , 0.09003489, 0.09003489,\n",
      "       0.06441607, 0.08816468, 0.0881647 , 0.07772921, 0.10150013,\n",
      "       0.10150013, 0.07165497, 0.10485728, 0.1048579 , 0.06901639,\n",
      "       0.10069473, 0.10069863, 0.07570045, 0.10586973, 0.10586365,\n",
      "       0.01544472, 0.02390176, 0.02390176, 0.0113605 , 0.02217327,\n",
      "       0.02217327, 0.03151475, 0.02895914, 0.02895914, 0.0248772 ,\n",
      "       0.0262821 , 0.0262821 , 0.03075616, 0.03148519, 0.03148556,\n",
      "       0.02280385, 0.0277206 , 0.02772092, 0.07301644, 0.08460496,\n",
      "       0.08460496, 0.08104356, 0.09045522, 0.0904554 , 0.0717736 ,\n",
      "       0.0854691 , 0.08546905, 0.07044532, 0.09930819, 0.0993047 ,\n",
      "       0.07072034, 0.08595506, 0.08595333, 0.07091494, 0.0976382 ,\n",
      "       0.09762876, 0.03085665, 0.02910879, 0.02910879, 0.02332783,\n",
      "       0.02591872, 0.02591872, 0.05393975, 0.03900781, 0.0390078 ,\n",
      "       0.04926523, 0.03757513, 0.03757515, 0.05265165, 0.03893967,\n",
      "       0.03894239, 0.04612147, 0.03567606, 0.03567774, 0.07301644,\n",
      "       0.08460496, 0.08460496, 0.08104356, 0.09045522, 0.0904554 ,\n",
      "       0.0717736 , 0.0854691 , 0.08546905, 0.07044532, 0.09930819,\n",
      "       0.0993047 , 0.07072034, 0.08595506, 0.08595333, 0.07091494,\n",
      "       0.0976382 , 0.09762876, 0.03085665, 0.02910879, 0.02910879,\n",
      "       0.02332783, 0.02591872, 0.02591872, 0.05393975, 0.03900781,\n",
      "       0.0390078 , 0.04926523, 0.03757513, 0.03757515, 0.05265165,\n",
      "       0.03893967, 0.03894239, 0.04612147, 0.03567606, 0.03567774,\n",
      "       0.07301644, 0.08460496, 0.08460496, 0.08104356, 0.09045522,\n",
      "       0.0904554 , 0.0717736 , 0.0854691 , 0.08546905, 0.07044532,\n",
      "       0.09930819, 0.0993047 , 0.07072034, 0.08595506, 0.08595333,\n",
      "       0.07091494, 0.0976382 , 0.09762876, 0.03085665, 0.02910879,\n",
      "       0.02910879, 0.02332783, 0.02591872, 0.02591872, 0.05393975,\n",
      "       0.03900781, 0.0390078 , 0.04926523, 0.03757513, 0.03757515,\n",
      "       0.05265165, 0.03893967, 0.03894239, 0.04612147, 0.03567606,\n",
      "       0.03567774, 0.0862468 , 0.0858683 , 0.0858683 , 0.06114979,\n",
      "       0.08952106, 0.08952106, 0.07461656, 0.07980154, 0.07980519,\n",
      "       0.08425547, 0.09709613, 0.09709613, 0.07980872, 0.08126669,\n",
      "       0.08125614, 0.07548541, 0.10219949, 0.10218034, 0.03874796,\n",
      "       0.03344291, 0.03344291, 0.02530338, 0.03020085, 0.03020085,\n",
      "       0.06649664, 0.05031818, 0.05031823, 0.06547528, 0.05134248,\n",
      "       0.05134256, 0.06109488, 0.04880103, 0.04880289, 0.059312  ,\n",
      "       0.04894563, 0.04894754, 0.0862468 , 0.0858683 , 0.0858683 ,\n",
      "       0.06114979, 0.08952106, 0.08952106, 0.07461656, 0.07980154,\n",
      "       0.07980519, 0.08425547, 0.09709613, 0.09709613, 0.07980872,\n",
      "       0.08126669, 0.08125614, 0.07548541, 0.10219949, 0.10218034,\n",
      "       0.03874796, 0.03344291, 0.03344291, 0.02530338, 0.03020085,\n",
      "       0.03020085, 0.06649664, 0.05031818, 0.05031823, 0.06547528,\n",
      "       0.05134248, 0.05134256, 0.06109488, 0.04880103, 0.04880289,\n",
      "       0.059312  , 0.04894563, 0.04894754, 0.0862468 , 0.0858683 ,\n",
      "       0.0858683 , 0.06114979, 0.08952106, 0.08952106, 0.07461656,\n",
      "       0.07980154, 0.07980519, 0.08425547, 0.09709613, 0.09709613,\n",
      "       0.07980872, 0.08126669, 0.08125614, 0.07548541, 0.10219949,\n",
      "       0.10218034, 0.03874796, 0.03344291, 0.03344291, 0.02530338,\n",
      "       0.03020085, 0.03020085, 0.06649664, 0.05031818, 0.05031823,\n",
      "       0.06547528, 0.05134248, 0.05134256, 0.06109488, 0.04880103,\n",
      "       0.04880289, 0.059312  , 0.04894563, 0.04894754, 0.09437976,\n",
      "       0.08936344, 0.08936342, 0.07079329, 0.09073995, 0.09073995,\n",
      "       0.09986827, 0.09344379, 0.09344325, 0.09455672, 0.1107177 ,\n",
      "       0.11071862, 0.09625564, 0.09121121, 0.09122523, 0.07516424,\n",
      "       0.11209622, 0.11208958, 0.03606798, 0.04341227, 0.04341227,\n",
      "       0.01053015, 0.03877456, 0.03877456, 0.07710584, 0.07139582,\n",
      "       0.07139593, 0.07017992, 0.06987768, 0.06987777, 0.07962213,\n",
      "       0.06793139, 0.06793362, 0.07070194, 0.06839664, 0.06839786,\n",
      "       0.09437976, 0.08936344, 0.08936342, 0.07079329, 0.09073995,\n",
      "       0.09073995, 0.09986827, 0.09344379, 0.09344325, 0.09455672,\n",
      "       0.1107177 , 0.11071862, 0.09625564, 0.09121121, 0.09122523,\n",
      "       0.07516424, 0.11209622, 0.11208958, 0.03606798, 0.04341227,\n",
      "       0.04341227, 0.01053015, 0.03877456, 0.03877456, 0.07710584,\n",
      "       0.07139582, 0.07139593, 0.07017992, 0.06987768, 0.06987777,\n",
      "       0.07962213, 0.06793139, 0.06793362, 0.07070194, 0.06839664,\n",
      "       0.06839786, 0.09437976, 0.08936344, 0.08936342, 0.07079329,\n",
      "       0.09073995, 0.09073995, 0.09986827, 0.09344379, 0.09344325,\n",
      "       0.09455672, 0.1107177 , 0.11071862, 0.09625564, 0.09121121,\n",
      "       0.09122523, 0.07516424, 0.11209622, 0.11208958, 0.03606798,\n",
      "       0.04341227, 0.04341227, 0.01053015, 0.03877456, 0.03877456,\n",
      "       0.07710584, 0.07139582, 0.07139593, 0.07017992, 0.06987768,\n",
      "       0.06987777, 0.07962213, 0.06793139, 0.06793362, 0.07070194,\n",
      "       0.06839664, 0.06839786]), 'rank_test_score': array([268, 175, 175, 259, 166, 163, 187, 130, 133, 190, 139, 142, 181,\n",
      "       106, 103, 184, 124, 127, 430, 391, 391, 427, 397, 397, 424, 379,\n",
      "       376, 421, 385, 382, 409, 364, 361, 412, 373, 370, 268, 175, 175,\n",
      "       259, 166, 163, 187, 130, 133, 190, 139, 142, 181, 106, 103, 184,\n",
      "       124, 127, 430, 391, 391, 427, 397, 397, 424, 379, 376, 421, 385,\n",
      "       382, 409, 364, 361, 412, 373, 370, 268, 175, 175, 259, 166, 163,\n",
      "       187, 130, 133, 190, 139, 142, 181, 106, 103, 184, 124, 127, 430,\n",
      "       391, 391, 427, 397, 397, 424, 379, 376, 421, 385, 382, 409, 364,\n",
      "       361, 412, 373, 370, 193, 112, 112, 205, 121, 118, 151,  22,  19,\n",
      "       169,  85,  88,  94,  31,  34, 148,  67,  70, 418, 343, 343, 415,\n",
      "       349, 349, 358, 331, 334, 355, 337, 340, 328, 316, 313, 325, 322,\n",
      "       319, 193, 112, 112, 205, 121, 118, 151,  22,  19, 169,  85,  88,\n",
      "        94,  31,  34, 148,  67,  70, 418, 343, 343, 415, 349, 349, 358,\n",
      "       331, 334, 355, 337, 340, 328, 316, 313, 325, 322, 319, 193, 112,\n",
      "       112, 205, 121, 118, 151,  22,  19, 169,  85,  88,  94,  31,  34,\n",
      "       148,  67,  70, 418, 343, 343, 415, 349, 349, 358, 331, 334, 355,\n",
      "       337, 340, 328, 316, 313, 325, 322, 319, 196,  79,  79, 199,  97,\n",
      "        97, 109,  28,  25, 160,  61,  61,  91,   1,   4, 136,  43,  46,\n",
      "       403, 289, 289, 388, 301, 301, 307, 271, 274, 310, 277, 280, 286,\n",
      "       256, 253, 283, 265, 262, 196,  79,  79, 199,  97,  97, 109,  28,\n",
      "        25, 160,  61,  61,  91,   1,   4, 136,  43,  46, 403, 289, 289,\n",
      "       388, 301, 301, 307, 271, 274, 310, 277, 280, 286, 256, 253, 283,\n",
      "       265, 262, 196,  79,  79, 199,  97,  97, 109,  28,  25, 160,  61,\n",
      "        61,  91,   1,   4, 136,  43,  46, 403, 289, 289, 388, 301, 301,\n",
      "       307, 271, 274, 310, 277, 280, 286, 256, 253, 283, 265, 262, 220,\n",
      "        58,  55, 202,  49,  52, 154,  16,  13, 172,  73,  76, 145,   7,\n",
      "        10, 157,  37,  40, 406, 235, 235, 367, 241, 241, 295, 217, 214,\n",
      "       298, 232, 229, 250, 211, 208, 247, 226, 223, 220,  58,  55, 202,\n",
      "        49,  52, 154,  16,  13, 172,  73,  76, 145,   7,  10, 157,  37,\n",
      "        40, 406, 235, 235, 367, 241, 241, 295, 217, 214, 298, 232, 229,\n",
      "       250, 211, 208, 247, 226, 223, 220,  58,  55, 202,  49,  52, 154,\n",
      "        16,  13, 172,  73,  76, 145,   7,  10, 157,  37,  40, 406, 235,\n",
      "       235, 367, 241, 241, 295, 217, 214, 298, 232, 229, 250, 211, 208,\n",
      "       247, 226, 223], dtype=int32), 'split0_train_score': array([0.76255326, 0.84775039, 0.84775039, 0.72567921, 0.82405025,\n",
      "       0.82405025, 0.88782298, 0.89995313, 0.89995313, 0.85469044,\n",
      "       0.86256197, 0.86256197, 0.93119007, 0.92922708, 0.92922708,\n",
      "       0.89736532, 0.89213464, 0.89213462, 0.17838548, 0.34227736,\n",
      "       0.34227736, 0.17268012, 0.33273341, 0.33273341, 0.30868879,\n",
      "       0.36369282, 0.36369282, 0.28838816, 0.34905287, 0.34905287,\n",
      "       0.38701976, 0.38242738, 0.38242738, 0.35560031, 0.36715069,\n",
      "       0.36715069, 0.76255326, 0.84775039, 0.84775039, 0.72567921,\n",
      "       0.82405025, 0.82405025, 0.88782298, 0.89995313, 0.89995313,\n",
      "       0.85469044, 0.86256197, 0.86256197, 0.93119007, 0.92922708,\n",
      "       0.92922708, 0.89736532, 0.89213464, 0.89213462, 0.17838548,\n",
      "       0.34227736, 0.34227736, 0.17268012, 0.33273341, 0.33273341,\n",
      "       0.30868879, 0.36369282, 0.36369282, 0.28838816, 0.34905287,\n",
      "       0.34905287, 0.38701976, 0.38242738, 0.38242738, 0.35560031,\n",
      "       0.36715069, 0.36715069, 0.76255326, 0.84775039, 0.84775039,\n",
      "       0.72567921, 0.82405025, 0.82405025, 0.88782298, 0.89995313,\n",
      "       0.89995313, 0.85469044, 0.86256197, 0.86256197, 0.93119007,\n",
      "       0.92922708, 0.92922708, 0.89736532, 0.89213464, 0.89213462,\n",
      "       0.17838548, 0.34227736, 0.34227736, 0.17268012, 0.33273341,\n",
      "       0.33273341, 0.30868879, 0.36369282, 0.36369282, 0.28838816,\n",
      "       0.34905287, 0.34905287, 0.38701976, 0.38242738, 0.38242738,\n",
      "       0.35560031, 0.36715069, 0.36715069, 0.81343396, 0.88075137,\n",
      "       0.88075137, 0.81018522, 0.85940872, 0.85940872, 0.91709491,\n",
      "       0.92301054, 0.92301054, 0.89441327, 0.90410573, 0.90410573,\n",
      "       0.9539447 , 0.95076418, 0.95076418, 0.92431743, 0.92837791,\n",
      "       0.92837791, 0.28314276, 0.46834275, 0.46834275, 0.29450983,\n",
      "       0.45711481, 0.45711481, 0.49251202, 0.5030273 , 0.5030273 ,\n",
      "       0.47200131, 0.48198361, 0.48198361, 0.55637023, 0.52646576,\n",
      "       0.52646576, 0.52783169, 0.49988428, 0.49988428, 0.81343396,\n",
      "       0.88075137, 0.88075137, 0.81018522, 0.85940872, 0.85940872,\n",
      "       0.91709491, 0.92301054, 0.92301054, 0.89441327, 0.90410573,\n",
      "       0.90410573, 0.9539447 , 0.95076418, 0.95076418, 0.92431743,\n",
      "       0.92837791, 0.92837791, 0.28314276, 0.46834275, 0.46834275,\n",
      "       0.29450983, 0.45711481, 0.45711481, 0.49251202, 0.5030273 ,\n",
      "       0.5030273 , 0.47200131, 0.48198361, 0.48198361, 0.55637023,\n",
      "       0.52646576, 0.52646576, 0.52783169, 0.49988428, 0.49988428,\n",
      "       0.81343396, 0.88075137, 0.88075137, 0.81018522, 0.85940872,\n",
      "       0.85940872, 0.91709491, 0.92301054, 0.92301054, 0.89441327,\n",
      "       0.90410573, 0.90410573, 0.9539447 , 0.95076418, 0.95076418,\n",
      "       0.92431743, 0.92837791, 0.92837791, 0.28314276, 0.46834275,\n",
      "       0.46834275, 0.29450983, 0.45711481, 0.45711481, 0.49251202,\n",
      "       0.5030273 , 0.5030273 , 0.47200131, 0.48198361, 0.48198361,\n",
      "       0.55637023, 0.52646576, 0.52646576, 0.52783169, 0.49988428,\n",
      "       0.49988428, 0.83508233, 0.8876221 , 0.8876221 , 0.80036534,\n",
      "       0.87322156, 0.87322156, 0.9134896 , 0.93242839, 0.93242839,\n",
      "       0.89851768, 0.91182748, 0.91182748, 0.95442711, 0.95999007,\n",
      "       0.95999007, 0.92872144, 0.93791482, 0.93791482, 0.31853453,\n",
      "       0.5760408 , 0.5760408 , 0.36184693, 0.5641137 , 0.5641137 ,\n",
      "       0.59081478, 0.62261246, 0.62261246, 0.5675686 , 0.59895945,\n",
      "       0.59895945, 0.65715524, 0.64394423, 0.64394423, 0.62679544,\n",
      "       0.61754076, 0.61754076, 0.83508233, 0.8876221 , 0.8876221 ,\n",
      "       0.80036534, 0.87322156, 0.87322156, 0.9134896 , 0.93242839,\n",
      "       0.93242839, 0.89851768, 0.91182748, 0.91182748, 0.95442711,\n",
      "       0.95999007, 0.95999007, 0.92872144, 0.93791482, 0.93791482,\n",
      "       0.31853453, 0.5760408 , 0.5760408 , 0.36184693, 0.5641137 ,\n",
      "       0.5641137 , 0.59081478, 0.62261246, 0.62261246, 0.5675686 ,\n",
      "       0.59895945, 0.59895945, 0.65715524, 0.64394423, 0.64394423,\n",
      "       0.62679544, 0.61754076, 0.61754076, 0.83508233, 0.8876221 ,\n",
      "       0.8876221 , 0.80036534, 0.87322156, 0.87322156, 0.9134896 ,\n",
      "       0.93242839, 0.93242839, 0.89851768, 0.91182748, 0.91182748,\n",
      "       0.95442711, 0.95999007, 0.95999007, 0.92872144, 0.93791482,\n",
      "       0.93791482, 0.31853453, 0.5760408 , 0.5760408 , 0.36184693,\n",
      "       0.5641137 , 0.5641137 , 0.59081478, 0.62261246, 0.62261246,\n",
      "       0.5675686 , 0.59895945, 0.59895945, 0.65715524, 0.64394423,\n",
      "       0.64394423, 0.62679544, 0.61754076, 0.61754076, 0.80771935,\n",
      "       0.9026921 , 0.9026921 , 0.80873405, 0.89047061, 0.89047061,\n",
      "       0.91853201, 0.93637923, 0.93637923, 0.9015715 , 0.91986845,\n",
      "       0.91986845, 0.95329419, 0.96097463, 0.96097463, 0.93480422,\n",
      "       0.94059799, 0.94059799, 0.30537982, 0.65937965, 0.65937965,\n",
      "       0.38522703, 0.6443543 , 0.6443543 , 0.62887331, 0.70964189,\n",
      "       0.70964189, 0.60743632, 0.68690926, 0.68690926, 0.70544364,\n",
      "       0.73167149, 0.73167149, 0.67343068, 0.70671373, 0.70671373,\n",
      "       0.80771935, 0.9026921 , 0.9026921 , 0.80873405, 0.89047061,\n",
      "       0.89047061, 0.91853201, 0.93637923, 0.93637923, 0.9015715 ,\n",
      "       0.91986845, 0.91986845, 0.95329419, 0.96097463, 0.96097463,\n",
      "       0.93480422, 0.94059799, 0.94059799, 0.30537982, 0.65937965,\n",
      "       0.65937965, 0.38522703, 0.6443543 , 0.6443543 , 0.62887331,\n",
      "       0.70964189, 0.70964189, 0.60743632, 0.68690926, 0.68690926,\n",
      "       0.70544364, 0.73167149, 0.73167149, 0.67343068, 0.70671373,\n",
      "       0.70671373, 0.80771935, 0.9026921 , 0.9026921 , 0.80873405,\n",
      "       0.89047061, 0.89047061, 0.91853201, 0.93637923, 0.93637923,\n",
      "       0.9015715 , 0.91986845, 0.91986845, 0.95329419, 0.96097463,\n",
      "       0.96097463, 0.93480422, 0.94059799, 0.94059799, 0.30537982,\n",
      "       0.65937965, 0.65937965, 0.38522703, 0.6443543 , 0.6443543 ,\n",
      "       0.62887331, 0.70964189, 0.70964189, 0.60743632, 0.68690926,\n",
      "       0.68690926, 0.70544364, 0.73167149, 0.73167149, 0.67343068,\n",
      "       0.70671373, 0.70671373]), 'split1_train_score': array([0.74851766, 0.85747916, 0.85747916, 0.73566387, 0.84593598,\n",
      "       0.84593598, 0.87966491, 0.90114727, 0.90114727, 0.85614952,\n",
      "       0.88826456, 0.88826456, 0.9329416 , 0.93431704, 0.93431704,\n",
      "       0.90617157, 0.91633624, 0.91633624, 0.19888916, 0.36800707,\n",
      "       0.36800707, 0.19604974, 0.36329593, 0.36329593, 0.33026482,\n",
      "       0.38808044, 0.38808044, 0.32622977, 0.38167203, 0.38167203,\n",
      "       0.39876108, 0.40523556, 0.40523556, 0.38895492, 0.39755102,\n",
      "       0.39755102, 0.74851766, 0.85747916, 0.85747916, 0.73566387,\n",
      "       0.84593598, 0.84593598, 0.87966491, 0.90114727, 0.90114727,\n",
      "       0.85614952, 0.88826456, 0.88826456, 0.9329416 , 0.93431704,\n",
      "       0.93431704, 0.90617157, 0.91633624, 0.91633624, 0.19888916,\n",
      "       0.36800707, 0.36800707, 0.19604974, 0.36329593, 0.36329593,\n",
      "       0.33026482, 0.38808044, 0.38808044, 0.32622977, 0.38167203,\n",
      "       0.38167203, 0.39876108, 0.40523556, 0.40523556, 0.38895492,\n",
      "       0.39755102, 0.39755102, 0.74851766, 0.85747916, 0.85747916,\n",
      "       0.73566387, 0.84593598, 0.84593598, 0.87966491, 0.90114727,\n",
      "       0.90114727, 0.85614952, 0.88826456, 0.88826456, 0.9329416 ,\n",
      "       0.93431704, 0.93431704, 0.90617157, 0.91633624, 0.91633624,\n",
      "       0.19888916, 0.36800707, 0.36800707, 0.19604974, 0.36329593,\n",
      "       0.36329593, 0.33026482, 0.38808044, 0.38808044, 0.32622977,\n",
      "       0.38167203, 0.38167203, 0.39876108, 0.40523556, 0.40523556,\n",
      "       0.38895492, 0.39755102, 0.39755102, 0.80908782, 0.88224152,\n",
      "       0.88224152, 0.79267159, 0.87260217, 0.87260217, 0.90866266,\n",
      "       0.92625458, 0.92625458, 0.8874423 , 0.91422847, 0.91422847,\n",
      "       0.94890972, 0.955193  , 0.955193  , 0.93331711, 0.93800259,\n",
      "       0.93800259, 0.32046774, 0.49329793, 0.49329793, 0.32203208,\n",
      "       0.4884583 , 0.4884583 , 0.49093356, 0.52096169, 0.52096169,\n",
      "       0.470495  , 0.51465517, 0.51465517, 0.56971015, 0.54493167,\n",
      "       0.54493167, 0.55899274, 0.53699843, 0.53699843, 0.80908782,\n",
      "       0.88224152, 0.88224152, 0.79267159, 0.87260217, 0.87260217,\n",
      "       0.90866266, 0.92625458, 0.92625458, 0.8874423 , 0.91422847,\n",
      "       0.91422847, 0.94890972, 0.955193  , 0.955193  , 0.93331711,\n",
      "       0.93800259, 0.93800259, 0.32046774, 0.49329793, 0.49329793,\n",
      "       0.32203208, 0.4884583 , 0.4884583 , 0.49093356, 0.52096169,\n",
      "       0.52096169, 0.470495  , 0.51465517, 0.51465517, 0.56971015,\n",
      "       0.54493167, 0.54493167, 0.55899274, 0.53699843, 0.53699843,\n",
      "       0.80908782, 0.88224152, 0.88224152, 0.79267159, 0.87260217,\n",
      "       0.87260217, 0.90866266, 0.92625458, 0.92625458, 0.8874423 ,\n",
      "       0.91422847, 0.91422847, 0.94890972, 0.955193  , 0.955193  ,\n",
      "       0.93331711, 0.93800259, 0.93800259, 0.32046774, 0.49329793,\n",
      "       0.49329793, 0.32203208, 0.4884583 , 0.4884583 , 0.49093356,\n",
      "       0.52096169, 0.52096169, 0.470495  , 0.51465517, 0.51465517,\n",
      "       0.56971015, 0.54493167, 0.54493167, 0.55899274, 0.53699843,\n",
      "       0.53699843, 0.80595681, 0.8951346 , 0.8951346 , 0.80038779,\n",
      "       0.88057884, 0.88057884, 0.91393689, 0.93403623, 0.93403623,\n",
      "       0.8952414 , 0.92068954, 0.92068954, 0.95111425, 0.96166494,\n",
      "       0.96166494, 0.93515504, 0.94622978, 0.94622978, 0.35096868,\n",
      "       0.59772422, 0.59772422, 0.38225581, 0.59394834, 0.59394834,\n",
      "       0.58610497, 0.63207392, 0.63207392, 0.56937491, 0.6270184 ,\n",
      "       0.6270184 , 0.66388461, 0.65903855, 0.65903855, 0.64357547,\n",
      "       0.65063102, 0.65063102, 0.80595681, 0.8951346 , 0.8951346 ,\n",
      "       0.80038779, 0.88057884, 0.88057884, 0.91393689, 0.93403623,\n",
      "       0.93403623, 0.8952414 , 0.92068954, 0.92068954, 0.95111425,\n",
      "       0.96166494, 0.96166494, 0.93515504, 0.94622978, 0.94622978,\n",
      "       0.35096868, 0.59772422, 0.59772422, 0.38225581, 0.59394834,\n",
      "       0.59394834, 0.58610497, 0.63207392, 0.63207392, 0.56937491,\n",
      "       0.6270184 , 0.6270184 , 0.66388461, 0.65903855, 0.65903855,\n",
      "       0.64357547, 0.65063102, 0.65063102, 0.80595681, 0.8951346 ,\n",
      "       0.8951346 , 0.80038779, 0.88057884, 0.88057884, 0.91393689,\n",
      "       0.93403623, 0.93403623, 0.8952414 , 0.92068954, 0.92068954,\n",
      "       0.95111425, 0.96166494, 0.96166494, 0.93515504, 0.94622978,\n",
      "       0.94622978, 0.35096868, 0.59772422, 0.59772422, 0.38225581,\n",
      "       0.59394834, 0.59394834, 0.58610497, 0.63207392, 0.63207392,\n",
      "       0.56937491, 0.6270184 , 0.6270184 , 0.66388461, 0.65903855,\n",
      "       0.65903855, 0.64357547, 0.65063102, 0.65063102, 0.77515381,\n",
      "       0.89927527, 0.89927527, 0.78415667, 0.88722076, 0.88722076,\n",
      "       0.911722  , 0.93982155, 0.93982155, 0.89966432, 0.9228657 ,\n",
      "       0.9228657 , 0.95083398, 0.96466388, 0.96466388, 0.93476326,\n",
      "       0.94827615, 0.94827615, 0.33553226, 0.67629565, 0.67629565,\n",
      "       0.3997719 , 0.67393263, 0.67393263, 0.6213464 , 0.71476718,\n",
      "       0.71476718, 0.60402506, 0.70947674, 0.70947674, 0.69883704,\n",
      "       0.73812573, 0.73812573, 0.66610448, 0.73282333, 0.73282333,\n",
      "       0.77515381, 0.89927527, 0.89927527, 0.78415667, 0.88722076,\n",
      "       0.88722076, 0.911722  , 0.93982155, 0.93982155, 0.89966432,\n",
      "       0.9228657 , 0.9228657 , 0.95083398, 0.96466388, 0.96466388,\n",
      "       0.93476326, 0.94827615, 0.94827615, 0.33553226, 0.67629565,\n",
      "       0.67629565, 0.3997719 , 0.67393263, 0.67393263, 0.6213464 ,\n",
      "       0.71476718, 0.71476718, 0.60402506, 0.70947674, 0.70947674,\n",
      "       0.69883704, 0.73812573, 0.73812573, 0.66610448, 0.73282333,\n",
      "       0.73282333, 0.77515381, 0.89927527, 0.89927527, 0.78415667,\n",
      "       0.88722076, 0.88722076, 0.911722  , 0.93982155, 0.93982155,\n",
      "       0.89966432, 0.9228657 , 0.9228657 , 0.95083398, 0.96466388,\n",
      "       0.96466388, 0.93476326, 0.94827615, 0.94827615, 0.33553226,\n",
      "       0.67629565, 0.67629565, 0.3997719 , 0.67393263, 0.67393263,\n",
      "       0.6213464 , 0.71476718, 0.71476718, 0.60402506, 0.70947674,\n",
      "       0.70947674, 0.69883704, 0.73812573, 0.73812573, 0.66610448,\n",
      "       0.73282333, 0.73282333]), 'split2_train_score': array([0.72558114, 0.83054103, 0.83054103, 0.67536976, 0.8047232 ,\n",
      "       0.8047232 , 0.87219438, 0.89428688, 0.89428688, 0.84019554,\n",
      "       0.86594402, 0.86594402, 0.93363187, 0.93117129, 0.93117129,\n",
      "       0.89729827, 0.89568416, 0.89568416, 0.1860728 , 0.31998194,\n",
      "       0.31998194, 0.17873663, 0.31403458, 0.31403458, 0.31435247,\n",
      "       0.35156382, 0.35156382, 0.2929137 , 0.33785278, 0.33785278,\n",
      "       0.38969875, 0.37105028, 0.37105028, 0.34910383, 0.3543382 ,\n",
      "       0.3543382 , 0.72558114, 0.83054103, 0.83054103, 0.67536976,\n",
      "       0.8047232 , 0.8047232 , 0.87219438, 0.89428688, 0.89428688,\n",
      "       0.84019554, 0.86594402, 0.86594402, 0.93363187, 0.93117129,\n",
      "       0.93117129, 0.89729827, 0.89568416, 0.89568416, 0.1860728 ,\n",
      "       0.31998194, 0.31998194, 0.17873663, 0.31403458, 0.31403458,\n",
      "       0.31435247, 0.35156382, 0.35156382, 0.2929137 , 0.33785278,\n",
      "       0.33785278, 0.38969875, 0.37105028, 0.37105028, 0.34910383,\n",
      "       0.3543382 , 0.3543382 , 0.72558114, 0.83054103, 0.83054103,\n",
      "       0.67536976, 0.8047232 , 0.8047232 , 0.87219438, 0.89428688,\n",
      "       0.89428688, 0.84019554, 0.86594402, 0.86594402, 0.93363187,\n",
      "       0.93117129, 0.93117129, 0.89729827, 0.89568416, 0.89568416,\n",
      "       0.1860728 , 0.31998194, 0.31998194, 0.17873663, 0.31403458,\n",
      "       0.31403458, 0.31435247, 0.35156382, 0.35156382, 0.2929137 ,\n",
      "       0.33785278, 0.33785278, 0.38969875, 0.37105028, 0.37105028,\n",
      "       0.34910383, 0.3543382 , 0.3543382 , 0.8020157 , 0.86930065,\n",
      "       0.86930065, 0.76378832, 0.84049205, 0.84049205, 0.91184268,\n",
      "       0.92449858, 0.92449858, 0.88056896, 0.89519755, 0.89519755,\n",
      "       0.95949017, 0.95401873, 0.95401873, 0.92744856, 0.92767523,\n",
      "       0.92767523, 0.28306288, 0.44180234, 0.44180234, 0.27724889,\n",
      "       0.43307342, 0.43307342, 0.46767381, 0.48743301, 0.48743301,\n",
      "       0.44866581, 0.47188161, 0.47188161, 0.5571974 , 0.51263197,\n",
      "       0.51263197, 0.52259201, 0.49490266, 0.49490266, 0.8020157 ,\n",
      "       0.86930065, 0.86930065, 0.76378832, 0.84049205, 0.84049205,\n",
      "       0.91184268, 0.92449858, 0.92449858, 0.88056896, 0.89519755,\n",
      "       0.89519755, 0.95949017, 0.95401873, 0.95401873, 0.92744856,\n",
      "       0.92767523, 0.92767523, 0.28306288, 0.44180234, 0.44180234,\n",
      "       0.27724889, 0.43307342, 0.43307342, 0.46767381, 0.48743301,\n",
      "       0.48743301, 0.44866581, 0.47188161, 0.47188161, 0.5571974 ,\n",
      "       0.51263197, 0.51263197, 0.52259201, 0.49490266, 0.49490266,\n",
      "       0.8020157 , 0.86930065, 0.86930065, 0.76378832, 0.84049205,\n",
      "       0.84049205, 0.91184268, 0.92449858, 0.92449858, 0.88056896,\n",
      "       0.89519755, 0.89519755, 0.95949017, 0.95401873, 0.95401873,\n",
      "       0.92744856, 0.92767523, 0.92767523, 0.28306288, 0.44180234,\n",
      "       0.44180234, 0.27724889, 0.43307342, 0.43307342, 0.46767381,\n",
      "       0.48743301, 0.48743301, 0.44866581, 0.47188161, 0.47188161,\n",
      "       0.5571974 , 0.51263197, 0.51263197, 0.52259201, 0.49490266,\n",
      "       0.49490266, 0.81284623, 0.88752425, 0.88752425, 0.76518054,\n",
      "       0.85285271, 0.85285271, 0.91496741, 0.93534771, 0.93534771,\n",
      "       0.89222498, 0.90575457, 0.90575457, 0.95931331, 0.96141242,\n",
      "       0.96141242, 0.93876339, 0.93508739, 0.93508739, 0.33130514,\n",
      "       0.54416466, 0.54416466, 0.32572984, 0.53248876, 0.53248876,\n",
      "       0.55445137, 0.60444529, 0.60444529, 0.53324549, 0.58558391,\n",
      "       0.58558391, 0.64669538, 0.63145364, 0.63145364, 0.61362573,\n",
      "       0.61054687, 0.61054687, 0.81284623, 0.88752425, 0.88752425,\n",
      "       0.76518054, 0.85285271, 0.85285271, 0.91496741, 0.93534771,\n",
      "       0.93534771, 0.89222498, 0.90575457, 0.90575457, 0.95931331,\n",
      "       0.96141242, 0.96141242, 0.93876339, 0.93508739, 0.93508739,\n",
      "       0.33130514, 0.54416466, 0.54416466, 0.32572984, 0.53248876,\n",
      "       0.53248876, 0.55445137, 0.60444529, 0.60444529, 0.53324549,\n",
      "       0.58558391, 0.58558391, 0.64669538, 0.63145364, 0.63145364,\n",
      "       0.61362573, 0.61054687, 0.61054687, 0.81284623, 0.88752425,\n",
      "       0.88752425, 0.76518054, 0.85285271, 0.85285271, 0.91496741,\n",
      "       0.93534771, 0.93534771, 0.89222498, 0.90575457, 0.90575457,\n",
      "       0.95931331, 0.96141242, 0.96141242, 0.93876339, 0.93508739,\n",
      "       0.93508739, 0.33130514, 0.54416466, 0.54416466, 0.32572984,\n",
      "       0.53248876, 0.53248876, 0.55445137, 0.60444529, 0.60444529,\n",
      "       0.53324549, 0.58558391, 0.58558391, 0.64669538, 0.63145364,\n",
      "       0.63145364, 0.61362573, 0.61054687, 0.61054687, 0.80728371,\n",
      "       0.90465761, 0.90465761, 0.77783544, 0.85973075, 0.85973075,\n",
      "       0.91424857, 0.94251222, 0.94251222, 0.89929974, 0.90972507,\n",
      "       0.90972507, 0.95990796, 0.96571743, 0.96571743, 0.93964764,\n",
      "       0.94068565, 0.94068565, 0.35025871, 0.61928496, 0.61928496,\n",
      "       0.34151554, 0.60769599, 0.60769599, 0.57549738, 0.69306566,\n",
      "       0.69306566, 0.5470479 , 0.67167956, 0.67167956, 0.68382657,\n",
      "       0.72192189, 0.72192189, 0.64673429, 0.69820495, 0.69820495,\n",
      "       0.80728371, 0.90465761, 0.90465761, 0.77783544, 0.85973075,\n",
      "       0.85973075, 0.91424857, 0.94251222, 0.94251222, 0.89929974,\n",
      "       0.90972507, 0.90972507, 0.95990796, 0.96571743, 0.96571743,\n",
      "       0.93964764, 0.94068565, 0.94068565, 0.35025871, 0.61928496,\n",
      "       0.61928496, 0.34151554, 0.60769599, 0.60769599, 0.57549738,\n",
      "       0.69306566, 0.69306566, 0.5470479 , 0.67167956, 0.67167956,\n",
      "       0.68382657, 0.72192189, 0.72192189, 0.64673429, 0.69820495,\n",
      "       0.69820495, 0.80728371, 0.90465761, 0.90465761, 0.77783544,\n",
      "       0.85973075, 0.85973075, 0.91424857, 0.94251222, 0.94251222,\n",
      "       0.89929974, 0.90972507, 0.90972507, 0.95990796, 0.96571743,\n",
      "       0.96571743, 0.93964764, 0.94068565, 0.94068565, 0.35025871,\n",
      "       0.61928496, 0.61928496, 0.34151554, 0.60769599, 0.60769599,\n",
      "       0.57549738, 0.69306566, 0.69306566, 0.5470479 , 0.67167956,\n",
      "       0.67167956, 0.68382657, 0.72192189, 0.72192189, 0.64673429,\n",
      "       0.69820495, 0.69820495]), 'mean_train_score': array([0.74555069, 0.84525686, 0.84525686, 0.71223761, 0.82490314,\n",
      "       0.82490314, 0.87989409, 0.89846243, 0.89846243, 0.85034516,\n",
      "       0.87225685, 0.87225685, 0.93258785, 0.93157181, 0.93157181,\n",
      "       0.90027839, 0.90138501, 0.90138501, 0.18778248, 0.34342212,\n",
      "       0.34342212, 0.18248883, 0.33668798, 0.33668798, 0.3177687 ,\n",
      "       0.36777903, 0.36777903, 0.30251054, 0.35619256, 0.35619256,\n",
      "       0.39182653, 0.38623774, 0.38623774, 0.36455302, 0.3730133 ,\n",
      "       0.3730133 , 0.74555069, 0.84525686, 0.84525686, 0.71223761,\n",
      "       0.82490314, 0.82490314, 0.87989409, 0.89846243, 0.89846243,\n",
      "       0.85034516, 0.87225685, 0.87225685, 0.93258785, 0.93157181,\n",
      "       0.93157181, 0.90027839, 0.90138501, 0.90138501, 0.18778248,\n",
      "       0.34342212, 0.34342212, 0.18248883, 0.33668798, 0.33668798,\n",
      "       0.3177687 , 0.36777903, 0.36777903, 0.30251054, 0.35619256,\n",
      "       0.35619256, 0.39182653, 0.38623774, 0.38623774, 0.36455302,\n",
      "       0.3730133 , 0.3730133 , 0.74555069, 0.84525686, 0.84525686,\n",
      "       0.71223761, 0.82490314, 0.82490314, 0.87989409, 0.89846243,\n",
      "       0.89846243, 0.85034516, 0.87225685, 0.87225685, 0.93258785,\n",
      "       0.93157181, 0.93157181, 0.90027839, 0.90138501, 0.90138501,\n",
      "       0.18778248, 0.34342212, 0.34342212, 0.18248883, 0.33668798,\n",
      "       0.33668798, 0.3177687 , 0.36777903, 0.36777903, 0.30251054,\n",
      "       0.35619256, 0.35619256, 0.39182653, 0.38623774, 0.38623774,\n",
      "       0.36455302, 0.3730133 , 0.3730133 , 0.80817916, 0.87743118,\n",
      "       0.87743118, 0.78888171, 0.85750098, 0.85750098, 0.91253342,\n",
      "       0.9245879 , 0.9245879 , 0.88747484, 0.90451059, 0.90451059,\n",
      "       0.95411487, 0.9533253 , 0.9533253 , 0.92836103, 0.93135191,\n",
      "       0.93135191, 0.29555779, 0.46781434, 0.46781434, 0.29793027,\n",
      "       0.45954884, 0.45954884, 0.48370646, 0.50380733, 0.50380733,\n",
      "       0.46372071, 0.4895068 , 0.4895068 , 0.5610926 , 0.5280098 ,\n",
      "       0.5280098 , 0.53647215, 0.51059512, 0.51059512, 0.80817916,\n",
      "       0.87743118, 0.87743118, 0.78888171, 0.85750098, 0.85750098,\n",
      "       0.91253342, 0.9245879 , 0.9245879 , 0.88747484, 0.90451059,\n",
      "       0.90451059, 0.95411487, 0.9533253 , 0.9533253 , 0.92836103,\n",
      "       0.93135191, 0.93135191, 0.29555779, 0.46781434, 0.46781434,\n",
      "       0.29793027, 0.45954884, 0.45954884, 0.48370646, 0.50380733,\n",
      "       0.50380733, 0.46372071, 0.4895068 , 0.4895068 , 0.5610926 ,\n",
      "       0.5280098 , 0.5280098 , 0.53647215, 0.51059512, 0.51059512,\n",
      "       0.80817916, 0.87743118, 0.87743118, 0.78888171, 0.85750098,\n",
      "       0.85750098, 0.91253342, 0.9245879 , 0.9245879 , 0.88747484,\n",
      "       0.90451059, 0.90451059, 0.95411487, 0.9533253 , 0.9533253 ,\n",
      "       0.92836103, 0.93135191, 0.93135191, 0.29555779, 0.46781434,\n",
      "       0.46781434, 0.29793027, 0.45954884, 0.45954884, 0.48370646,\n",
      "       0.50380733, 0.50380733, 0.46372071, 0.4895068 , 0.4895068 ,\n",
      "       0.5610926 , 0.5280098 , 0.5280098 , 0.53647215, 0.51059512,\n",
      "       0.51059512, 0.81796179, 0.89009365, 0.89009365, 0.78864456,\n",
      "       0.86888437, 0.86888437, 0.9141313 , 0.93393744, 0.93393744,\n",
      "       0.89532802, 0.9127572 , 0.9127572 , 0.95495156, 0.96102247,\n",
      "       0.96102247, 0.93421329, 0.939744  , 0.939744  , 0.33360279,\n",
      "       0.57264323, 0.57264323, 0.35661086, 0.56351693, 0.56351693,\n",
      "       0.57712371, 0.61971055, 0.61971055, 0.55672967, 0.60385392,\n",
      "       0.60385392, 0.65591175, 0.64481214, 0.64481214, 0.62799888,\n",
      "       0.62623955, 0.62623955, 0.81796179, 0.89009365, 0.89009365,\n",
      "       0.78864456, 0.86888437, 0.86888437, 0.9141313 , 0.93393744,\n",
      "       0.93393744, 0.89532802, 0.9127572 , 0.9127572 , 0.95495156,\n",
      "       0.96102247, 0.96102247, 0.93421329, 0.939744  , 0.939744  ,\n",
      "       0.33360279, 0.57264323, 0.57264323, 0.35661086, 0.56351693,\n",
      "       0.56351693, 0.57712371, 0.61971055, 0.61971055, 0.55672967,\n",
      "       0.60385392, 0.60385392, 0.65591175, 0.64481214, 0.64481214,\n",
      "       0.62799888, 0.62623955, 0.62623955, 0.81796179, 0.89009365,\n",
      "       0.89009365, 0.78864456, 0.86888437, 0.86888437, 0.9141313 ,\n",
      "       0.93393744, 0.93393744, 0.89532802, 0.9127572 , 0.9127572 ,\n",
      "       0.95495156, 0.96102247, 0.96102247, 0.93421329, 0.939744  ,\n",
      "       0.939744  , 0.33360279, 0.57264323, 0.57264323, 0.35661086,\n",
      "       0.56351693, 0.56351693, 0.57712371, 0.61971055, 0.61971055,\n",
      "       0.55672967, 0.60385392, 0.60385392, 0.65591175, 0.64481214,\n",
      "       0.64481214, 0.62799888, 0.62623955, 0.62623955, 0.79671896,\n",
      "       0.90220833, 0.90220833, 0.79024205, 0.87914071, 0.87914071,\n",
      "       0.9148342 , 0.939571  , 0.939571  , 0.90017852, 0.91748641,\n",
      "       0.91748641, 0.95467871, 0.96378531, 0.96378531, 0.93640504,\n",
      "       0.9431866 , 0.9431866 , 0.33039026, 0.65165342, 0.65165342,\n",
      "       0.37550483, 0.64199431, 0.64199431, 0.60857237, 0.70582491,\n",
      "       0.70582491, 0.58616976, 0.68935519, 0.68935519, 0.69603575,\n",
      "       0.73057304, 0.73057304, 0.66208982, 0.71258067, 0.71258067,\n",
      "       0.79671896, 0.90220833, 0.90220833, 0.79024205, 0.87914071,\n",
      "       0.87914071, 0.9148342 , 0.939571  , 0.939571  , 0.90017852,\n",
      "       0.91748641, 0.91748641, 0.95467871, 0.96378531, 0.96378531,\n",
      "       0.93640504, 0.9431866 , 0.9431866 , 0.33039026, 0.65165342,\n",
      "       0.65165342, 0.37550483, 0.64199431, 0.64199431, 0.60857237,\n",
      "       0.70582491, 0.70582491, 0.58616976, 0.68935519, 0.68935519,\n",
      "       0.69603575, 0.73057304, 0.73057304, 0.66208982, 0.71258067,\n",
      "       0.71258067, 0.79671896, 0.90220833, 0.90220833, 0.79024205,\n",
      "       0.87914071, 0.87914071, 0.9148342 , 0.939571  , 0.939571  ,\n",
      "       0.90017852, 0.91748641, 0.91748641, 0.95467871, 0.96378531,\n",
      "       0.96378531, 0.93640504, 0.9431866 , 0.9431866 , 0.33039026,\n",
      "       0.65165342, 0.65165342, 0.37550483, 0.64199431, 0.64199431,\n",
      "       0.60857237, 0.70582491, 0.70582491, 0.58616976, 0.68935519,\n",
      "       0.68935519, 0.69603575, 0.73057304, 0.73057304, 0.66208982,\n",
      "       0.71258067, 0.71258067]), 'std_train_score': array([0.01523891, 0.01113789, 0.01113789, 0.02638626, 0.01683585,\n",
      "       0.01683585, 0.0063824 , 0.00299253, 0.00299253, 0.00720155,\n",
      "       0.01140306, 0.01140306, 0.00102777, 0.00209718, 0.00209718,\n",
      "       0.0041672 , 0.01067096, 0.01067097, 0.00845744, 0.01962288,\n",
      "       0.01962288, 0.00990266, 0.02030434, 0.02030434, 0.00913361,\n",
      "       0.01518527, 0.01518527, 0.01687348, 0.01858787, 0.01858787,\n",
      "       0.00502396, 0.01421378, 0.01421378, 0.01745739, 0.01812208,\n",
      "       0.01812208, 0.01523891, 0.01113789, 0.01113789, 0.02638626,\n",
      "       0.01683585, 0.01683585, 0.0063824 , 0.00299253, 0.00299253,\n",
      "       0.00720155, 0.01140306, 0.01140306, 0.00102777, 0.00209718,\n",
      "       0.00209718, 0.0041672 , 0.01067096, 0.01067097, 0.00845744,\n",
      "       0.01962288, 0.01962288, 0.00990266, 0.02030434, 0.02030434,\n",
      "       0.00913361, 0.01518527, 0.01518527, 0.01687348, 0.01858787,\n",
      "       0.01858787, 0.00502396, 0.01421378, 0.01421378, 0.01745739,\n",
      "       0.01812208, 0.01812208, 0.01523891, 0.01113789, 0.01113789,\n",
      "       0.02638626, 0.01683585, 0.01683585, 0.0063824 , 0.00299253,\n",
      "       0.00299253, 0.00720155, 0.01140306, 0.01140306, 0.00102777,\n",
      "       0.00209718, 0.00209718, 0.0041672 , 0.01067096, 0.01067097,\n",
      "       0.00845744, 0.01962288, 0.01962288, 0.00990266, 0.02030434,\n",
      "       0.02030434, 0.00913361, 0.01518527, 0.01518527, 0.01687348,\n",
      "       0.01858787, 0.01858787, 0.00502396, 0.01421378, 0.01421378,\n",
      "       0.01745739, 0.01812208, 0.01812208, 0.00470556, 0.00578125,\n",
      "       0.00578125, 0.01913009, 0.01317813, 0.01317813, 0.00347693,\n",
      "       0.00132588, 0.00132588, 0.00565196, 0.00777461, 0.00777461,\n",
      "       0.00432113, 0.00187336, 0.00187336, 0.00373033, 0.00471148,\n",
      "       0.00471148, 0.01761402, 0.02102631, 0.02102631, 0.01844195,\n",
      "       0.0226762 , 0.0226762 , 0.0113551 , 0.01369913, 0.01369913,\n",
      "       0.01066317, 0.01825455, 0.01825455, 0.00610288, 0.01323142,\n",
      "       0.01323142, 0.01606749, 0.0187804 , 0.0187804 , 0.00470556,\n",
      "       0.00578125, 0.00578125, 0.01913009, 0.01317813, 0.01317813,\n",
      "       0.00347693, 0.00132588, 0.00132588, 0.00565196, 0.00777461,\n",
      "       0.00777461, 0.00432113, 0.00187336, 0.00187336, 0.00373033,\n",
      "       0.00471148, 0.00471148, 0.01761402, 0.02102631, 0.02102631,\n",
      "       0.01844195, 0.0226762 , 0.0226762 , 0.0113551 , 0.01369913,\n",
      "       0.01369913, 0.01066317, 0.01825455, 0.01825455, 0.00610288,\n",
      "       0.01323142, 0.01323142, 0.01606749, 0.0187804 , 0.0187804 ,\n",
      "       0.00470556, 0.00578125, 0.00578125, 0.01913009, 0.01317813,\n",
      "       0.01317813, 0.00347693, 0.00132588, 0.00132588, 0.00565196,\n",
      "       0.00777461, 0.00777461, 0.00432113, 0.00187336, 0.00187336,\n",
      "       0.00373033, 0.00471148, 0.00471148, 0.01761402, 0.02102631,\n",
      "       0.02102631, 0.01844195, 0.0226762 , 0.0226762 , 0.0113551 ,\n",
      "       0.01369913, 0.01369913, 0.01066317, 0.01825455, 0.01825455,\n",
      "       0.00610288, 0.01323142, 0.01323142, 0.01606749, 0.0187804 ,\n",
      "       0.0187804 , 0.01242848, 0.00356471, 0.00356471, 0.01659157,\n",
      "       0.01172726, 0.01172726, 0.00061877, 0.00119385, 0.00119385,\n",
      "       0.00256971, 0.00613251, 0.00613251, 0.00336773, 0.00073726,\n",
      "       0.00073726, 0.00415334, 0.00472917, 0.00472917, 0.01334049,\n",
      "       0.02199719, 0.02199719, 0.02337176, 0.02509432, 0.02509432,\n",
      "       0.01614665, 0.01146447, 0.01146447, 0.01662219, 0.01726598,\n",
      "       0.01726598, 0.00707235, 0.0112782 , 0.0112782 , 0.01225651,\n",
      "       0.01748212, 0.01748212, 0.01242848, 0.00356471, 0.00356471,\n",
      "       0.01659157, 0.01172726, 0.01172726, 0.00061877, 0.00119385,\n",
      "       0.00119385, 0.00256971, 0.00613251, 0.00613251, 0.00336773,\n",
      "       0.00073726, 0.00073726, 0.00415334, 0.00472917, 0.00472917,\n",
      "       0.01334049, 0.02199719, 0.02199719, 0.02337176, 0.02509432,\n",
      "       0.02509432, 0.01614665, 0.01146447, 0.01146447, 0.01662219,\n",
      "       0.01726598, 0.01726598, 0.00707235, 0.0112782 , 0.0112782 ,\n",
      "       0.01225651, 0.01748212, 0.01748212, 0.01242848, 0.00356471,\n",
      "       0.00356471, 0.01659157, 0.01172726, 0.01172726, 0.00061877,\n",
      "       0.00119385, 0.00119385, 0.00256971, 0.00613251, 0.00613251,\n",
      "       0.00336773, 0.00073726, 0.00073726, 0.00415334, 0.00472917,\n",
      "       0.00472917, 0.01334049, 0.02199719, 0.02199719, 0.02337176,\n",
      "       0.02509432, 0.02509432, 0.01614665, 0.01146447, 0.01146447,\n",
      "       0.01662219, 0.01726598, 0.01726598, 0.00707235, 0.0112782 ,\n",
      "       0.0112782 , 0.01225651, 0.01748212, 0.01748212, 0.0152499 ,\n",
      "       0.0022238 , 0.0022238 , 0.01332804, 0.01378889, 0.01378889,\n",
      "       0.00281084, 0.00251004, 0.00251004, 0.00099617, 0.00562285,\n",
      "       0.00562285, 0.00383162, 0.00203346, 0.00203346, 0.00229293,\n",
      "       0.00359904, 0.00359904, 0.01867902, 0.02390712, 0.02390712,\n",
      "       0.02475671, 0.02709244, 0.02709244, 0.02358855, 0.00926161,\n",
      "       0.00926161, 0.02769837, 0.01552726, 0.01552726, 0.0090447 ,\n",
      "       0.00666063, 0.00666063, 0.0112624 , 0.0147292 , 0.0147292 ,\n",
      "       0.0152499 , 0.0022238 , 0.0022238 , 0.01332804, 0.01378889,\n",
      "       0.01378889, 0.00281084, 0.00251004, 0.00251004, 0.00099617,\n",
      "       0.00562285, 0.00562285, 0.00383162, 0.00203346, 0.00203346,\n",
      "       0.00229293, 0.00359904, 0.00359904, 0.01867902, 0.02390712,\n",
      "       0.02390712, 0.02475671, 0.02709244, 0.02709244, 0.02358855,\n",
      "       0.00926161, 0.00926161, 0.02769837, 0.01552726, 0.01552726,\n",
      "       0.0090447 , 0.00666063, 0.00666063, 0.0112624 , 0.0147292 ,\n",
      "       0.0147292 , 0.0152499 , 0.0022238 , 0.0022238 , 0.01332804,\n",
      "       0.01378889, 0.01378889, 0.00281084, 0.00251004, 0.00251004,\n",
      "       0.00099617, 0.00562285, 0.00562285, 0.00383162, 0.00203346,\n",
      "       0.00203346, 0.00229293, 0.00359904, 0.00359904, 0.01867902,\n",
      "       0.02390712, 0.02390712, 0.02475671, 0.02709244, 0.02709244,\n",
      "       0.02358855, 0.00926161, 0.00926161, 0.02769837, 0.01552726,\n",
      "       0.01552726, 0.0090447 , 0.00666063, 0.00666063, 0.0112624 ,\n",
      "       0.0147292 , 0.0147292 ])}\n"
     ]
    }
   ],
   "source": [
    "print(r_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parans:\n",
      " [{'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.3, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.5, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 0.7, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.0, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.1, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 4, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 6, 'regressor__min_child_weight': 3, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 1, 'scaler': None}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__colsample_bytree': 1, 'regressor__gamma': 0.2, 'regressor__learning_rate': 0.01, 'regressor__max_depth': 8, 'regressor__min_child_weight': 3, 'scaler': None}] \n",
      "\n",
      "mean_test_score:\n",
      " [0.52836724 0.6879909  0.6879909  0.53111126 0.70094517 0.70094539\n",
      " 0.66733518 0.7255984  0.7255984  0.66039481 0.71676905 0.71676836\n",
      " 0.6789806  0.73321898 0.73322253 0.67309681 0.72734599 0.72734091\n",
      " 0.14216158 0.2972597  0.2972597  0.14290385 0.29517595 0.29517595\n",
      " 0.22467947 0.31417979 0.31417979 0.22565104 0.31033861 0.31033861\n",
      " 0.262772   0.32286413 0.32286444 0.25828932 0.31924123 0.31924157\n",
      " 0.52836724 0.6879909  0.6879909  0.53111126 0.70094517 0.70094539\n",
      " 0.66733518 0.7255984  0.7255984  0.66039481 0.71676905 0.71676836\n",
      " 0.6789806  0.73321898 0.73322253 0.67309681 0.72734599 0.72734091\n",
      " 0.14216158 0.2972597  0.2972597  0.14290385 0.29517595 0.29517595\n",
      " 0.22467947 0.31417979 0.31417979 0.22565104 0.31033861 0.31033861\n",
      " 0.262772   0.32286413 0.32286444 0.25828932 0.31924123 0.31924157\n",
      " 0.52836724 0.6879909  0.6879909  0.53111126 0.70094517 0.70094539\n",
      " 0.66733518 0.7255984  0.7255984  0.66039481 0.71676905 0.71676836\n",
      " 0.6789806  0.73321898 0.73322253 0.67309681 0.72734599 0.72734091\n",
      " 0.14216158 0.2972597  0.2972597  0.14290385 0.29517595 0.29517595\n",
      " 0.22467947 0.31417979 0.31417979 0.22565104 0.31033861 0.31033861\n",
      " 0.262772   0.32286413 0.32286444 0.25828932 0.31924123 0.31924157\n",
      " 0.64111961 0.7314747  0.7314747  0.61852719 0.72801402 0.72801474\n",
      " 0.71142496 0.75729452 0.75729646 0.69821849 0.74133566 0.74133246\n",
      " 0.73704717 0.75576743 0.75576577 0.71318251 0.74819797 0.7481902\n",
      " 0.24586268 0.39962359 0.39962359 0.25033133 0.39564851 0.39564851\n",
      " 0.37795848 0.42581511 0.42581447 0.3791343  0.42150961 0.42150914\n",
      " 0.42685736 0.43734093 0.4373428  0.42905927 0.43170346 0.43170433\n",
      " 0.64111961 0.7314747  0.7314747  0.61852719 0.72801402 0.72801474\n",
      " 0.71142496 0.75729452 0.75729646 0.69821849 0.74133566 0.74133246\n",
      " 0.73704717 0.75576743 0.75576577 0.71318251 0.74819797 0.7481902\n",
      " 0.24586268 0.39962359 0.39962359 0.25033133 0.39564851 0.39564851\n",
      " 0.37795848 0.42581511 0.42581447 0.3791343  0.42150961 0.42150914\n",
      " 0.42685736 0.43734093 0.4373428  0.42905927 0.43170346 0.43170433\n",
      " 0.64111961 0.7314747  0.7314747  0.61852719 0.72801402 0.72801474\n",
      " 0.71142496 0.75729452 0.75729646 0.69821849 0.74133566 0.74133246\n",
      " 0.73704717 0.75576743 0.75576577 0.71318251 0.74819797 0.7481902\n",
      " 0.24586268 0.39962359 0.39962359 0.25033133 0.39564851 0.39564851\n",
      " 0.37795848 0.42581511 0.42581447 0.3791343  0.42150961 0.42150914\n",
      " 0.42685736 0.43734093 0.4373428  0.42905927 0.43170346 0.43170433\n",
      " 0.63154401 0.74182255 0.74182255 0.62784004 0.73481062 0.73481062\n",
      " 0.73228148 0.75702747 0.75703068 0.70471429 0.75103004 0.75103004\n",
      " 0.73794285 0.759609   0.7596003  0.71723828 0.75195415 0.75193789\n",
      " 0.28347597 0.49124606 0.49124606 0.3099473  0.48109486 0.48109486\n",
      " 0.46613976 0.52663693 0.52663688 0.46514973 0.51846963 0.51846957\n",
      " 0.51276759 0.53574728 0.53574859 0.51463261 0.5289573  0.52895868\n",
      " 0.63154401 0.74182255 0.74182255 0.62784004 0.73481062 0.73481062\n",
      " 0.73228148 0.75702747 0.75703068 0.70471429 0.75103004 0.75103004\n",
      " 0.73794285 0.759609   0.7596003  0.71723828 0.75195415 0.75193789\n",
      " 0.28347597 0.49124606 0.49124606 0.3099473  0.48109486 0.48109486\n",
      " 0.46613976 0.52663693 0.52663688 0.46514973 0.51846963 0.51846957\n",
      " 0.51276759 0.53574728 0.53574859 0.51463261 0.5289573  0.52895868\n",
      " 0.63154401 0.74182255 0.74182255 0.62784004 0.73481062 0.73481062\n",
      " 0.73228148 0.75702747 0.75703068 0.70471429 0.75103004 0.75103004\n",
      " 0.73794285 0.759609   0.7596003  0.71723828 0.75195415 0.75193789\n",
      " 0.28347597 0.49124606 0.49124606 0.3099473  0.48109486 0.48109486\n",
      " 0.46613976 0.52663693 0.52663688 0.46514973 0.51846963 0.51846957\n",
      " 0.51276759 0.53574728 0.53574859 0.51463261 0.5289573  0.52895868\n",
      " 0.60701444 0.75104901 0.75104902 0.62495098 0.75189707 0.75189706\n",
      " 0.70866503 0.75850382 0.75850519 0.6979481  0.74726022 0.74725962\n",
      " 0.71542101 0.75935576 0.75934171 0.7070995  0.75346717 0.75346081\n",
      " 0.28198947 0.55708809 0.55708809 0.32271484 0.54193794 0.54193794\n",
      " 0.48745489 0.60992138 0.60992147 0.48734153 0.59203196 0.59203203\n",
      " 0.53647804 0.61711169 0.61711365 0.5375511  0.6000298  0.60003081\n",
      " 0.60701444 0.75104901 0.75104902 0.62495098 0.75189707 0.75189706\n",
      " 0.70866503 0.75850382 0.75850519 0.6979481  0.74726022 0.74725962\n",
      " 0.71542101 0.75935576 0.75934171 0.7070995  0.75346717 0.75346081\n",
      " 0.28198947 0.55708809 0.55708809 0.32271484 0.54193794 0.54193794\n",
      " 0.48745489 0.60992138 0.60992147 0.48734153 0.59203196 0.59203203\n",
      " 0.53647804 0.61711169 0.61711365 0.5375511  0.6000298  0.60003081\n",
      " 0.60701444 0.75104901 0.75104902 0.62495098 0.75189707 0.75189706\n",
      " 0.70866503 0.75850382 0.75850519 0.6979481  0.74726022 0.74725962\n",
      " 0.71542101 0.75935576 0.75934171 0.7070995  0.75346717 0.75346081\n",
      " 0.28198947 0.55708809 0.55708809 0.32271484 0.54193794 0.54193794\n",
      " 0.48745489 0.60992138 0.60992147 0.48734153 0.59203196 0.59203203\n",
      " 0.53647804 0.61711169 0.61711365 0.5375511  0.6000298  0.60003081] \n",
      "\n",
      "std_test_score:\n",
      " [0.0684487  0.09003489 0.09003489 0.06441607 0.08816468 0.0881647\n",
      " 0.07772921 0.10150013 0.10150013 0.07165497 0.10485728 0.1048579\n",
      " 0.06901639 0.10069473 0.10069863 0.07570045 0.10586973 0.10586365\n",
      " 0.01544472 0.02390176 0.02390176 0.0113605  0.02217327 0.02217327\n",
      " 0.03151475 0.02895914 0.02895914 0.0248772  0.0262821  0.0262821\n",
      " 0.03075616 0.03148519 0.03148556 0.02280385 0.0277206  0.02772092\n",
      " 0.0684487  0.09003489 0.09003489 0.06441607 0.08816468 0.0881647\n",
      " 0.07772921 0.10150013 0.10150013 0.07165497 0.10485728 0.1048579\n",
      " 0.06901639 0.10069473 0.10069863 0.07570045 0.10586973 0.10586365\n",
      " 0.01544472 0.02390176 0.02390176 0.0113605  0.02217327 0.02217327\n",
      " 0.03151475 0.02895914 0.02895914 0.0248772  0.0262821  0.0262821\n",
      " 0.03075616 0.03148519 0.03148556 0.02280385 0.0277206  0.02772092\n",
      " 0.0684487  0.09003489 0.09003489 0.06441607 0.08816468 0.0881647\n",
      " 0.07772921 0.10150013 0.10150013 0.07165497 0.10485728 0.1048579\n",
      " 0.06901639 0.10069473 0.10069863 0.07570045 0.10586973 0.10586365\n",
      " 0.01544472 0.02390176 0.02390176 0.0113605  0.02217327 0.02217327\n",
      " 0.03151475 0.02895914 0.02895914 0.0248772  0.0262821  0.0262821\n",
      " 0.03075616 0.03148519 0.03148556 0.02280385 0.0277206  0.02772092\n",
      " 0.07301644 0.08460496 0.08460496 0.08104356 0.09045522 0.0904554\n",
      " 0.0717736  0.0854691  0.08546905 0.07044532 0.09930819 0.0993047\n",
      " 0.07072034 0.08595506 0.08595333 0.07091494 0.0976382  0.09762876\n",
      " 0.03085665 0.02910879 0.02910879 0.02332783 0.02591872 0.02591872\n",
      " 0.05393975 0.03900781 0.0390078  0.04926523 0.03757513 0.03757515\n",
      " 0.05265165 0.03893967 0.03894239 0.04612147 0.03567606 0.03567774\n",
      " 0.07301644 0.08460496 0.08460496 0.08104356 0.09045522 0.0904554\n",
      " 0.0717736  0.0854691  0.08546905 0.07044532 0.09930819 0.0993047\n",
      " 0.07072034 0.08595506 0.08595333 0.07091494 0.0976382  0.09762876\n",
      " 0.03085665 0.02910879 0.02910879 0.02332783 0.02591872 0.02591872\n",
      " 0.05393975 0.03900781 0.0390078  0.04926523 0.03757513 0.03757515\n",
      " 0.05265165 0.03893967 0.03894239 0.04612147 0.03567606 0.03567774\n",
      " 0.07301644 0.08460496 0.08460496 0.08104356 0.09045522 0.0904554\n",
      " 0.0717736  0.0854691  0.08546905 0.07044532 0.09930819 0.0993047\n",
      " 0.07072034 0.08595506 0.08595333 0.07091494 0.0976382  0.09762876\n",
      " 0.03085665 0.02910879 0.02910879 0.02332783 0.02591872 0.02591872\n",
      " 0.05393975 0.03900781 0.0390078  0.04926523 0.03757513 0.03757515\n",
      " 0.05265165 0.03893967 0.03894239 0.04612147 0.03567606 0.03567774\n",
      " 0.0862468  0.0858683  0.0858683  0.06114979 0.08952106 0.08952106\n",
      " 0.07461656 0.07980154 0.07980519 0.08425547 0.09709613 0.09709613\n",
      " 0.07980872 0.08126669 0.08125614 0.07548541 0.10219949 0.10218034\n",
      " 0.03874796 0.03344291 0.03344291 0.02530338 0.03020085 0.03020085\n",
      " 0.06649664 0.05031818 0.05031823 0.06547528 0.05134248 0.05134256\n",
      " 0.06109488 0.04880103 0.04880289 0.059312   0.04894563 0.04894754\n",
      " 0.0862468  0.0858683  0.0858683  0.06114979 0.08952106 0.08952106\n",
      " 0.07461656 0.07980154 0.07980519 0.08425547 0.09709613 0.09709613\n",
      " 0.07980872 0.08126669 0.08125614 0.07548541 0.10219949 0.10218034\n",
      " 0.03874796 0.03344291 0.03344291 0.02530338 0.03020085 0.03020085\n",
      " 0.06649664 0.05031818 0.05031823 0.06547528 0.05134248 0.05134256\n",
      " 0.06109488 0.04880103 0.04880289 0.059312   0.04894563 0.04894754\n",
      " 0.0862468  0.0858683  0.0858683  0.06114979 0.08952106 0.08952106\n",
      " 0.07461656 0.07980154 0.07980519 0.08425547 0.09709613 0.09709613\n",
      " 0.07980872 0.08126669 0.08125614 0.07548541 0.10219949 0.10218034\n",
      " 0.03874796 0.03344291 0.03344291 0.02530338 0.03020085 0.03020085\n",
      " 0.06649664 0.05031818 0.05031823 0.06547528 0.05134248 0.05134256\n",
      " 0.06109488 0.04880103 0.04880289 0.059312   0.04894563 0.04894754\n",
      " 0.09437976 0.08936344 0.08936342 0.07079329 0.09073995 0.09073995\n",
      " 0.09986827 0.09344379 0.09344325 0.09455672 0.1107177  0.11071862\n",
      " 0.09625564 0.09121121 0.09122523 0.07516424 0.11209622 0.11208958\n",
      " 0.03606798 0.04341227 0.04341227 0.01053015 0.03877456 0.03877456\n",
      " 0.07710584 0.07139582 0.07139593 0.07017992 0.06987768 0.06987777\n",
      " 0.07962213 0.06793139 0.06793362 0.07070194 0.06839664 0.06839786\n",
      " 0.09437976 0.08936344 0.08936342 0.07079329 0.09073995 0.09073995\n",
      " 0.09986827 0.09344379 0.09344325 0.09455672 0.1107177  0.11071862\n",
      " 0.09625564 0.09121121 0.09122523 0.07516424 0.11209622 0.11208958\n",
      " 0.03606798 0.04341227 0.04341227 0.01053015 0.03877456 0.03877456\n",
      " 0.07710584 0.07139582 0.07139593 0.07017992 0.06987768 0.06987777\n",
      " 0.07962213 0.06793139 0.06793362 0.07070194 0.06839664 0.06839786\n",
      " 0.09437976 0.08936344 0.08936342 0.07079329 0.09073995 0.09073995\n",
      " 0.09986827 0.09344379 0.09344325 0.09455672 0.1107177  0.11071862\n",
      " 0.09625564 0.09121121 0.09122523 0.07516424 0.11209622 0.11208958\n",
      " 0.03606798 0.04341227 0.04341227 0.01053015 0.03877456 0.03877456\n",
      " 0.07710584 0.07139582 0.07139593 0.07017992 0.06987768 0.06987777\n",
      " 0.07962213 0.06793139 0.06793362 0.07070194 0.06839664 0.06839786] \n",
      "\n",
      "mean_train_score:\n",
      " [0.74555069 0.84525686 0.84525686 0.71223761 0.82490314 0.82490314\n",
      " 0.87989409 0.89846243 0.89846243 0.85034516 0.87225685 0.87225685\n",
      " 0.93258785 0.93157181 0.93157181 0.90027839 0.90138501 0.90138501\n",
      " 0.18778248 0.34342212 0.34342212 0.18248883 0.33668798 0.33668798\n",
      " 0.3177687  0.36777903 0.36777903 0.30251054 0.35619256 0.35619256\n",
      " 0.39182653 0.38623774 0.38623774 0.36455302 0.3730133  0.3730133\n",
      " 0.74555069 0.84525686 0.84525686 0.71223761 0.82490314 0.82490314\n",
      " 0.87989409 0.89846243 0.89846243 0.85034516 0.87225685 0.87225685\n",
      " 0.93258785 0.93157181 0.93157181 0.90027839 0.90138501 0.90138501\n",
      " 0.18778248 0.34342212 0.34342212 0.18248883 0.33668798 0.33668798\n",
      " 0.3177687  0.36777903 0.36777903 0.30251054 0.35619256 0.35619256\n",
      " 0.39182653 0.38623774 0.38623774 0.36455302 0.3730133  0.3730133\n",
      " 0.74555069 0.84525686 0.84525686 0.71223761 0.82490314 0.82490314\n",
      " 0.87989409 0.89846243 0.89846243 0.85034516 0.87225685 0.87225685\n",
      " 0.93258785 0.93157181 0.93157181 0.90027839 0.90138501 0.90138501\n",
      " 0.18778248 0.34342212 0.34342212 0.18248883 0.33668798 0.33668798\n",
      " 0.3177687  0.36777903 0.36777903 0.30251054 0.35619256 0.35619256\n",
      " 0.39182653 0.38623774 0.38623774 0.36455302 0.3730133  0.3730133\n",
      " 0.80817916 0.87743118 0.87743118 0.78888171 0.85750098 0.85750098\n",
      " 0.91253342 0.9245879  0.9245879  0.88747484 0.90451059 0.90451059\n",
      " 0.95411487 0.9533253  0.9533253  0.92836103 0.93135191 0.93135191\n",
      " 0.29555779 0.46781434 0.46781434 0.29793027 0.45954884 0.45954884\n",
      " 0.48370646 0.50380733 0.50380733 0.46372071 0.4895068  0.4895068\n",
      " 0.5610926  0.5280098  0.5280098  0.53647215 0.51059512 0.51059512\n",
      " 0.80817916 0.87743118 0.87743118 0.78888171 0.85750098 0.85750098\n",
      " 0.91253342 0.9245879  0.9245879  0.88747484 0.90451059 0.90451059\n",
      " 0.95411487 0.9533253  0.9533253  0.92836103 0.93135191 0.93135191\n",
      " 0.29555779 0.46781434 0.46781434 0.29793027 0.45954884 0.45954884\n",
      " 0.48370646 0.50380733 0.50380733 0.46372071 0.4895068  0.4895068\n",
      " 0.5610926  0.5280098  0.5280098  0.53647215 0.51059512 0.51059512\n",
      " 0.80817916 0.87743118 0.87743118 0.78888171 0.85750098 0.85750098\n",
      " 0.91253342 0.9245879  0.9245879  0.88747484 0.90451059 0.90451059\n",
      " 0.95411487 0.9533253  0.9533253  0.92836103 0.93135191 0.93135191\n",
      " 0.29555779 0.46781434 0.46781434 0.29793027 0.45954884 0.45954884\n",
      " 0.48370646 0.50380733 0.50380733 0.46372071 0.4895068  0.4895068\n",
      " 0.5610926  0.5280098  0.5280098  0.53647215 0.51059512 0.51059512\n",
      " 0.81796179 0.89009365 0.89009365 0.78864456 0.86888437 0.86888437\n",
      " 0.9141313  0.93393744 0.93393744 0.89532802 0.9127572  0.9127572\n",
      " 0.95495156 0.96102247 0.96102247 0.93421329 0.939744   0.939744\n",
      " 0.33360279 0.57264323 0.57264323 0.35661086 0.56351693 0.56351693\n",
      " 0.57712371 0.61971055 0.61971055 0.55672967 0.60385392 0.60385392\n",
      " 0.65591175 0.64481214 0.64481214 0.62799888 0.62623955 0.62623955\n",
      " 0.81796179 0.89009365 0.89009365 0.78864456 0.86888437 0.86888437\n",
      " 0.9141313  0.93393744 0.93393744 0.89532802 0.9127572  0.9127572\n",
      " 0.95495156 0.96102247 0.96102247 0.93421329 0.939744   0.939744\n",
      " 0.33360279 0.57264323 0.57264323 0.35661086 0.56351693 0.56351693\n",
      " 0.57712371 0.61971055 0.61971055 0.55672967 0.60385392 0.60385392\n",
      " 0.65591175 0.64481214 0.64481214 0.62799888 0.62623955 0.62623955\n",
      " 0.81796179 0.89009365 0.89009365 0.78864456 0.86888437 0.86888437\n",
      " 0.9141313  0.93393744 0.93393744 0.89532802 0.9127572  0.9127572\n",
      " 0.95495156 0.96102247 0.96102247 0.93421329 0.939744   0.939744\n",
      " 0.33360279 0.57264323 0.57264323 0.35661086 0.56351693 0.56351693\n",
      " 0.57712371 0.61971055 0.61971055 0.55672967 0.60385392 0.60385392\n",
      " 0.65591175 0.64481214 0.64481214 0.62799888 0.62623955 0.62623955\n",
      " 0.79671896 0.90220833 0.90220833 0.79024205 0.87914071 0.87914071\n",
      " 0.9148342  0.939571   0.939571   0.90017852 0.91748641 0.91748641\n",
      " 0.95467871 0.96378531 0.96378531 0.93640504 0.9431866  0.9431866\n",
      " 0.33039026 0.65165342 0.65165342 0.37550483 0.64199431 0.64199431\n",
      " 0.60857237 0.70582491 0.70582491 0.58616976 0.68935519 0.68935519\n",
      " 0.69603575 0.73057304 0.73057304 0.66208982 0.71258067 0.71258067\n",
      " 0.79671896 0.90220833 0.90220833 0.79024205 0.87914071 0.87914071\n",
      " 0.9148342  0.939571   0.939571   0.90017852 0.91748641 0.91748641\n",
      " 0.95467871 0.96378531 0.96378531 0.93640504 0.9431866  0.9431866\n",
      " 0.33039026 0.65165342 0.65165342 0.37550483 0.64199431 0.64199431\n",
      " 0.60857237 0.70582491 0.70582491 0.58616976 0.68935519 0.68935519\n",
      " 0.69603575 0.73057304 0.73057304 0.66208982 0.71258067 0.71258067\n",
      " 0.79671896 0.90220833 0.90220833 0.79024205 0.87914071 0.87914071\n",
      " 0.9148342  0.939571   0.939571   0.90017852 0.91748641 0.91748641\n",
      " 0.95467871 0.96378531 0.96378531 0.93640504 0.9431866  0.9431866\n",
      " 0.33039026 0.65165342 0.65165342 0.37550483 0.64199431 0.64199431\n",
      " 0.60857237 0.70582491 0.70582491 0.58616976 0.68935519 0.68935519\n",
      " 0.69603575 0.73057304 0.73057304 0.66208982 0.71258067 0.71258067] \n",
      "\n",
      "std_train_score:\n",
      " [0.01523891 0.01113789 0.01113789 0.02638626 0.01683585 0.01683585\n",
      " 0.0063824  0.00299253 0.00299253 0.00720155 0.01140306 0.01140306\n",
      " 0.00102777 0.00209718 0.00209718 0.0041672  0.01067096 0.01067097\n",
      " 0.00845744 0.01962288 0.01962288 0.00990266 0.02030434 0.02030434\n",
      " 0.00913361 0.01518527 0.01518527 0.01687348 0.01858787 0.01858787\n",
      " 0.00502396 0.01421378 0.01421378 0.01745739 0.01812208 0.01812208\n",
      " 0.01523891 0.01113789 0.01113789 0.02638626 0.01683585 0.01683585\n",
      " 0.0063824  0.00299253 0.00299253 0.00720155 0.01140306 0.01140306\n",
      " 0.00102777 0.00209718 0.00209718 0.0041672  0.01067096 0.01067097\n",
      " 0.00845744 0.01962288 0.01962288 0.00990266 0.02030434 0.02030434\n",
      " 0.00913361 0.01518527 0.01518527 0.01687348 0.01858787 0.01858787\n",
      " 0.00502396 0.01421378 0.01421378 0.01745739 0.01812208 0.01812208\n",
      " 0.01523891 0.01113789 0.01113789 0.02638626 0.01683585 0.01683585\n",
      " 0.0063824  0.00299253 0.00299253 0.00720155 0.01140306 0.01140306\n",
      " 0.00102777 0.00209718 0.00209718 0.0041672  0.01067096 0.01067097\n",
      " 0.00845744 0.01962288 0.01962288 0.00990266 0.02030434 0.02030434\n",
      " 0.00913361 0.01518527 0.01518527 0.01687348 0.01858787 0.01858787\n",
      " 0.00502396 0.01421378 0.01421378 0.01745739 0.01812208 0.01812208\n",
      " 0.00470556 0.00578125 0.00578125 0.01913009 0.01317813 0.01317813\n",
      " 0.00347693 0.00132588 0.00132588 0.00565196 0.00777461 0.00777461\n",
      " 0.00432113 0.00187336 0.00187336 0.00373033 0.00471148 0.00471148\n",
      " 0.01761402 0.02102631 0.02102631 0.01844195 0.0226762  0.0226762\n",
      " 0.0113551  0.01369913 0.01369913 0.01066317 0.01825455 0.01825455\n",
      " 0.00610288 0.01323142 0.01323142 0.01606749 0.0187804  0.0187804\n",
      " 0.00470556 0.00578125 0.00578125 0.01913009 0.01317813 0.01317813\n",
      " 0.00347693 0.00132588 0.00132588 0.00565196 0.00777461 0.00777461\n",
      " 0.00432113 0.00187336 0.00187336 0.00373033 0.00471148 0.00471148\n",
      " 0.01761402 0.02102631 0.02102631 0.01844195 0.0226762  0.0226762\n",
      " 0.0113551  0.01369913 0.01369913 0.01066317 0.01825455 0.01825455\n",
      " 0.00610288 0.01323142 0.01323142 0.01606749 0.0187804  0.0187804\n",
      " 0.00470556 0.00578125 0.00578125 0.01913009 0.01317813 0.01317813\n",
      " 0.00347693 0.00132588 0.00132588 0.00565196 0.00777461 0.00777461\n",
      " 0.00432113 0.00187336 0.00187336 0.00373033 0.00471148 0.00471148\n",
      " 0.01761402 0.02102631 0.02102631 0.01844195 0.0226762  0.0226762\n",
      " 0.0113551  0.01369913 0.01369913 0.01066317 0.01825455 0.01825455\n",
      " 0.00610288 0.01323142 0.01323142 0.01606749 0.0187804  0.0187804\n",
      " 0.01242848 0.00356471 0.00356471 0.01659157 0.01172726 0.01172726\n",
      " 0.00061877 0.00119385 0.00119385 0.00256971 0.00613251 0.00613251\n",
      " 0.00336773 0.00073726 0.00073726 0.00415334 0.00472917 0.00472917\n",
      " 0.01334049 0.02199719 0.02199719 0.02337176 0.02509432 0.02509432\n",
      " 0.01614665 0.01146447 0.01146447 0.01662219 0.01726598 0.01726598\n",
      " 0.00707235 0.0112782  0.0112782  0.01225651 0.01748212 0.01748212\n",
      " 0.01242848 0.00356471 0.00356471 0.01659157 0.01172726 0.01172726\n",
      " 0.00061877 0.00119385 0.00119385 0.00256971 0.00613251 0.00613251\n",
      " 0.00336773 0.00073726 0.00073726 0.00415334 0.00472917 0.00472917\n",
      " 0.01334049 0.02199719 0.02199719 0.02337176 0.02509432 0.02509432\n",
      " 0.01614665 0.01146447 0.01146447 0.01662219 0.01726598 0.01726598\n",
      " 0.00707235 0.0112782  0.0112782  0.01225651 0.01748212 0.01748212\n",
      " 0.01242848 0.00356471 0.00356471 0.01659157 0.01172726 0.01172726\n",
      " 0.00061877 0.00119385 0.00119385 0.00256971 0.00613251 0.00613251\n",
      " 0.00336773 0.00073726 0.00073726 0.00415334 0.00472917 0.00472917\n",
      " 0.01334049 0.02199719 0.02199719 0.02337176 0.02509432 0.02509432\n",
      " 0.01614665 0.01146447 0.01146447 0.01662219 0.01726598 0.01726598\n",
      " 0.00707235 0.0112782  0.0112782  0.01225651 0.01748212 0.01748212\n",
      " 0.0152499  0.0022238  0.0022238  0.01332804 0.01378889 0.01378889\n",
      " 0.00281084 0.00251004 0.00251004 0.00099617 0.00562285 0.00562285\n",
      " 0.00383162 0.00203346 0.00203346 0.00229293 0.00359904 0.00359904\n",
      " 0.01867902 0.02390712 0.02390712 0.02475671 0.02709244 0.02709244\n",
      " 0.02358855 0.00926161 0.00926161 0.02769837 0.01552726 0.01552726\n",
      " 0.0090447  0.00666063 0.00666063 0.0112624  0.0147292  0.0147292\n",
      " 0.0152499  0.0022238  0.0022238  0.01332804 0.01378889 0.01378889\n",
      " 0.00281084 0.00251004 0.00251004 0.00099617 0.00562285 0.00562285\n",
      " 0.00383162 0.00203346 0.00203346 0.00229293 0.00359904 0.00359904\n",
      " 0.01867902 0.02390712 0.02390712 0.02475671 0.02709244 0.02709244\n",
      " 0.02358855 0.00926161 0.00926161 0.02769837 0.01552726 0.01552726\n",
      " 0.0090447  0.00666063 0.00666063 0.0112624  0.0147292  0.0147292\n",
      " 0.0152499  0.0022238  0.0022238  0.01332804 0.01378889 0.01378889\n",
      " 0.00281084 0.00251004 0.00251004 0.00099617 0.00562285 0.00562285\n",
      " 0.00383162 0.00203346 0.00203346 0.00229293 0.00359904 0.00359904\n",
      " 0.01867902 0.02390712 0.02390712 0.02475671 0.02709244 0.02709244\n",
      " 0.02358855 0.00926161 0.00926161 0.02769837 0.01552726 0.01552726\n",
      " 0.0090447  0.00666063 0.00666063 0.0112624  0.0147292  0.0147292 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('parans:\\n',r_dt['params'],'\\n')\n",
    "print('mean_test_score:\\n',r_dt['mean_test_score'],'\\n')\n",
    "print('std_test_score:\\n',r_dt['std_test_score'],'\\n')\n",
    "print('mean_train_score:\\n',r_dt['mean_train_score'],'\\n')\n",
    "print('std_train_score:\\n',r_dt['std_train_score'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SearchCV_XGBoost'\n",
    "pickle.dump(SearchCV, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                      ('scaler', Normalizer()),\n",
    "                      ('regressor', LinearSVR())\n",
    "                     ])\n",
    "\n",
    "parameters = {    \n",
    "              'scaler': [Normalizer(), MinMaxScaler(), None],\n",
    "              'regressor__C': [1, 0.1, 0.01]\n",
    "              }\n",
    "\n",
    "scoring = 'r2'\n",
    "\n",
    "n_splits = 3\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=123457)\n",
    "\n",
    "SearchCV = GridSearchCV(estimator=pipeline,\n",
    "                        param_grid=parameters,\n",
    "                        scoring=scoring, \n",
    "                        cv=cv,\n",
    "                        return_train_score=True,\n",
    "                        verbose=1, \n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  3.9min finished\n",
      "/Users/iflab/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/iflab/Desktop/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=123457, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        Normalizer(copy=True, norm='l2')),\n",
       "                                       ('regressor',\n",
       "                                        LinearSVR(C=1.0, dual=True, epsilon=0.0,\n",
       "                                                  fit_intercept=True,\n",
       "                                                  intercept_scaling=1.0,\n",
       "                                                  loss='epsilon_insensitive',\n",
       "                                                  max_iter=1000,\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'regressor__C': [1, 0.1, 0.01],\n",
       "                         'scaler': [Normalizer(copy=True, norm='l2'),\n",
       "                                    MinMaxScaler(copy=True,\n",
       "                                                 feature_range=(0, 1)),\n",
       "                                    None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__C': 0.01, 'scaler': None}\n",
      "0.474239347286399\n"
     ]
    }
   ],
   "source": [
    "best_estimator = SearchCV.best_estimator_\n",
    "best_params = SearchCV.best_params_\n",
    "print(best_params)\n",
    "print(SearchCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test score (r2): 0.541218650722493\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = SearchCV.predict(X_test)\n",
    "test_score = SearchCV.score(X_test, y_test) \n",
    "print(\" test score (\"+scoring+\"):\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dt=SearchCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 0.88728102,  1.11157211, 99.10561959,  1.12351274,  1.29156899,\n",
      "       85.24658942,  1.24985329,  1.29504569, 67.77525107]), 'std_fit_time': array([3.83551904e-02, 2.48020187e-02, 2.19269865e-01, 1.00927047e-02,\n",
      "       2.13526324e-03, 9.39169334e+00, 9.52747647e-02, 6.68429453e-02,\n",
      "       1.08608462e+01]), 'mean_score_time': array([0.07993094, 0.07470926, 0.01687749, 0.07298207, 0.07894532,\n",
      "       0.01582424, 0.07265306, 0.07351263, 0.01107637]), 'std_score_time': array([0.0047576 , 0.0144949 , 0.00055579, 0.00290023, 0.00349196,\n",
      "       0.00029896, 0.00018965, 0.0018397 , 0.00308277]), 'param_regressor__C': masked_array(data=[1, 1, 1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_scaler': masked_array(data=[Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None,\n",
      "                   Normalizer(copy=True, norm='l2'),\n",
      "                   MinMaxScaler(copy=True, feature_range=(0, 1)), None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'regressor__C': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__C': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__C': 1, 'scaler': None}, {'regressor__C': 0.1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__C': 0.1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__C': 0.1, 'scaler': None}, {'regressor__C': 0.01, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__C': 0.01, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__C': 0.01, 'scaler': None}], 'split0_test_score': array([-0.00719418, -0.00718614, -0.65670283, -0.00749972, -0.00743284,\n",
      "        0.03084534, -0.00800082, -0.00798955,  0.46331165]), 'split1_test_score': array([-0.00687587, -0.00683124,  0.37151493, -0.00713941, -0.00706619,\n",
      "       -0.18282259, -0.00762615, -0.00761545,  0.51845392]), 'split2_test_score': array([-0.00695043, -0.00690976, -0.94504605, -0.00722215, -0.00715083,\n",
      "        0.37591527, -0.00770579, -0.00769438,  0.44095247]), 'mean_test_score': array([-0.00700683, -0.00697571, -0.41007798, -0.00728709, -0.00721662,\n",
      "        0.074646  , -0.00777759, -0.00776646,  0.47423935]), 'std_test_score': array([1.35929381e-04, 1.52209578e-04, 5.65066999e-01, 1.54097612e-04,\n",
      "       1.56748616e-04, 2.30196831e-01, 1.61162566e-04, 1.61003556e-04,\n",
      "       3.25697138e-02]), 'rank_test_score': array([4, 3, 9, 6, 5, 2, 8, 7, 1], dtype=int32), 'split0_train_score': array([-0.00690619, -0.00687838, -0.8376693 , -0.00717052, -0.00710211,\n",
      "       -0.15087794, -0.00765854, -0.00764473,  0.49148247]), 'split1_train_score': array([-0.00707175, -0.00706326,  0.32466783, -0.00736177, -0.00729424,\n",
      "       -0.08556246, -0.00785547, -0.00784621,  0.456589  ]), 'split2_train_score': array([-0.00703961, -0.00698454, -1.16000421, -0.00732681, -0.00725161,\n",
      "        0.42073634, -0.00781665, -0.00780637,  0.48530668]), 'mean_train_score': array([-0.00700585, -0.00697539, -0.55766856, -0.00728637, -0.00721599,\n",
      "        0.06143198, -0.00777689, -0.00776577,  0.47779272]), 'std_train_score': array([7.16813567e-05, 7.57560721e-05, 6.37632638e-01, 8.31525060e-05,\n",
      "       8.23840975e-05, 2.55461996e-01, 8.51714745e-05, 8.71207801e-05,\n",
      "       1.52037978e-02])}\n"
     ]
    }
   ],
   "source": [
    "print(r_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parans:\n",
      " [{'regressor__C': 1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__C': 1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__C': 1, 'scaler': None}, {'regressor__C': 0.1, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__C': 0.1, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__C': 0.1, 'scaler': None}, {'regressor__C': 0.01, 'scaler': Normalizer(copy=True, norm='l2')}, {'regressor__C': 0.01, 'scaler': MinMaxScaler(copy=True, feature_range=(0, 1))}, {'regressor__C': 0.01, 'scaler': None}] \n",
      "\n",
      "mean_test_score:\n",
      " [-0.00700683 -0.00697571 -0.41007798 -0.00728709 -0.00721662  0.074646\n",
      " -0.00777759 -0.00776646  0.47423935] \n",
      "\n",
      "std_test_score:\n",
      " [1.35929381e-04 1.52209578e-04 5.65066999e-01 1.54097612e-04\n",
      " 1.56748616e-04 2.30196831e-01 1.61162566e-04 1.61003556e-04\n",
      " 3.25697138e-02] \n",
      "\n",
      "mean_train_score:\n",
      " [-0.00700585 -0.00697539 -0.55766856 -0.00728637 -0.00721599  0.06143198\n",
      " -0.00777689 -0.00776577  0.47779272] \n",
      "\n",
      "std_train_score:\n",
      " [7.16813567e-05 7.57560721e-05 6.37632638e-01 8.31525060e-05\n",
      " 8.23840975e-05 2.55461996e-01 8.51714745e-05 8.71207801e-05\n",
      " 1.52037978e-02] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('parans:\\n',r_dt['params'],'\\n')\n",
    "print('mean_test_score:\\n',r_dt['mean_test_score'],'\\n')\n",
    "print('std_test_score:\\n',r_dt['std_test_score'],'\\n')\n",
    "print('mean_train_score:\\n',r_dt['mean_train_score'],'\\n')\n",
    "print('std_train_score:\\n',r_dt['std_train_score'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SearchCV_SVM'\n",
    "pickle.dump(SearchCV, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
