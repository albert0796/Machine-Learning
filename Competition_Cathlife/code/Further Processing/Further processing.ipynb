{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainv1 = pd.read_csv(\"train_cleaned_version1.csv\", low_memory=False, index_col=0)\n",
    "testv1 = pd.read_csv(\"test_cleaned_1.csv\", low_memory=False, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization (略)\n",
    "由於表現較好的XGBOOST、random forest為tree-based model；另外，Logistic regression只要不做regularization像是Lasso、Ridge，理論基礎上有沒有standardization無差別。而KNN是這裡唯一會受重大影響的，但上傳次數有限就先不理它。(這個資料集以名目順序為主，應該也不太適合)\n",
    "\n",
    "注意:其實如果要Standardization的話要對train test split後的train資料做，而不是一起做"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding\n",
    "1. Tree-based model不適合用one-hot encoding。BJ4詳見:https://towardsdatascience.com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769\n",
    "\n",
    "2. Logistic regression、KNN則需要\n",
    "\n",
    "Note:僅針對名目尺度處理(如果只有2類(ex.GENDER)已經處理過了，這裡只要把多類轉換就行)\n",
    "原來就是名目:收費地址CHARGE_CITY_CD、聯絡地址CONTACT_CITY_CD、婚姻狀況MARRIAGE_CD 、九大客群CUST_9_SEGMENTS_CD\n",
    "補遺失值後視為名目:首次擔任要保人年齡(級距)APC_1ST_AGE、再購次數(級距)REBUY_TIMES_CNT、曾投保主約件數(等級)RFM_M_LEVEL、APC_1ST_YEARDIF、TERMINATION_RATE、RFM_R、LEVEL\n",
    "\n",
    "Note:職業類別特殊處理=>將0->7視為順序尺度\n",
    "\n",
    "注意:One hot 是可以在train_test split前做的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occ_tran(col):\n",
    "    if col == 0:\n",
    "        return 7\n",
    "    else:\n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainv1[\"OCCUPATION_CLASS_CD\"] = trainv1[\"OCCUPATION_CLASS_CD\"].apply(occ_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainv1.to_csv(\"train_cleaned_version1_proc_tree.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.get_dummies(trainv1[\"CHARGE_CITY_CD\"], drop_first=True)\n",
    "B = pd.get_dummies(trainv1[\"CONTACT_CITY_CD\"], drop_first=True)\n",
    "C = pd.get_dummies(trainv1[\"MARRIAGE_CD\"], drop_first=True)\n",
    "D = pd.get_dummies(trainv1[\"CUST_9_SEGMENTS_CD\"], drop_first=True)\n",
    "E = pd.get_dummies(trainv1[\"APC_1ST_AGE\"], drop_first=True)\n",
    "F = pd.get_dummies(trainv1[\"REBUY_TIMES_CNT\"], drop_first=True)\n",
    "G = pd.get_dummies(trainv1[\"RFM_M_LEVEL\"], drop_first=True)\n",
    "H = pd.get_dummies(trainv1[\"APC_1ST_YEARDIF\"], drop_first=True)\n",
    "I = pd.get_dummies(trainv1[\"TERMINATION_RATE\"], drop_first=True)\n",
    "J = pd.get_dummies(trainv1[\"RFM_R\"], drop_first=True)\n",
    "K = pd.get_dummies(trainv1[\"LEVEL\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainv1_encoding = pd.concat([trainv1, A, B, C, D, E, F, G, H, I, J, K], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainv1_encoding = trainv1_encoding.drop([\"CHARGE_CITY_CD\", \"CONTACT_CITY_CD\", \"MARRIAGE_CD\", \n",
    "                      \"CUST_9_SEGMENTS_CD\", \"APC_1ST_AGE\", \"REBUY_TIMES_CNT\", \n",
    "                      \"RFM_M_LEVEL\", \"APC_1ST_YEARDIF\", \"TERMINATION_RATE\", \"RFM_R\", \"LEVEL\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainv1_encoding.to_csv(\"train_cleaned_version1_proc_nontree.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testv1[\"OCCUPATION_CLASS_CD\"] = testv1[\"OCCUPATION_CLASS_CD\"].apply(occ_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    116804\n",
       "2.0     22388\n",
       "3.0      5776\n",
       "4.0      3189\n",
       "7.0      1180\n",
       "5.0       346\n",
       "6.0       317\n",
       "Name: OCCUPATION_CLASS_CD, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testv1[\"OCCUPATION_CLASS_CD\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testv1.to_csv(\"test_cleaned_version1_proc_tree.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.get_dummies(testv1[\"CHARGE_CITY_CD\"], drop_first=True)\n",
    "B = pd.get_dummies(testv1[\"CONTACT_CITY_CD\"], drop_first=True)\n",
    "C = pd.get_dummies(testv1[\"MARRIAGE_CD\"], drop_first=True)\n",
    "D = pd.get_dummies(testv1[\"CUST_9_SEGMENTS_CD\"], drop_first=True)\n",
    "E = pd.get_dummies(testv1[\"APC_1ST_AGE\"], drop_first=True)\n",
    "F = pd.get_dummies(testv1[\"REBUY_TIMES_CNT\"], drop_first=True)\n",
    "G = pd.get_dummies(testv1[\"RFM_M_LEVEL\"], drop_first=True)\n",
    "H = pd.get_dummies(testv1[\"APC_1ST_YEARDIF\"], drop_first=True)\n",
    "I = pd.get_dummies(testv1[\"TERMINATION_RATE\"], drop_first=True)\n",
    "J = pd.get_dummies(testv1[\"RFM_R\"], drop_first=True)\n",
    "K = pd.get_dummies(testv1[\"LEVEL\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testv1_encoding = pd.concat([testv1, A, B, C, D, E, F, G, H, I, J, K], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testv1_encoding = testv1_encoding.drop([\"CHARGE_CITY_CD\", \"CONTACT_CITY_CD\", \"MARRIAGE_CD\", \n",
    "                      \"CUST_9_SEGMENTS_CD\", \"APC_1ST_AGE\", \"REBUY_TIMES_CNT\", \n",
    "                      \"RFM_M_LEVEL\", \"APC_1ST_YEARDIF\", \"TERMINATION_RATE\", \"RFM_R\", \"LEVEL\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testv1_encoding.to_csv(\"test_cleaned_version1_proc_nontree.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
